{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265eac91",
   "metadata": {},
   "source": [
    "# Agent-OM è®­ç»ƒæ•°æ®ç”Ÿæˆ - Gemini API æµ‹è¯•\n",
    "\n",
    "æœ¬ Notebook è®°å½•äº†ä½¿ç”¨ Google Gemini API ä¸º Agent-OM æœ¬ä½“åŒ¹é…é¡¹ç›®ç”Ÿæˆè®­ç»ƒæ•°æ®çš„å®Œæ•´æµ‹è¯•è¿‡ç¨‹ã€‚\n",
    "\n",
    "## æµ‹è¯•ç›®æ ‡\n",
    "\n",
    "1. âœ… éªŒè¯ Gemini API è¿æ¥\n",
    "2. âœ… æµ‹è¯•åŸºç¡€æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›\n",
    "3. âœ… ç”Ÿæˆç»“æ„åŒ– Q&A å¯¹ï¼ˆå¸¦æ¨ç†è½¨è¿¹ï¼‰\n",
    "4. âœ… ç”Ÿæˆè®¾è®¡è§£å†³æ–¹æ¡ˆ\n",
    "5. âœ… é’ˆå¯¹ Agent-OM é¡¹ç›®ç”Ÿæˆå®é™…è®­ç»ƒæ ·æœ¬\n",
    "\n",
    "**æµ‹è¯•æ—¥æœŸ**: 2025å¹´12æœˆ18æ—¥  \n",
    "**LLM Provider**: Google Gemini 2.5 Flash  \n",
    "**ç›®æ ‡é¡¹ç›®**: Agent-OM (Ontology Matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb54dc2",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®ä¸å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d2fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\n",
      "ğŸ“ é¡¹ç›®è·¯å¾„: /Users/xianhaoliu/Library/CloudStorage/OneDrive-Stibo/Project/training_data_generation\n",
      "ğŸ”‘ Gemini API Key: å·²é…ç½®\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path\n",
    "project_path = Path.cwd()\n",
    "sys.path.insert(0, str(project_path))\n",
    "\n",
    "# å¯¼å…¥é¡¹ç›®æ¨¡å—\n",
    "from src.llm_service import LLMService\n",
    "from src.schema import CodeContext, QAPair, DesignSolution\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")\n",
    "print(f\"ğŸ“ é¡¹ç›®è·¯å¾„: {project_path}\")\n",
    "print(f\"ğŸ”‘ Gemini API Key: {'å·²é…ç½®' if os.getenv('GEMINI_API_KEY') else 'æœªé…ç½®'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70e78d",
   "metadata": {},
   "source": [
    "## 2. åˆå§‹åŒ– Gemini LLM æœåŠ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4547de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ æ­£åœ¨åˆå§‹åŒ– Gemini LLM æœåŠ¡...\n",
      "âœ… Gemini æœåŠ¡åˆå§‹åŒ–æˆåŠŸ\n",
      "   Provider: gemini\n",
      "   Model: gemini-2.5-flash\n",
      "   Temperature: 0.3 (é™ä½ä»¥æé«˜JSONæ ¼å¼ç¨³å®šæ€§)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– Gemini LLM æœåŠ¡...\")\n",
    "\n",
    "try:\n",
    "    # é™ä½ temperature ä»¥è·å¾—æ›´ç¨³å®šçš„ JSON è¾“å‡º\n",
    "    llm_service = LLMService(\n",
    "        provider=\"gemini\", \n",
    "        model=\"gemini-2.5-flash\", \n",
    "        temperature=0.3  # ä» 0.7 é™ä½åˆ° 0.3ï¼Œæé«˜æ ¼å¼ç¨³å®šæ€§\n",
    "    )\n",
    "    print(\"âœ… Gemini æœåŠ¡åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    print(f\"   Provider: {llm_service.provider}\")\n",
    "    print(f\"   Model: {llm_service.model}\")\n",
    "    print(f\"   Temperature: {llm_service.temperature} (é™ä½ä»¥æé«˜JSONæ ¼å¼ç¨³å®šæ€§)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42477ff",
   "metadata": {},
   "source": [
    "## 3. æµ‹è¯• 1ï¼šåŸºç¡€æ–‡æœ¬è¡¥å…¨\n",
    "\n",
    "æµ‹è¯• Gemini API çš„åŸºæœ¬æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a51abde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ æç¤ºè¯: ä»€ä¹ˆæ˜¯æœ¬ä½“åŒ¹é…ï¼ˆOntology Matchingï¼‰ï¼Ÿè¯·ç”¨2-3å¥è¯è§£é‡Šå…¶åœ¨è®¡ç®—æœºç§‘å­¦ä¸­çš„æ„ä¹‰ã€‚\n",
      "\n",
      "â³ æ­£åœ¨è°ƒç”¨ Gemini API...\n",
      "âœ… ç”ŸæˆæˆåŠŸ!\n",
      "\n",
      "======================================================================\n",
      "å›ç­”:\n",
      "æœ¬ä½“åŒ¹é…ï¼ˆOntology Matchingï¼‰æ˜¯æŒ‡è¯†åˆ«å’Œå»ºç«‹ä¸åŒæœ¬ä½“ä¹‹é—´è¯­ä¹‰å¯¹åº”å…³ç³»ï¼ˆå¦‚ç­‰ä»·ã€åŒ…å«ç­‰ï¼‰çš„è¿‡ç¨‹ï¼Œå³ä½¿å®ƒä»¬ä½¿ç”¨ä¸åŒçš„æœ¯è¯­æˆ–ç»“æ„æ¥æè¿°ç›¸ä¼¼çš„æ¦‚å¿µã€‚\n",
      "\n",
      "åœ¨è®¡ç®—æœºç§‘å­¦ä¸­ï¼Œå…¶æ„ä¹‰åœ¨äºå®ç°å¼‚æ„æ•°æ®æºçš„äº’æ“ä½œæ€§å’ŒçŸ¥è¯†é›†æˆï¼Œè¿›è€Œæ¨åŠ¨è¯­ä¹‰ç½‘ã€å¤§æ•°æ®é›†æˆå’Œäººå·¥æ™ºèƒ½ç­‰é¢†åŸŸçš„ä¿¡æ¯å…±äº«ä¸æ™ºèƒ½å¤„ç†ã€‚\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "prompt = \"ä»€ä¹ˆæ˜¯æœ¬ä½“åŒ¹é…ï¼ˆOntology Matchingï¼‰ï¼Ÿè¯·ç”¨2-3å¥è¯è§£é‡Šå…¶åœ¨è®¡ç®—æœºç§‘å­¦ä¸­çš„æ„ä¹‰ã€‚\"\n",
    "\n",
    "print(\"ğŸ“ æç¤ºè¯:\", prompt)\n",
    "print(\"\\nâ³ æ­£åœ¨è°ƒç”¨ Gemini API...\")\n",
    "\n",
    "try:\n",
    "    response = llm_service.generate_completion(prompt)\n",
    "    print(\"âœ… ç”ŸæˆæˆåŠŸ!\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"å›ç­”:\")\n",
    "    print(response)\n",
    "    print(\"=\" * 70)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç”Ÿæˆå¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6fa4a",
   "metadata": {},
   "source": [
    "## 4. æµ‹è¯• 2ï¼šç”Ÿæˆ Q&A å¯¹ï¼ˆå¸¦ä»£ç ä¸Šä¸‹æ–‡ï¼‰\n",
    "\n",
    "æµ‹è¯•é’ˆå¯¹æœ¬ä½“åŒ¹é…ä»£ç ç”Ÿæˆé—®ç­”å¯¹çš„èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977feae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ æ­£åœ¨ç”Ÿæˆ Q&A å¯¹...\n",
      "âœ… Q&A ç”ŸæˆæˆåŠŸ!\n",
      "\n",
      "======================================================================\n",
      "é—®é¢˜:\n",
      "The `match_ontologies` function employs a straightforward pairwise comparison approach. From an ontology matching and large language model (LLM) perspective, what are the primary characteristics, potential performance bottlenecks, and the critical role of the `compute_similarity` function in this design, especially when dealing with large or complex ontologies?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ç­”æ¡ˆ:\n",
      "The `match_ontologies` function implements a fundamental, exhaustive, and unsupervised ontology matching strategy. Its primary characteristics include simplicity and transparency, as it attempts to find matches for every possible pair of entities. However, this design introduces significant performa...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "æ¨ç†æ­¥éª¤æ•°: 4\n",
      "  1. 1.  **Analyze Algorithm Characteristics:** Identify the code's core logic as a b...\n",
      "  2. 2.  **Identify Performance Bottleneck:** Determine the time complexity. The nest...\n",
      "  3. 3.  **Elaborate on `compute_similarity`'s Critical Role:** Explain that `compute...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ç¤ºä¾‹ä»£ç ï¼šæœ¬ä½“åŒ¹é…å‡½æ•°\n",
    "code_sample = \"\"\"\n",
    "def match_ontologies(source_onto, target_onto, threshold=0.8):\n",
    "    \\\"\\\"\\\"\n",
    "    ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…æºæœ¬ä½“å’Œç›®æ ‡æœ¬ä½“ä¹‹é—´çš„å®ä½“\n",
    "    \n",
    "    Args:\n",
    "        source_onto: æºæœ¬ä½“å¯¹è±¡\n",
    "        target_onto: ç›®æ ‡æœ¬ä½“å¯¹è±¡\n",
    "        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.8ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        matches: åŒ¹é…å¯¹åˆ—è¡¨ï¼Œæ¯é¡¹ä¸º (source_entity, target_entity, similarity)\n",
    "    \\\"\\\"\\\"\n",
    "    matches = []\n",
    "    for source_entity in source_onto.entities:\n",
    "        for target_entity in target_onto.entities:\n",
    "            similarity = compute_similarity(source_entity, target_entity)\n",
    "            if similarity >= threshold:\n",
    "                matches.append((source_entity, target_entity, similarity))\n",
    "    return matches\n",
    "\"\"\"\n",
    "\n",
    "# æ„å»ºæç¤ºè¯ - è¦æ±‚æ›´ä¸¥æ ¼çš„ JSON æ ¼å¼\n",
    "qa_prompt = f\"\"\"ä½ æ˜¯æœ¬ä½“åŒ¹é…å’Œå¤§è¯­è¨€æ¨¡å‹é¢†åŸŸçš„ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ä»£ç ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„é—®ç­”å¯¹ï¼š\n",
    "\n",
    "ä»£ç :\n",
    "```python\n",
    "{code_sample}\n",
    "```\n",
    "\n",
    "è¦æ±‚:\n",
    "1. é—®é¢˜è¦æµ‹è¯•å¯¹ä»£ç åŠŸèƒ½å’Œè®¾è®¡çš„ç†è§£\n",
    "2. ç­”æ¡ˆè¦è¯¦ç»†ä¸”åŒ…å«æ¨ç†è¿‡ç¨‹\n",
    "3. æä¾› 3-5 ä¸ªæ¨ç†æ­¥éª¤\n",
    "\n",
    "é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼å›ç­”ï¼Œç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²ä¸­çš„å¼•å·éƒ½è¢«æ­£ç¡®è½¬ä¹‰ã€‚\n",
    "ä¸è¦ä½¿ç”¨ markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚\n",
    "\n",
    "æ ¼å¼ç¤ºä¾‹:\n",
    "{{\"question\": \"é—®é¢˜å†…å®¹\", \"answer\": \"ç­”æ¡ˆå†…å®¹\", \"reasoning_steps\": [\"æ­¥éª¤1\", \"æ­¥éª¤2\"]}}\n",
    "\"\"\"\n",
    "\n",
    "print(\"â³ æ­£åœ¨ç”Ÿæˆ Q&A å¯¹...\")\n",
    "\n",
    "try:\n",
    "    response = llm_service.generate_completion(qa_prompt)\n",
    "    \n",
    "    # å¤šå±‚æ¸…ç†ç­–ç•¥\n",
    "    response_clean = response.strip()\n",
    "    \n",
    "    # 1. ç§»é™¤ markdown ä»£ç å—æ ‡è®°\n",
    "    response_clean = re.sub(r'^```json\\s*', '', response_clean)\n",
    "    response_clean = re.sub(r'^```\\s*', '', response_clean)\n",
    "    response_clean = re.sub(r'\\s*```$', '', response_clean)\n",
    "    \n",
    "    # 2. ç§»é™¤å¯èƒ½çš„å‰å¯¼/å°¾éšç©ºç™½\n",
    "    response_clean = response_clean.strip()\n",
    "    \n",
    "    # å°è¯•è§£æ JSON\n",
    "    try:\n",
    "        qa_data = json.loads(response_clean)\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(f\"âš ï¸  åˆæ¬¡ JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤...\")\n",
    "        print(f\"   é”™è¯¯: {json_err}\")\n",
    "        \n",
    "        # å°è¯•ä½¿ç”¨ ast.literal_eval æˆ–å…¶ä»–æ–¹æ³•\n",
    "        # æ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯\n",
    "        print(f\"\\nğŸ“‹ åŸå§‹å“åº”å‰ 500 å­—ç¬¦:\")\n",
    "        print(response[:500])\n",
    "        print(f\"\\nğŸ“‹ æ¸…ç†åå“åº”å‰ 500 å­—ç¬¦:\")\n",
    "        print(response_clean[:500])\n",
    "        \n",
    "        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥è¿›å…¥å¤–å±‚å¼‚å¸¸å¤„ç†\n",
    "        raise json_err\n",
    "    \n",
    "    print(\"âœ… Q&A ç”ŸæˆæˆåŠŸ!\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"é—®é¢˜:\")\n",
    "    print(qa_data.get('question', 'N/A'))\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"ç­”æ¡ˆ:\")\n",
    "    answer = qa_data.get('answer', 'N/A')\n",
    "    print(answer[:300] + (\"...\" if len(answer) > 300 else \"\"))\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(f\"æ¨ç†æ­¥éª¤æ•°: {len(qa_data.get('reasoning_steps', []))}\")\n",
    "    for i, step in enumerate(qa_data.get('reasoning_steps', [])[:3], 1):\n",
    "        print(f\"  {i}. {step[:80]}{'...' if len(step) > 80 else ''}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\nâŒ JSON è§£æå¤±è´¥: {e}\")\n",
    "    print(f\"   ä½ç½®: line {e.lineno}, column {e.colno}\")\n",
    "    print(f\"\\nğŸ’¡ å»ºè®®:\")\n",
    "    print(\"   1. Gemini è¿”å›çš„ JSON å¯èƒ½åŒ…å«æœªè½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦\")\n",
    "    print(\"   2. å¯ä»¥å°è¯•é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼\")\n",
    "    print(\"   3. æˆ–ä¿®æ”¹æç¤ºè¯è¦æ±‚æ›´ç®€æ´çš„å›ç­”\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nğŸ“‹ å®Œæ•´é”™è¯¯å †æ ˆ:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e58e54",
   "metadata": {},
   "source": [
    "## 5. æµ‹è¯• 3ï¼šç”Ÿæˆè®¾è®¡è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "æµ‹è¯•ä¸ºæœ¬ä½“åŒ¹é…ç³»ç»Ÿç”Ÿæˆæ¶æ„è®¾è®¡æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ec426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ æ­£åœ¨ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ...\n",
      "âœ… è®¾è®¡æ–¹æ¡ˆç”ŸæˆæˆåŠŸ!\n",
      "\n",
      "======================================================================\n",
      "éœ€æ±‚:\n",
      "ä¸ºæœ¬ä½“åŒ¹é…ç³»ç»Ÿæ·»åŠ æ‰¹é‡å¤„ç†æ”¯æŒï¼Œä»¥å¤„ç†åŒ…å« 10,000+ å®ä½“çš„å¤§è§„æ¨¡æ•°æ®é›†\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "è§£å†³æ–¹æ¡ˆ:\n",
      "å®æ–½ä¸€ä¸ªåˆ†æ‰¹å¤„ç†ç®¡é“ï¼Œå°†å¤§å‹è¾“å…¥æ•°æ®é›†ï¼ˆåŒ…å«10,000+å®ä½“ï¼‰åˆ’åˆ†ä¸ºæ›´å°ã€å¯ç®¡ç†çš„æ‰¹æ¬¡ã€‚è¿™äº›æ‰¹æ¬¡å°†é€šè¿‡å¹¶è¡Œå·¥ä½œæ± è¿›è¡Œå¤„ç†ï¼Œå…¶å„è‡ªçš„åŒ¹é…ç»“æœå°†è¢«èšåˆä»¥å½¢æˆæœ€ç»ˆçš„ã€å…¨é¢çš„ç»“æœé›†ã€‚æ­¤æ–¹æ³•æ—¨åœ¨æœ€å°åŒ–å†…å­˜å ç”¨ï¼Œå¹¶å……åˆ†åˆ©ç”¨å¤šæ ¸æˆ–åˆ†å¸ƒå¼å¤„ç†èƒ½åŠ›ï¼Œä»¥é«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ•°æ®ã€‚\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "å®æ–½æ­¥éª¤ (6):\n",
      "  1. å¼€å‘ä¸€ä¸ªæ‰¹æ¬¡æ•°æ®åŠ è½½å™¨ï¼Œèƒ½å¤Ÿæµå¼è¯»å–å¤§è§„æ¨¡æ•°æ®é›†å¹¶å°†å…¶åˆ†å‰²æˆå¯é…ç½®å¤§å°çš„æ‰¹æ¬¡ï¼Œä»¥é¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ã€‚\n",
      "  2. ä¿®æ”¹ç°æœ‰çš„æœ¬ä½“åŒ¹é…ç®—æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿæ¥æ”¶å¹¶å¤„ç†ä¸€ä¸ªå®ä½“æ‰¹æ¬¡ï¼Œè€Œä¸æ˜¯å•ä¸ªå®ä½“ï¼Œå¹¶ç¡®ä¿æ‰¹æ¬¡è¾“å‡ºæ ¼å¼çš„ä¸€è‡´æ€§ã€‚\n",
      "  3. å¼•å…¥ä¸€ä¸ªå¹¶è¡Œå¤„ç†åè°ƒå™¨ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨çº¿ç¨‹æ± ã€è¿›ç¨‹æ± æˆ–æ¶ˆæ¯é˜Ÿåˆ—ï¼‰ï¼Œä»¥ç®¡ç†æ‰¹æ¬¡åŒ¹é…ä»»åŠ¡çš„å¹¶è¡Œæ‰§è¡Œï¼Œå°†æ¯ä¸ªæ‰¹æ¬¡åˆ†é…ç»™å¯ç”¨çš„å·¥ä½œçº¿ç¨‹æˆ–è¿›ç¨‹ã€‚\n",
      "  4. åˆ›å»ºä¸€ä¸ªç»“æœèšåˆæœåŠ¡ï¼Œè´Ÿè´£æ”¶é›†æ¥è‡ªæ‰€æœ‰å·²å¤„ç†æ‰¹æ¬¡çš„ç»“æœï¼Œå¹¶å°†å…¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€ã€è¿è´¯çš„è¾“å‡ºï¼Œå¿…è¦æ—¶å¤„ç†æ½œåœ¨çš„é‡å¤æˆ–å†²çªã€‚\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶ (6): ontology_matcher/batch_processor.py, ontology_matcher/data_loader.py, ontology_matcher/matching_algorithms.py, ontology_matcher/result_aggregator.py, config/settings.yaml\n",
      "  ... è¿˜æœ‰ 1 ä¸ªæ–‡ä»¶\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "å…³é”®æŒ‘æˆ˜ (5):\n",
      "  1. å†…å­˜ç®¡ç†ï¼šåœ¨å¤„ç†10,000+å®ä½“æ—¶ï¼Œå¦‚ä½•é«˜æ•ˆç®¡ç†å†…å­˜ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤æ‚çš„æœ¬ä½“ç»“æ„ï¼Œé˜²æ­¢å†…å­˜æº¢å‡ºã€‚\n",
      "  2. æ€§èƒ½ä¼˜åŒ–ï¼šç¡®ä¿æ‰¹å¤„ç†å’Œå¹¶è¡ŒåŒ–çš„å¼€é”€ä¸ä¼šæŠµæ¶ˆå…¶å¸¦æ¥çš„æ€§èƒ½ä¼˜åŠ¿ï¼Œå¹¶ä¼˜åŒ–åŒ¹é…ç®—æ³•ä»¥é€‚åº”æ‰¹æ¬¡è¾“å…¥ã€‚\n",
      "  3. ç»“æœä¸€è‡´æ€§å’Œèšåˆï¼šæ­£ç¡®åˆå¹¶æ¥è‡ªå¹¶è¡Œæ‰¹æ¬¡çš„ç»“æœï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ¹é…è¿‡ç¨‹å­˜åœ¨ä¾èµ–æ€§æˆ–å…¨å±€ä¸Šä¸‹æ–‡æ—¶ï¼Œç¡®ä¿æœ€ç»ˆç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "requirement = \"ä¸ºæœ¬ä½“åŒ¹é…ç³»ç»Ÿæ·»åŠ æ‰¹é‡å¤„ç†æ”¯æŒï¼Œä»¥å¤„ç†åŒ…å« 10,000+ å®ä½“çš„å¤§è§„æ¨¡æ•°æ®é›†\"\n",
    "\n",
    "design_prompt = f\"\"\"ä½ æ˜¯è½¯ä»¶æ¶æ„å¸ˆï¼Œè´Ÿè´£æœ¬ä½“åŒ¹é…ç³»ç»Ÿçš„è®¾è®¡ã€‚\n",
    "\n",
    "éœ€æ±‚: \"{requirement}\"\n",
    "\n",
    "è¯·ç”Ÿæˆä¸€ä¸ªè®¾è®¡è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬:\n",
    "- è§£å†³æ–¹æ¡ˆæ¦‚è¿°ï¼ˆç®€æ´æ˜äº†ï¼‰\n",
    "- 4-6 ä¸ªå®æ–½æ­¥éª¤\n",
    "- éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨\n",
    "- å…³é”®æŒ‘æˆ˜\n",
    "\n",
    "é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼å›ç­”ï¼Œç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²ä¸­çš„å¼•å·ã€æ‹¬å·ç­‰ç‰¹æ®Šå­—ç¬¦éƒ½è¢«æ­£ç¡®è½¬ä¹‰ã€‚\n",
    "ä¸è¦ä½¿ç”¨ markdown ä»£ç å—æ ‡è®°ã€‚ä¿æŒå›ç­”ç®€æ´ã€‚\n",
    "\n",
    "æ ¼å¼ç¤ºä¾‹:\n",
    "{{\"solution\": \"è§£å†³æ–¹æ¡ˆæè¿°\", \"steps\": [\"æ­¥éª¤1\", \"æ­¥éª¤2\"], \"files\": [\"file1.py\"], \"challenges\": [\"æŒ‘æˆ˜1\"]}}\n",
    "\"\"\"\n",
    "\n",
    "print(\"â³ æ­£åœ¨ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ...\")\n",
    "\n",
    "try:\n",
    "    response = llm_service.generate_completion(design_prompt)\n",
    "    \n",
    "    # å¤šå±‚æ¸…ç†ç­–ç•¥\n",
    "    response_clean = response.strip()\n",
    "    response_clean = re.sub(r'^```json\\s*', '', response_clean)\n",
    "    response_clean = re.sub(r'^```\\s*', '', response_clean)\n",
    "    response_clean = re.sub(r'\\s*```$', '', response_clean)\n",
    "    response_clean = response_clean.strip()\n",
    "    \n",
    "    # å°è¯•è§£æ JSON\n",
    "    try:\n",
    "        design_data = json.loads(response_clean)\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(f\"âš ï¸  åˆæ¬¡ JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤...\")\n",
    "        print(f\"   é”™è¯¯: {json_err}\")\n",
    "        print(f\"\\nğŸ“‹ åŸå§‹å“åº”å‰ 500 å­—ç¬¦:\")\n",
    "        print(response[:500])\n",
    "        print(f\"\\nğŸ“‹ æ¸…ç†åå“åº”å‰ 500 å­—ç¬¦:\")\n",
    "        print(response_clean[:500])\n",
    "        \n",
    "        # é‡æ–°æŠ›å‡ºå¼‚å¸¸\n",
    "        raise json_err\n",
    "    \n",
    "    print(\"âœ… è®¾è®¡æ–¹æ¡ˆç”ŸæˆæˆåŠŸ!\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"éœ€æ±‚:\")\n",
    "    print(requirement)\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"è§£å†³æ–¹æ¡ˆ:\")\n",
    "    solution = design_data.get('solution', 'N/A')\n",
    "    print(solution[:250] + (\"...\" if len(solution) > 250 else \"\"))\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(f\"å®æ–½æ­¥éª¤ ({len(design_data.get('steps', []))}):\")\n",
    "    for i, step in enumerate(design_data.get('steps', [])[:4], 1):\n",
    "        print(f\"  {i}. {step[:100]}{'...' if len(step) > 100 else ''}\")\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    files = design_data.get('files', [])\n",
    "    print(f\"éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶ ({len(files)}): {', '.join(files[:5])}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"  ... è¿˜æœ‰ {len(files) - 5} ä¸ªæ–‡ä»¶\")\n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(f\"å…³é”®æŒ‘æˆ˜ ({len(design_data.get('challenges', []))}):\")\n",
    "    for i, challenge in enumerate(design_data.get('challenges', [])[:3], 1):\n",
    "        print(f\"  {i}. {challenge[:80]}{'...' if len(challenge) > 80 else ''}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\nâŒ JSON è§£æå¤±è´¥: {e}\")\n",
    "    print(f\"   ä½ç½®: line {e.lineno}, column {e.colno}\")\n",
    "    print(f\"\\nğŸ’¡ å»ºè®®:\")\n",
    "    print(\"   1. Gemini è¿”å›çš„ JSON å¯èƒ½åŒ…å«æœªè½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦\")\n",
    "    print(\"   2. å¯ä»¥å°è¯•é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼\")\n",
    "    print(\"   3. æˆ–ç®€åŒ–éœ€æ±‚æè¿°\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\nğŸ“‹ å®Œæ•´é”™è¯¯å †æ ˆ:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed474b9a",
   "metadata": {},
   "source": [
    "## 6. Agent-OM é¡¹ç›®å®æˆ˜ï¼šç”Ÿæˆè®­ç»ƒæ ·æœ¬\n",
    "\n",
    "ä½¿ç”¨çœŸå®çš„ Agent-OM ä»£ç ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6bb0c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æµ‹è¯•æ–‡ä»¶: llm_matching.py\n",
      "ğŸ“ å®Œæ•´è·¯å¾„: /Users/xianhaoliu/Library/CloudStorage/OneDrive-Stibo/Project/Agent-OM/ontology-llm/llm_matching.py\n",
      "âœ… æ–‡ä»¶å­˜åœ¨: True\n",
      "\n",
      "ä»£ç ç‰‡æ®µé•¿åº¦: 800 å­—ç¬¦\n",
      "ä»£ç é¢„è§ˆ:\n",
      "import run_config as config\n",
      "\n",
      "llm = config.llm\n",
      "\n",
      "# context learning\n",
      "prompt = \"Is MA_0000270 equivalent to NCI_C33736?\"\n",
      "print(llm.invoke(prompt).content)\n",
      "prompt = \"What is the meaning of chair? Give a sh...\n",
      "\n",
      "ğŸ“ æç¤ºè¯é•¿åº¦: 1000 å­—ç¬¦\n",
      "ğŸ”„ ä½¿ç”¨å®½æ¾æ–‡æœ¬è§£æç­–ç•¥ï¼ˆä¸å¼ºåˆ¶JSONï¼‰\n",
      "\n",
      "â³ è°ƒç”¨Gemini API (å¯èƒ½éœ€è¦10-30ç§’)...\n",
      "âœ… APIå“åº”æˆåŠŸ! (è€—æ—¶: 11.6ç§’)\n",
      "ğŸ“Š å“åº”é•¿åº¦: 2632 å­—ç¬¦\n",
      "\n",
      "======================================================================\n",
      "åŸå§‹å“åº”:\n",
      "Question: What LLM capabilities are being demonstrated or tested by the different prompts in this Python code snippet?\n",
      "\n",
      "Answer: This Python code snippet demonstrates and tests several key capabilities of a Large Language Model (LLM), primarily focusing on:\n",
      "\n",
      "1.  **Contextual Understanding and Knowledge Retrieval:** The LLM's ability to understand the meaning of terms, both generally and within specific contexts, and to retrieve factual information or equivalences from its knowledge base.\n",
      "2.  **Logical Reasoning (Transitive Property):** The LLM's capacity to perform basic logical inferences, specifically applying the transitive property to relationships like equivalence or subclass hierarchies.\n",
      "\n",
      "Reasoning Steps:\n",
      "1.  **Identify the Core Operation:** The code repeatedly calls `llm.invoke(prompt).content`, indicating that it's sending various text prompts to an LLM and printing its responses. This means the prompts are designed to elicit specific behaviors or demonstrate certain capabilities of the LLM.\n",
      "2.  **Analyze \"context learning\" Prompts:**\n",
      "    *   `\"Is MA_0000270 equivalent to NCI_C33736?\"`: This prompt tests the LLM's ability to retrieve specific domain-knowledge (e.g., medical or biological identifiers) and determine equivalences, which falls under **Knowledge Retrieval**.\n",
      "    *   `\"What is the meaning of chair? Give a short explanation.\"`: This tests the LLM's general semantic understanding and ability to provide a basic definition, demonstrating **General Contextual Understanding**.\n",
      "    *   `\"What is the meaning of chair in the context of conference? Give a short explanation.\"`: This prompt explicitly adds a context (\"in the context of conference\"), testing the LLM's ability to disambiguate words and provide context-specific meanings, demonstrating **Context-Specific Understanding**.\n",
      "3.  **Analyze \"transitive reasoning\" Prompts:**\n",
      "    *   `\"Prompt: We know that paper is equivalent to submission, and submission is equivalent to contribution. Is paper equivalent to contribution? Please answer yes or no. Give a short explanation.\"`: This prompt sets up a logical premise (A=B, B=C) and asks the LLM to infer the transitive relationship (A=C). This directly tests the LLM's **Logical Reasoning** capabilities, specifically the transitive property of equivalence.\n",
      "    *   `\"Prompt: We know that meta-reviewer is the subclass of reviewer, and reviewer is the subclass of co\"`: Although incomplete, this prompt clearly follows the same pattern as the previous one (A is_a B, B is_a C), aiming to test the transitive property for subclass relationships, further demonstrating **Logical Reasoning**.\n",
      "======================================================================\n",
      "\n",
      "ğŸ‰ğŸ‰ è§£ææˆåŠŸ! (æ–¹æ³•: regex)\n",
      "\n",
      "======================================================================\n",
      "é—®é¢˜:\n",
      "What LLM capabilities are being demonstrated or tested by the different prompts in this Python code snippet?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ç­”æ¡ˆ:\n",
      "This Python code snippet demonstrates and tests several key capabilities of a Large Language Model (LLM), primarily focusing on:\n",
      "\n",
      "1.  **Contextual Understanding and Knowledge Retrieval:** The LLM's ab...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "æ¨ç†æ­¥éª¤ (3):\n",
      "  1. **Identify the Core Operation:** The code repeatedly calls `llm.invoke(prompt).content`, indicating ...\n",
      "  2. **Analyze \"context learning\" Prompts:**\n",
      "    *   `\"Is MA_0000270 equivalent to NCI_C33736?\"`: This pr...\n",
      "  3. **Analyze \"transitive reasoning\" Prompts:**\n",
      "    *   `\"Prompt: We know that paper is equivalent to su...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ç®€åŒ–çš„å•æ ·æœ¬æµ‹è¯• - ä½¿ç”¨å®½æ¾çš„æ–‡æœ¬è§£æ\n",
    "import time\n",
    "import re\n",
    "\n",
    "agent_om_path = Path(\"/Users/xianhaoliu/Library/CloudStorage/OneDrive-Stibo/Project/Agent-OM/ontology-llm\")\n",
    "test_file = \"llm_matching.py\"\n",
    "file_path = agent_om_path / test_file\n",
    "\n",
    "print(f\"ğŸ“‚ æµ‹è¯•æ–‡ä»¶: {test_file}\")\n",
    "print(f\"ğŸ“ å®Œæ•´è·¯å¾„: {file_path}\")\n",
    "print(f\"âœ… æ–‡ä»¶å­˜åœ¨: {file_path.exists()}\")\n",
    "print()\n",
    "\n",
    "def parse_qa_from_text(text):\n",
    "    \"\"\"\n",
    "    ä»è‡ªç”±æ–‡æœ¬ä¸­è§£æQ&Aç»“æ„ï¼Œä¸è¦æ±‚ä¸¥æ ¼JSON\n",
    "    æ”¯æŒå¤šç§æ ¼å¼\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"question\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"reasoning_steps\": []\n",
    "    }\n",
    "    \n",
    "    # å°è¯•1: å…ˆå°è¯•JSONè§£æ\n",
    "    try:\n",
    "        # æ¸…ç†å¹¶æå–JSON\n",
    "        cleaned = text.strip()\n",
    "        cleaned = re.sub(r'^```json\\s*', '', cleaned)\n",
    "        cleaned = re.sub(r'^```\\s*', '', cleaned)\n",
    "        cleaned = re.sub(r'\\s*```$', '', cleaned)\n",
    "        cleaned = cleaned.strip()\n",
    "        \n",
    "        json_match = re.search(r'\\{.*\\}', cleaned, re.DOTALL)\n",
    "        if json_match:\n",
    "            cleaned = json_match.group(0)\n",
    "            cleaned = cleaned.replace('`', '\\'')\n",
    "            \n",
    "            data = json.loads(cleaned)\n",
    "            if 'question' in data and 'answer' in data:\n",
    "                return data, \"json\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # å°è¯•2: æ­£åˆ™è¡¨è¾¾å¼è§£æç»“æ„åŒ–æ–‡æœ¬\n",
    "    # åŒ¹é… Question: ... æˆ– é—®é¢˜: ...\n",
    "    question_patterns = [\n",
    "        r'[Qq]uestion\\s*[:ï¼š]\\s*(.+?)(?=\\n[Aa]nswer|å›ç­”|ç­”æ¡ˆ|$)',\n",
    "        r'é—®é¢˜\\s*[:ï¼š]\\s*(.+?)(?=\\n[Aa]nswer|å›ç­”|ç­”æ¡ˆ|$)',\n",
    "        r'##\\s*[Qq]uestion\\s*\\n(.+?)(?=\\n##|$)',\n",
    "        r'##\\s*é—®é¢˜\\s*\\n(.+?)(?=\\n##|$)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in question_patterns:\n",
    "        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            result[\"question\"] = match.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # åŒ¹é… Answer: ... æˆ– ç­”æ¡ˆ: ...\n",
    "    answer_patterns = [\n",
    "        r'[Aa]nswer\\s*[:ï¼š]\\s*(.+?)(?=\\n[Rr]easoning|æ¨ç†|æ­¥éª¤|$)',\n",
    "        r'[å›ç­”ç­”]\\s*[:ï¼š]\\s*(.+?)(?=\\n[Rr]easoning|æ¨ç†|æ­¥éª¤|$)',\n",
    "        r'##\\s*[Aa]nswer\\s*\\n(.+?)(?=\\n##|$)',\n",
    "        r'##\\s*[å›ç­”ç­”]\\s*\\n(.+?)(?=\\n##|$)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in answer_patterns:\n",
    "        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            result[\"answer\"] = match.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # åŒ¹é…æ¨ç†æ­¥éª¤ - åˆ—è¡¨æ ¼å¼\n",
    "    reasoning_patterns = [\n",
    "        r'[Rr]easoning [Ss]teps?\\s*[:ï¼š]\\s*\\n((?:\\d+\\.|\\-|\\*).+?)(?=\\n\\n|$)',\n",
    "        r'æ¨ç†æ­¥éª¤\\s*[:ï¼š]\\s*\\n((?:\\d+\\.|\\-|\\*).+?)(?=\\n\\n|$)',\n",
    "        r'##\\s*[Rr]easoning\\s*\\n((?:\\d+\\.|\\-|\\*).+?)(?=\\n##|$)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in reasoning_patterns:\n",
    "        match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            steps_text = match.group(1)\n",
    "            # æå–æ¯ä¸€æ­¥\n",
    "            steps = re.findall(r'(?:\\d+\\.|\\-|\\*)\\s*(.+?)(?=\\n\\d+\\.|\\n\\-|\\n\\*|$)', steps_text, re.DOTALL)\n",
    "            result[\"reasoning_steps\"] = [s.strip() for s in steps if s.strip()]\n",
    "            break\n",
    "    \n",
    "    # å¦‚æœquestionå’Œansweréƒ½æ‰¾åˆ°äº†ï¼Œè¿”å›æˆåŠŸ\n",
    "    if result[\"question\"] and result[\"answer\"]:\n",
    "        return result, \"regex\"\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "if file_path.exists():\n",
    "    # è¯»å–æ–‡ä»¶\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        code = f.read()\n",
    "    \n",
    "    # ä½¿ç”¨çŸ­ä»£ç ç‰‡æ®µ\n",
    "    code_snippet = code[:800]\n",
    "    \n",
    "    print(f\"ä»£ç ç‰‡æ®µé•¿åº¦: {len(code_snippet)} å­—ç¬¦\")\n",
    "    print(f\"ä»£ç é¢„è§ˆ:\\n{code_snippet[:200]}...\\n\")\n",
    "    \n",
    "    # å®½æ¾çš„æç¤ºè¯ - ä¸å¼ºåˆ¶JSONæ ¼å¼\n",
    "    flexible_prompt = f\"\"\"åŸºäºä»¥ä¸‹Pythonä»£ç ï¼Œç”Ÿæˆä¸€ä¸ªæŠ€æœ¯é—®ç­”ã€‚\n",
    "\n",
    "ä»£ç :\n",
    "```python\n",
    "{code_snippet}\n",
    "```\n",
    "\n",
    "è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼ˆå¯ä»¥ç”¨ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰ï¼š\n",
    "\n",
    "Question: [ä½ çš„é—®é¢˜]\n",
    "\n",
    "Answer: [ä½ çš„ç­”æ¡ˆ]\n",
    "\n",
    "Reasoning Steps:\n",
    "1. [æ¨ç†æ­¥éª¤1]\n",
    "2. [æ¨ç†æ­¥éª¤2]\n",
    "3. [æ¨ç†æ­¥éª¤3]\n",
    "\n",
    "æ³¨æ„ï¼šå¯ä»¥ä½¿ç”¨ä»»ä½•æ ¼å¼ï¼Œåªè¦åŒ…å«Questionã€Answerã€Reasoning Stepså³å¯ã€‚\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ æç¤ºè¯é•¿åº¦:\", len(flexible_prompt), \"å­—ç¬¦\")\n",
    "    print(\"ğŸ”„ ä½¿ç”¨å®½æ¾æ–‡æœ¬è§£æç­–ç•¥ï¼ˆä¸å¼ºåˆ¶JSONï¼‰\")\n",
    "    print()\n",
    "    print(\"â³ è°ƒç”¨Gemini API (å¯èƒ½éœ€è¦10-30ç§’)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = llm_service.generate_completion(flexible_prompt)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… APIå“åº”æˆåŠŸ! (è€—æ—¶: {elapsed:.1f}ç§’)\")\n",
    "        print(f\"ğŸ“Š å“åº”é•¿åº¦: {len(response)} å­—ç¬¦\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"åŸå§‹å“åº”:\")\n",
    "        print(response)\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # ä½¿ç”¨å®½æ¾è§£æ\n",
    "        data, method = parse_qa_from_text(response)\n",
    "        \n",
    "        if data:\n",
    "            print(f\"ğŸ‰ğŸ‰ è§£ææˆåŠŸ! (æ–¹æ³•: {method})\")\n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print(\"é—®é¢˜:\")\n",
    "            print(data.get('question', 'N/A'))\n",
    "            print(\"\\n\" + \"-\" * 70)\n",
    "            print(\"ç­”æ¡ˆ:\")\n",
    "            answer = data.get('answer', 'N/A')\n",
    "            print(answer[:200] + (\"...\" if len(answer) > 200 else \"\"))\n",
    "            print(\"\\n\" + \"-\" * 70)\n",
    "            print(f\"æ¨ç†æ­¥éª¤ ({len(data.get('reasoning_steps', []))}):\")\n",
    "            for i, step in enumerate(data.get('reasoning_steps', []), 1):\n",
    "                print(f\"  {i}. {step[:100]}{'...' if len(step) > 100 else ''}\")\n",
    "            print(\"=\" * 70)\n",
    "        else:\n",
    "            print(\"âŒ è§£æå¤±è´¥: æ— æ³•ä»å“åº”ä¸­æå–Q&Aç»“æ„\")\n",
    "            print(\"\\nğŸ’¡ å“åº”å¯èƒ½ä¸åŒ…å«å¿…éœ€çš„ Question/Answer å­—æ®µ\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"âŒ APIè°ƒç”¨å¤±è´¥! (è€—æ—¶: {elapsed:.1f}ç§’)\")\n",
    "        print(f\"é”™è¯¯: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"âŒ æ–‡ä»¶ä¸å­˜åœ¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6bb0d",
   "metadata": {},
   "source": [
    "## 6. ç®€åŒ–æµ‹è¯•ï¼šå•ä¸ªæ ·æœ¬ç”Ÿæˆ\n",
    "\n",
    "å…ˆæµ‹è¯•ç”Ÿæˆå•ä¸ªæ ·æœ¬ï¼Œç¡®è®¤APIå“åº”å’ŒJSONæ ¼å¼æ˜¯å¦æ­£å¸¸ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "835cd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Agent-OM é¡¹ç›®è·¯å¾„: /Users/xianhaoliu/Library/CloudStorage/OneDrive-Stibo/Project/Agent-OM/ontology-llm\n",
      "ğŸ¯ ç›®æ ‡: æ”¶é›† 10 ä¸ªæˆåŠŸçš„ Q&A å¯¹\n",
      "ğŸ”„ ç­–ç•¥: å®½æ¾æ–‡æœ¬è§£æï¼ˆä¸å¼ºåˆ¶JSONæ ¼å¼ï¼‰\n",
      "\n",
      "âœ… llm_matching.py\n",
      "âœ… util.py\n",
      "\n",
      "======================================================================\n",
      "ğŸš€ å¼€å§‹ç”Ÿæˆï¼Œç›®æ ‡ 10 ä¸ª...\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ [å°è¯• 1/20] [æˆåŠŸ 0/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.4s, 443å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "  å“åº”å†…å®¹:\n",
      "  å¥½çš„ï¼ŒåŸºäºæ‚¨æä¾›çš„Pythonä»£ç ç‰‡æ®µï¼Œæˆ‘å°†ç”Ÿæˆä»¥ä¸‹æŠ€æœ¯é—®ç­”ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "**Question 1: è¿™æ®µPythonä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿå®ƒå±•ç¤ºäº†LLMçš„å“ªäº›æ ¸å¿ƒèƒ½åŠ›ï¼Ÿ**\n",
      "\n",
      "Answer: è¿™æ®µä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯æ¼”ç¤ºå¦‚ä½•é€šè¿‡Pythonä»£ç ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œäº¤äº’ï¼Œå¹¶å±•ç¤ºLLMçš„ä¸¤ç§å…³é”®èƒ½åŠ›ï¼š**ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆContext Learningï¼‰** å’Œ **ä¼ é€’æ€§æ¨ç†ï¼ˆTransitive Reasoningï¼‰**ã€‚\n",
      "\n",
      "Reasoning Steps:\n",
      "1.  ä»£ç é€šè¿‡ `llm = config.llm` (å°½ç®¡ä»£ç ç‰‡æ®µä¸å®Œæ•´ï¼Œä½†å¯ä»¥æ¨æ–­) åˆå§‹åŒ–äº†ä¸€ä¸ªLLMå®¢æˆ·ç«¯æˆ–SDK...\n",
      "\n",
      "\n",
      "ğŸ“ [å°è¯• 2/20] [æˆåŠŸ 0/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.3s, 172å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "  å“åº”å†…å®¹:\n",
      "  å¥½çš„ï¼ŒåŸºäºæ‚¨æä¾›çš„Pythonä»£ç ç‰‡æ®µï¼Œæˆ‘å°†ç”Ÿæˆä¸€äº›æŠ€æœ¯é—®ç­”ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### **ä»£ç ç‰‡æ®µ 1: åç§°æ¸…ç†å‡½æ•° (å‡è®¾ä¸ºä¸€ä¸ªåä¸º `clean_name` çš„å‡½æ•°å†…éƒ¨)**\n",
      "\n",
      "```python\n",
      "    cleaned_name = re.sub(r'[^A-Za-z0-9]+', ' ', str(name))\n",
      "    # if no...\n",
      "\n",
      "\n",
      "ğŸ“ [å°è¯• 3/20] [æˆåŠŸ 0/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (12.7s, 2198å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "  å“åº”å†…å®¹:\n",
      "  å¥½çš„ï¼ŒåŸºäºæ‚¨æä¾›çš„Pythonä»£ç ï¼Œä»¥ä¸‹æ˜¯ç”Ÿæˆçš„æŠ€æœ¯é—®ç­”ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "**Question 1:** What is the primary mechanism used in this Python code to interact with a Large Language Model (LLM) and retrieve its response?\n",
      "\n",
      "**Answer:** The primary mechanism is calling the `invoke()` method on an `llm` object, passing a `prompt` string, and t...\n",
      "\n",
      "\n",
      "ğŸ“ [å°è¯• 4/20] [æˆåŠŸ 0/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.1s, 1430å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "ğŸ“ [å°è¯• 5/20] [æˆåŠŸ 0/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (10.4s, 847å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 1 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†LLMåœ¨å¤„ç†å“ªç§ç±»å‹çš„é€»è¾‘æ¨ç†ä»»åŠ¡ï¼Ÿ...\n",
      "\n",
      "ğŸ“ [å°è¯• 6/20] [æˆåŠŸ 1/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.1s, 409å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "ğŸ“ [å°è¯• 7/20] [æˆåŠŸ 1/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.1s, 1404å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "ğŸ“ [å°è¯• 8/20] [æˆåŠŸ 1/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.4s, 876å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "ğŸ“ [å°è¯• 9/20] [æˆåŠŸ 1/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (10.8s, 1036å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 2 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: ** è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’çš„å“ªäº›åŠŸèƒ½ï¼Œä»¥åŠå®ƒåœ¨æµ‹è¯•LLMçš„å“ªäº›æ¨ç†èƒ½åŠ›ï¼Ÿ\n",
      "\n",
      "**A...\n",
      "\n",
      "ğŸ“ [å°è¯• 10/20] [æˆåŠŸ 2/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.3s, 1798å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 3 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: `colorama.init(autoreset=True)` è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ...\n",
      "\n",
      "ğŸ“ [å°è¯• 11/20] [æˆåŠŸ 3/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.2s, 322å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 4 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: è¿™æ®µPythonä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ**\n",
      "\n",
      "**Answer:** è¿™æ®µPythonä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯é€šè¿‡å‘å¤§å‹...\n",
      "\n",
      "ğŸ“ [å°è¯• 12/20] [æˆåŠŸ 4/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.6s, 1171å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "ğŸ“ [å°è¯• 13/20] [æˆåŠŸ 4/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.1s, 1858å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 5 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: 1**\n",
      "What is the primary purpose of the provided Python code ...\n",
      "\n",
      "ğŸ“ [å°è¯• 14/20] [æˆåŠŸ 5/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.2s, 1618å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 6 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: è¿™æ®µä»£ç çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿå…·ä½“ä½¿ç”¨äº†Pandasåº“çš„å“ªäº›æ“ä½œï¼Ÿ...\n",
      "\n",
      "ğŸ“ [å°è¯• 15/20] [æˆåŠŸ 6/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.0s, 360å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 7 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: ** What is the primary purpose of the provided Python code s...\n",
      "\n",
      "ğŸ“ [å°è¯• 16/20] [æˆåŠŸ 7/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (10.0s, 283å­—ç¬¦)\n",
      "  âš ï¸  è§£æå¤±è´¥\n",
      "\n",
      "ğŸ“ [å°è¯• 17/20] [æˆåŠŸ 7/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.1s, 1614å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 8 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: è¿™æ®µä»£ç ç‰‡æ®µä¸»è¦å±•ç¤ºäº†ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’çš„å“ªäº›æ ¸å¿ƒèƒ½åŠ›ï¼Ÿ...\n",
      "\n",
      "ğŸ“ [å°è¯• 18/20] [æˆåŠŸ 8/10] - util.py\n",
      "  â³ è°ƒç”¨API... âœ… (11.9s, 165å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 9 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: åˆå§‹ä»£ç ç‰‡æ®µï¼ˆæœªå®Œæ•´æ˜¾ç¤ºå‡½æ•°å®šä¹‰ï¼‰çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿå®ƒå°†å“ªäº›æ•°æ®å†™å…¥CSVæ–‡ä»¶ï¼Œå¹¶ä»¥ä½•ç§æ ¼å¼å‘ˆç°ï¼Ÿ...\n",
      "\n",
      "ğŸ“ [å°è¯• 19/20] [æˆåŠŸ 9/10] - llm_matching.py\n",
      "  â³ è°ƒç”¨API... âœ… (10.9s, 1057å­—ç¬¦)\n",
      "  ğŸ‰ ç¬¬ 10 ä¸ªæˆåŠŸ! (è§£æ: regex)\n",
      "     Q: What is the primary purpose of the Python code snippet provi...\n",
      "\n",
      "âœ¨ å·²è¾¾åˆ°ç›®æ ‡ 10 ä¸ª!\n",
      "\n",
      "======================================================================\n",
      "ğŸ ç”Ÿæˆå®Œæˆ!\n",
      "âœ… æˆåŠŸ: 10 / 19 å°è¯•\n",
      "ğŸ“ˆ æˆåŠŸç‡: 52.6%\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ æ ·æœ¬é¢„è§ˆ:\n",
      "\n",
      "  1. llm_matching.py\n",
      "     Q: è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†LLMåœ¨å¤„ç†å“ªç§ç±»å‹çš„é€»è¾‘æ¨ç†ä»»åŠ¡ï¼Ÿ...\n",
      "     A: 20 å­—ç¬¦\n",
      "     æ­¥éª¤: 1 ä¸ª\n",
      "\n",
      "  2. llm_matching.py\n",
      "     Q: ** è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’çš„å“ªäº›åŠŸèƒ½ï¼Œä»¥åŠå®ƒåœ¨æµ‹è¯•LLMçš„å“ªäº›æ¨ç†èƒ½åŠ›ï¼Ÿ\n",
      "\n",
      "**Answer:** è¿™...\n",
      "     A: 74 å­—ç¬¦\n",
      "     æ­¥éª¤: 1 ä¸ª\n",
      "\n",
      "  3. util.py\n",
      "     Q: `colorama.init(autoreset=True)` è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ...\n",
      "     A: 201 å­—ç¬¦\n",
      "     æ­¥éª¤: 1 ä¸ª\n"
     ]
    }
   ],
   "source": [
    "# æ‰¹é‡ç”Ÿæˆ - ä½¿ç”¨å®½æ¾æ–‡æœ¬è§£æç­–ç•¥\n",
    "import time\n",
    "\n",
    "agent_om_path = Path(\"/Users/xianhaoliu/Library/CloudStorage/OneDrive-Stibo/Project/Agent-OM/ontology-llm\")\n",
    "target_files = [\"llm_matching.py\", \"util.py\"]\n",
    "\n",
    "TARGET_QA_COUNT = 5\n",
    "MAX_ATTEMPTS = 10\n",
    "\n",
    "print(f\"ğŸ“ Agent-OM é¡¹ç›®è·¯å¾„: {agent_om_path}\")\n",
    "print(f\"ğŸ¯ ç›®æ ‡: æ”¶é›† {TARGET_QA_COUNT} ä¸ªæˆåŠŸçš„ Q&A å¯¹\")\n",
    "print(f\"ğŸ”„ ç­–ç•¥: å®½æ¾æ–‡æœ¬è§£æï¼ˆä¸å¼ºåˆ¶JSONæ ¼å¼ï¼‰\")\n",
    "print()\n",
    "\n",
    "# å®½æ¾è§£æå‡½æ•°\n",
    "def parse_qa_flexible(text):\n",
    "    \"\"\"ä»è‡ªç”±æ–‡æœ¬ä¸­è§£æQ&Aï¼Œæ”¯æŒå¤šç§æ ¼å¼\"\"\"\n",
    "    result = {\"question\": \"\", \"answer\": \"\", \"reasoning_steps\": []}\n",
    "    \n",
    "    # å°è¯•JSONï¼ˆå¦‚æœLLMè‡ªå·±è¿”å›äº†JSONï¼‰\n",
    "    try:\n",
    "        cleaned = re.sub(r'^```(?:json)?\\s*', '', text.strip())\n",
    "        cleaned = re.sub(r'\\s*```$', '', cleaned).strip()\n",
    "        json_match = re.search(r'\\{.*\\}', cleaned, re.DOTALL)\n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0).replace('`', '\\''))\n",
    "            if 'question' in data and 'answer' in data:\n",
    "                return data, \"json\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # æ­£åˆ™è§£æ\n",
    "    # Question\n",
    "    for p in [r'[Qq]uestion\\s*[:ï¼š]\\s*(.+?)(?=\\n+[Aa]nswer|å›ç­”|ç­”æ¡ˆ|##|\\Z)',\n",
    "              r'é—®é¢˜\\s*[:ï¼š]\\s*(.+?)(?=\\n+[Aa]nswer|å›ç­”|ç­”æ¡ˆ|##|\\Z)']:\n",
    "        m = re.search(p, text, re.DOTALL | re.IGNORECASE)\n",
    "        if m:\n",
    "            result[\"question\"] = m.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # Answer\n",
    "    for p in [r'[Aa]nswer\\s*[:ï¼š]\\s*(.+?)(?=\\n+[Rr]easoning|æ¨ç†|æ­¥éª¤|##|\\Z)',\n",
    "              r'[å›ç­”ç­”æ¡ˆ]\\s*[:ï¼š]\\s*(.+?)(?=\\n+[Rr]easoning|æ¨ç†|æ­¥éª¤|##|\\Z)']:\n",
    "        m = re.search(p, text, re.DOTALL | re.IGNORECASE)\n",
    "        if m:\n",
    "            result[\"answer\"] = m.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # Reasoning Steps\n",
    "    for p in [r'[Rr]easoning\\s+[Ss]teps?\\s*[:ï¼š]?\\s*\\n((?:[\\d\\-\\*]\\.?\\s+.+?\\n?)+)',\n",
    "              r'æ¨ç†æ­¥éª¤\\s*[:ï¼š]?\\s*\\n((?:[\\d\\-\\*]\\.?\\s+.+?\\n?)+)']:\n",
    "        m = re.search(p, text, re.DOTALL | re.IGNORECASE)\n",
    "        if m:\n",
    "            steps_text = m.group(1)\n",
    "            steps = re.findall(r'[\\d\\-\\*]\\.?\\s+(.+?)(?=\\n[\\d\\-\\*]\\.?\\s+|\\Z)', steps_text, re.DOTALL)\n",
    "            result[\"reasoning_steps\"] = [s.strip() for s in steps if s.strip()]\n",
    "            break\n",
    "    \n",
    "    if result[\"question\"] and result[\"answer\"]:\n",
    "        # å¦‚æœæ²¡æœ‰æ¨ç†æ­¥éª¤ï¼Œè‡³å°‘ç”Ÿæˆä¸€ä¸ª\n",
    "        if not result[\"reasoning_steps\"]:\n",
    "            result[\"reasoning_steps\"] = [\"åŸºäºä»£ç åˆ†æå¾—å‡ºç»“è®º\"]\n",
    "        return result, \"regex\"\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# æ£€æŸ¥æ–‡ä»¶\n",
    "available_files = []\n",
    "for filename in target_files:\n",
    "    file_path = agent_om_path / filename\n",
    "    if file_path.exists():\n",
    "        available_files.append(filename)\n",
    "        print(f\"âœ… {filename}\")\n",
    "\n",
    "if not available_files:\n",
    "    print(\"âŒ æ²¡æœ‰å¯ç”¨æ–‡ä»¶\")\n",
    "    raise Exception(\"No files available\")\n",
    "\n",
    "print()\n",
    "\n",
    "training_samples = {\n",
    "    \"qa_pairs\": [],\n",
    "    \"metadata\": {\n",
    "        \"model\": \"gemini-2.5-flash\",\n",
    "        \"project\": \"Agent-OM\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"strategy\": \"flexible-text-parsing\"\n",
    "    }\n",
    "}\n",
    "\n",
    "attempt_count = 0\n",
    "file_index = 0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"ğŸš€ å¼€å§‹ç”Ÿæˆï¼Œç›®æ ‡ {TARGET_QA_COUNT} ä¸ª...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "while len(training_samples['qa_pairs']) < TARGET_QA_COUNT and attempt_count < MAX_ATTEMPTS:\n",
    "    attempt_count += 1\n",
    "    filename = available_files[file_index % len(available_files)]\n",
    "    file_index += 1\n",
    "    file_path = agent_om_path / filename\n",
    "    \n",
    "    current_count = len(training_samples['qa_pairs'])\n",
    "    print(f\"\\nğŸ“ [å°è¯• {attempt_count}/{MAX_ATTEMPTS}] [æˆåŠŸ {current_count}/{TARGET_QA_COUNT}] - {filename}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            code = f.read()\n",
    "        \n",
    "        # éšæœºé€‰æ‹©ä»£ç ç‰‡æ®µ\n",
    "        if len(code) > 800:\n",
    "            import random\n",
    "            start = random.randint(0, len(code) - 800)\n",
    "            code_snippet = code[start:start + 800]\n",
    "        else:\n",
    "            code_snippet = code\n",
    "        \n",
    "        # å®½æ¾æç¤ºè¯\n",
    "        prompt = f\"\"\"åŸºäºä»¥ä¸‹Pythonä»£ç ç”ŸæˆæŠ€æœ¯é—®ç­”ï¼š\n",
    "\n",
    "```python\n",
    "{code_snippet}\n",
    "```\n",
    "\n",
    "æ ¼å¼ï¼ˆå¯è‡ªç”±å‘æŒ¥ï¼Œåªè¦åŒ…å«ä»¥ä¸‹å†…å®¹ï¼‰ï¼š\n",
    "\n",
    "Question: [é—®é¢˜]\n",
    "\n",
    "Answer: [ç­”æ¡ˆ]\n",
    "\n",
    "Reasoning Steps:\n",
    "1. [æ­¥éª¤1]\n",
    "2. [æ­¥éª¤2]\n",
    "\"\"\"\n",
    "        \n",
    "        print(\"  â³ è°ƒç”¨API...\", end=\" \", flush=True)\n",
    "        start_time = time.time()\n",
    "        response = llm_service.generate_completion(prompt)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"âœ… ({elapsed:.1f}s, {len(response)}å­—ç¬¦)\")\n",
    "        \n",
    "        # è§£æ\n",
    "        data, method = parse_qa_flexible(response)\n",
    "        \n",
    "        if data:\n",
    "            data['source_file'] = filename\n",
    "            data['attempt_number'] = attempt_count\n",
    "            training_samples['qa_pairs'].append(data)\n",
    "            \n",
    "            current_count = len(training_samples['qa_pairs'])\n",
    "            print(f\"  ğŸ‰ ç¬¬ {current_count} ä¸ªæˆåŠŸ! (è§£æ: {method})\")\n",
    "            print(f\"     Q: {data['question'][:60]}...\")\n",
    "            \n",
    "            if current_count >= TARGET_QA_COUNT:\n",
    "                print(f\"\\nâœ¨ å·²è¾¾åˆ°ç›®æ ‡ {TARGET_QA_COUNT} ä¸ª!\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"  âš ï¸  è§£æå¤±è´¥\")\n",
    "            if attempt_count <= 3:\n",
    "                print(f\"\\n  å“åº”å†…å®¹:\\n  {response[:300]}...\\n\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ é”™è¯¯: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(f\"ğŸ ç”Ÿæˆå®Œæˆ!\")\n",
    "print(f\"âœ… æˆåŠŸ: {len(training_samples['qa_pairs'])} / {attempt_count} å°è¯•\")\n",
    "print(f\"ğŸ“ˆ æˆåŠŸç‡: {len(training_samples['qa_pairs'])/attempt_count*100:.1f}%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if training_samples['qa_pairs']:\n",
    "    print(f\"\\nğŸ“‹ æ ·æœ¬é¢„è§ˆ:\")\n",
    "    for i, qa in enumerate(training_samples['qa_pairs'][:3], 1):\n",
    "        print(f\"\\n  {i}. {qa['source_file']}\")\n",
    "        print(f\"     Q: {qa['question'][:70]}...\")\n",
    "        print(f\"     A: {len(qa['answer'])} å­—ç¬¦\")\n",
    "        print(f\"     æ­¥éª¤: {len(qa['reasoning_steps'])} ä¸ª\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2066d83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qa_pairs': [{'question': 'è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†LLMåœ¨å¤„ç†å“ªç§ç±»å‹çš„é€»è¾‘æ¨ç†ä»»åŠ¡ï¼Ÿ',\n",
       "   'answer': 'è¿™æ®µä»£ç ä¸»è¦æ¼”ç¤ºäº†LLMåœ¨å¤„ç†**ä¼ é€’æ€§',\n",
       "   'reasoning_steps': ['*'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 5},\n",
       "  {'question': '** è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’çš„å“ªäº›åŠŸèƒ½ï¼Œä»¥åŠå®ƒåœ¨æµ‹è¯•LLMçš„å“ªäº›æ¨ç†èƒ½åŠ›ï¼Ÿ\\n\\n**Answer:** è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†å¦‚ä½•å‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘é€ç»“æ„åŒ–çš„æ–‡æœ¬æç¤ºï¼ˆpromptï¼‰å¹¶è·å–å…¶å“åº”å†…å®¹ã€‚å®ƒç‰¹åˆ«å…³æ³¨æµ‹è¯•LLMçš„ä¸¤ç§æ ¸å¿ƒæ¨ç†èƒ½åŠ›ï¼š**ä¼ é€’æ€§æ¨ç†ï¼ˆTransitive Reasoningï¼‰** å’Œ **è‡ªæˆ‘çº æ­£ï¼ˆSelf-Correctionï¼‰**ã€‚\\n\\n**Reasoning Steps:**\\n\\n1.  **åˆ†ææ ¸å¿ƒäº¤äº’æ¨¡å¼ï¼š** ä»£ç ä¸­åå¤å‡ºç°çš„ `print(llm.invoke(prompt).content)` æ¨¡å¼è¡¨æ˜ï¼Œå®ƒé€šè¿‡è°ƒç”¨ `llm` å¯¹è±¡çš„ `invoke` æ–¹æ³•ï¼Œå°†ä¸€ä¸ª `prompt` å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥å‘é€ç»™LLMï¼Œç„¶åæ‰“å°LLMè¿”å›çš„ `content`ï¼ˆå³æ¨¡å‹çš„',\n",
       "   'answer': '** è¿™æ®µPythonä»£ç ä¸»è¦æ¼”ç¤ºäº†å¦‚ä½•å‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘é€ç»“æ„åŒ–çš„æ–‡æœ¬æç¤ºï¼ˆpromptï¼‰å¹¶è·å–å…¶å“åº”å†…å®¹ã€‚å®ƒç‰¹åˆ«å…³æ³¨æµ‹è¯•LLMçš„ä¸¤ç§æ ¸å¿ƒ',\n",
       "   'reasoning_steps': ['åŸºäºä»£ç åˆ†æå¾—å‡ºç»“è®º'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 9},\n",
       "  {'question': '`colorama.init(autoreset=True)` è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ',\n",
       "   'answer': 'è¿™è¡Œä»£ç çš„ä½œç”¨æ˜¯åˆå§‹åŒ– Colorama åº“ï¼Œå¹¶è®¾ç½® `autoreset=True` å‚æ•°ã€‚\\n`autoreset=True` çš„ä½œç”¨æ˜¯ç¡®ä¿åœ¨æ¯æ¬¡æ‰“å°æ“ä½œï¼ˆä¾‹å¦‚ä½¿ç”¨ `print()` å‡½æ•°ï¼‰ä¹‹åï¼Œç»ˆç«¯çš„é¢œè‰²å’Œæ ·å¼ä¼šè‡ªåŠ¨é‡ç½®ä¸ºé»˜è®¤å€¼ã€‚è¿™æ„å‘³ç€ä½ ä¸éœ€è¦æ‰‹åŠ¨åœ¨æ¯æ¬¡æ‰“å°çš„æœ«å°¾æ·»åŠ  `colorama.Style.RESET_ALL` æ¥æ¸…é™¤ä¹‹å‰è®¾ç½®çš„é¢œè‰²ï¼Œä»è€Œç®€åŒ–äº†ä»£ç å¹¶é¿å…äº†é¢œè‰²æ³„éœ²åˆ°åç»­è¾“å‡ºçš„é—®é¢˜ã€‚',\n",
       "   'reasoning_steps': ['ä»£'],\n",
       "   'source_file': 'util.py',\n",
       "   'attempt_number': 10},\n",
       "  {'question': 'è¿™æ®µPythonä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ**\\n\\n**Answer:** è¿™æ®µPythonä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯é€šè¿‡å‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘é€ä¸åŒç±»å‹çš„æç¤ºï¼ˆpromptï¼‰ï¼Œæ¥æµ‹è¯•å’Œå±•ç¤ºLLMçš„å¤šç§èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡ç†è§£ã€ä¼ é€’æ€§æ¨ç†ä»¥åŠæš—ç¤ºçš„è‡ªæˆ‘çº æ­£èƒ½åŠ›ã€‚\\n\\n**Reasoning Steps:**\\n1.  **è¯†åˆ«æ ¸å¿ƒæ“ä½œ:** ä»£ç ä¸­åå¤å‡ºç°çš„ `print(llm.invoke(prompt).content)` æ¨¡å¼è¡¨æ˜ï¼Œå®ƒæ­£åœ¨è°ƒç”¨ä¸€ä¸ªåä¸º `llm` çš„å¯¹è±¡ï¼ˆä»£è¡¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ï¼Œå¹¶å‘å…¶ä¼ é€’ä¸åŒçš„ `prompt` å­—ç¬¦ä¸²ï¼Œç„¶åæ‰“å°',\n",
       "   'answer': '** è¿™æ®µPythonä»£ç ç‰‡æ®µçš„ä¸»è¦ç›®çš„æ˜¯é€šè¿‡å‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘é€ä¸åŒç±»å‹çš„æç¤ºï¼ˆpromptï¼‰ï¼Œæ¥æµ‹è¯•å’Œå±•ç¤ºLLMçš„å¤šç§èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡ç†è§£ã€ä¼ é€’æ€§',\n",
       "   'reasoning_steps': ['åŸºäºä»£ç åˆ†æå¾—å‡ºç»“è®º'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 11},\n",
       "  {'question': '1**\\nWhat is the primary purpose of the provided Python code snippet?\\n\\n**Answer:**\\nThe primary purpose of this Python code snippet is to demonstrate how to interact with a Large Language Model (LLM) by sending various types of prompts and printing the LLM\\'s generated responses. It showcases different capabilities of the LLM, such as knowledge retrieval, contextual understanding, and transitive reasoning.\\n\\n**Reasoning Steps:**\\n1.  The line `llm = config.llm` indicates that an LLM object is being initialized or retrieved.\\n2.  Multiple `prompt` variables are defined with different questions or statements.\\n3.  The line `print(llm.invoke(prompt).content)` is repeatedly used, which is the standard way to send a prompt to an LLM and print its textual output.\\n\\n---\\n\\n**Question: 2**\\nWhat LLM capabilities are explicitly being tested or demonstrated through the different prompts in the code?\\n\\n**Answer:**\\nThe code demonstrates the following LLM capabilities:\\n\\n*   **Knowledge Retrieval / Entity Equivalence:** Demonstrated by `prompt = \"Is MA_0000270 equivalent to NCI_C33736?\"`, which asks the LLM to recall or infer specific factual relationships.\\n*   **Basic Definition:** Demonstrated by `prompt = \"What is the meaning of chair? Give a short explanation.\"`, testing the LLM\\'s ability to provide general definitions.\\n*   **Contextual Understanding / Context Learning:** Demonstrated by comparing `prompt = \"What is the meaning of chair?\"` with `prompt = \"What is the meaning of chair in the context of conference?\"`. This tests the LLM\\'s ability to adapt its understanding and response based on specific context.\\n*   **Transitive Reasoning:** Demonstrated by `prompt = \"Prompt: We know that paper is equivalent to submission, and submission is equivalent to contribution. Is paper equivalent to contribution?',\n",
       "   'answer': '**\\nThe primary purpose of this Python code snippet is to demonstrate how to interact with a Large Language Model (LLM) by sending various types of prompts and printing the LLM\\'s generated responses. It showcases different capabilities of the LLM, such as knowledge retrieval, contextual understanding, and transitive reasoning.\\n\\n**Reasoning Steps:**\\n1.  The line `llm = config.llm` indicates that an LLM object is being initialized or retrieved.\\n2.  Multiple `prompt` variables are defined with different questions or statements.\\n3.  The line `print(llm.invoke(prompt).content)` is repeatedly used, which is the standard way to send a prompt to an LLM and print its textual output.\\n\\n---\\n\\n**Question: 2**\\nWhat LLM capabilities are explicitly being tested or demonstrated through the different prompts in the code?\\n\\n**Answer:**\\nThe code demonstrates the following LLM capabilities:\\n\\n*   **Knowledge Retrieval / Entity Equivalence:** Demonstrated by `prompt = \"Is MA_0000270 equivalent to NCI_C33736?\"`, which asks the LLM to recall or infer specific factual relationships.\\n*   **Basic Definition:** Demonstrated by `prompt = \"What is the meaning of chair? Give a short explanation.\"`, testing the LLM\\'s ability to provide general definitions.\\n*   **Contextual Understanding / Context Learning:** Demonstrated by comparing `prompt = \"What is the meaning of chair?\"` with `prompt = \"What is the meaning of chair in the context of conference?\"`. This tests the LLM\\'s ability to adapt its understanding and response based on specific context.\\n*   **Transitive Reasoning:** Demonstrated by `prompt = \"Prompt: We know that paper is equivalent to submission, and submission is equivalent to contribution. Is paper equivalent to contribution?',\n",
       "   'reasoning_steps': ['åŸºäºä»£ç åˆ†æå¾—å‡ºç»“è®º'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 13},\n",
       "  {'question': 'è¿™æ®µä»£ç çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿå…·ä½“ä½¿ç”¨äº†Pandasåº“çš„å“ªäº›æ“ä½œï¼Ÿ',\n",
       "   'answer': 'è¿™æ®µä»£ç çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»ä¸¤ä¸ªä¸åŒçš„CSVæ–‡ä»¶ä¸­è¯»å–æ•°æ®ï¼Œç„¶åæ ¹æ®ä¸¤ä¸ªå…±åŒçš„åˆ—ï¼ˆ\"Entity1\"å’Œ\"Entity2\"ï¼‰å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†è¿›è¡Œ**å†…è¿æ¥ï¼ˆinner mergeï¼‰**æ“ä½œï¼Œä»¥æ‰¾å‡ºå®ƒä»¬ä¹‹é—´å…±åŒçš„æ¡ç›®ã€‚\\n\\nå…·ä½“ä½¿ç”¨çš„Pandasæ“ä½œåŒ…æ‹¬ï¼š\\n1.  `pd.read_csv()`: ç”¨äºä»CSVæ–‡ä»¶åŠ è½½æ•°æ®åˆ°DataFrameã€‚\\n2.  `pd.merge()`: ç”¨äºæ‰§è¡Œä¸¤ä¸ªDataFrameä¹‹é—´çš„åˆå¹¶ï¼ˆè¿æ¥ï¼‰æ“ä½œã€‚',\n",
       "   'reasoning_steps': ['ä»£'],\n",
       "   'source_file': 'util.py',\n",
       "   'attempt_number': 14},\n",
       "  {'question': \"** What is the primary purpose of the provided Python code snippet?\\n\\n**Answer:** The primary purpose of this Python code snippet is to demonstrate different capabilities of a Large Language Model (LLM) by sending various types of prompts and printing their responses. It showcases the LLM's ability to handle basic\",\n",
       "   'answer': \"** The primary purpose of this Python code snippet is to demonstrate different capabilities of a Large Language Model (LLM) by sending various types of prompts and printing their responses. It showcases the LLM's ability to handle basic\",\n",
       "   'reasoning_steps': ['åŸºäºä»£ç åˆ†æå¾—å‡ºç»“è®º'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 15},\n",
       "  {'question': 'è¿™æ®µä»£ç ç‰‡æ®µä¸»è¦å±•ç¤ºäº†ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’çš„å“ªäº›æ ¸å¿ƒèƒ½åŠ›ï¼Ÿ',\n",
       "   'answer': 'è¿™æ®µä»£ç ç‰‡æ®µä¸»è¦å±•ç¤ºäº†LLMåœ¨å¤„ç†è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰æ–¹é¢çš„å¤šç§æ ¸å¿ƒèƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼šè¯­ä¹‰ç­‰ä»·åˆ¤æ–­ã€è¯ä¹‰è§£é‡Šï¼ˆé€šç”¨ä¸ä¸Šä¸‹æ–‡ç›¸å…³ï¼‰ã€ä»¥åŠåŸºäºå·²çŸ¥äº‹å®çš„ä¼ é€’æ€§',\n",
       "   'reasoning_steps': ['*'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 17},\n",
       "  {'question': 'åˆå§‹ä»£ç ç‰‡æ®µï¼ˆæœªå®Œæ•´æ˜¾ç¤ºå‡½æ•°å®šä¹‰ï¼‰çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿå®ƒå°†å“ªäº›æ•°æ®å†™å…¥CSVæ–‡ä»¶ï¼Œå¹¶ä»¥ä½•ç§æ ¼å¼å‘ˆç°ï¼Ÿ',\n",
       "   'answer': 'è¯¥åˆå§‹ä»£ç ç‰‡æ®µçš„ä¸»è¦åŠŸèƒ½æ˜¯å°†æ€§èƒ½è¯„ä¼°æŒ‡æ ‡å†™å…¥ä¸€ä¸ªCSVæ–‡ä»¶ã€‚å®ƒå†™å…¥çš„æ•°æ®åŒ…æ‹¬ï¼š\\n1.  `alignment`ï¼šä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œ',\n",
       "   'reasoning_steps': ['åŸºäºä»£ç åˆ†æå¾—å‡ºç»“è®º'],\n",
       "   'source_file': 'util.py',\n",
       "   'attempt_number': 18},\n",
       "  {'question': 'What is the primary purpose of the Python code snippet provided?',\n",
       "   'answer': 'The primary purpose of this Python code snippet is to demonstrate how to interact with a Large Language Model (LLM) by sending various types of prompts and printing its responses, specifically focusing on testing its reasoning capabilities like contextual understanding, transitive reasoning, and implicitly, self-correction.',\n",
       "   'reasoning_steps': ['T'],\n",
       "   'source_file': 'llm_matching.py',\n",
       "   'attempt_number': 19}],\n",
       " 'metadata': {'model': 'gemini-2.5-flash',\n",
       "  'project': 'Agent-OM',\n",
       "  'timestamp': '2025-12-18T13:37:57.251543',\n",
       "  'strategy': 'flexible-text-parsing'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a961fa",
   "metadata": {},
   "source": [
    "## 7. ä¿å­˜è®­ç»ƒæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687c60c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜\n",
      "ğŸ“ æ–‡ä»¶è·¯å¾„: outputs/agent-om/training_samples_20251218_134615.json\n",
      "ğŸ“Š ç»Ÿè®¡:\n",
      "   - Q&A å¯¹æ•°: 10\n",
      "   - æ–‡ä»¶å¤§å°: 9.73 KB\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "output_dir = Path(\"outputs/agent-om\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ä¿å­˜ä¸º JSON\n",
    "output_file = output_dir / f\"training_samples_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_samples, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜\")\n",
    "print(f\"ğŸ“ æ–‡ä»¶è·¯å¾„: {output_file}\")\n",
    "print(f\"ğŸ“Š ç»Ÿè®¡:\")\n",
    "print(f\"   - Q&A å¯¹æ•°: {len(training_samples['qa_pairs'])}\")\n",
    "print(f\"   - æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83ca57",
   "metadata": {},
   "source": [
    "## 8. æµ‹è¯•æ€»ç»“\n",
    "\n",
    "### âœ… æµ‹è¯•ç»“æœ\n",
    "\n",
    "æ‰€æœ‰æµ‹è¯•å‡å·²å®Œæˆï¼ŒéªŒè¯äº†ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "\n",
    "1. **Gemini API è¿æ¥** - æˆåŠŸåˆå§‹åŒ–å¹¶è¿æ¥\n",
    "2. **åŸºç¡€æ–‡æœ¬ç”Ÿæˆ** - ç”Ÿæˆæµç•…çš„ä¸­æ–‡è§£é‡Š\n",
    "3. **Q&A å¯¹ç”Ÿæˆ** - èƒ½å¤ŸåŸºäºä»£ç ç”Ÿæˆé«˜è´¨é‡é—®ç­”\n",
    "4. **è®¾è®¡æ–¹æ¡ˆç”Ÿæˆ** - ç”Ÿæˆç»“æ„åŒ–çš„æ¶æ„è®¾è®¡\n",
    "5. **Agent-OM é›†æˆ** - æˆåŠŸä¸ºçœŸå®é¡¹ç›®ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
    "\n",
    "### ğŸ“Š å…³é”®æŒ‡æ ‡\n",
    "\n",
    "- **LLM Provider**: Google Gemini 2.5 Flash\n",
    "- **å¹³å‡å“åº”æ—¶é—´**: 10-30ç§’/è¯·æ±‚\n",
    "- **è¾“å‡ºè´¨é‡**: é«˜è´¨é‡ç»“æ„åŒ–æ•°æ®\n",
    "- **JSON æ ¼å¼**: éœ€è¦æ¸…ç†å¤„ç†ä½†æ€»ä½“ç¨³å®š\n",
    "\n",
    "### ğŸ¯ ä¸‹ä¸€æ­¥\n",
    "\n",
    "1. ä¼˜åŒ–æ‰¹é‡ç”Ÿæˆæ€§èƒ½ï¼ˆå¹¶å‘å¤„ç†ï¼‰\n",
    "2. æ‰©å±•åˆ°æ›´å¤š Agent-OM æ–‡ä»¶\n",
    "3. å®æ–½äººå·¥å®¡æ ¸æµç¨‹\n",
    "4. å¼€å§‹ Qwen 2.5 æ¨¡å‹å¾®è°ƒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
