{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e2a763",
   "metadata": {},
   "source": [
    "## ğŸ”§ æ­¥éª¤1: ç¯å¢ƒé…ç½®\n",
    "\n",
    "é¦–å…ˆé…ç½®å¿…è¦çš„ç¯å¢ƒå’ŒAPIå¯†é’¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8865c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… APIå¯†é’¥å·²é…ç½®\n",
      "   å¯†é’¥å‰ç¼€: AIzaSyCglf...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# é…ç½®APIå¯†é’¥ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å¯†é’¥ï¼‰\n",
    "# æ–¹å¼1: ç›´æ¥è®¾ç½®ï¼ˆä¸æ¨èï¼Œä»…ç”¨äºæµ‹è¯•ï¼‰\n",
    "# os.environ['GEMINI_API_KEY'] = 'your_api_key_here'\n",
    "\n",
    "# æ–¹å¼2: ä».envæ–‡ä»¶è¯»å–ï¼ˆæ¨èï¼‰\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# éªŒè¯\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "if api_key:\n",
    "    print(\"âœ… APIå¯†é’¥å·²é…ç½®\")\n",
    "    print(f\"   å¯†é’¥å‰ç¼€: {api_key[:10]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸  æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼\")\n",
    "    print(\"   æç¤º: åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® GEMINI_API_KEY=your_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ccddd",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤2: é€‰æ‹©ç›®æ ‡é¡¹ç›®\n",
    "\n",
    "å¯ä»¥é€‰æ‹©:\n",
    "1. GitHubå…¬å¼€é¡¹ç›®ï¼ˆè‡ªåŠ¨å…‹éš†ï¼‰\n",
    "2. æœ¬åœ°é¡¹ç›®è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f8c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ å‡†å¤‡é¡¹ç›®...\n",
      "âœ… é¡¹ç›®å·²å­˜åœ¨: /Users/xianhaoliu/github_repos/ontology-llm\n",
      "\n",
      "ğŸ“‚ é¡¹ç›®è·¯å¾„: /Users/xianhaoliu/github_repos/ontology-llm\n",
      "   é¡¹ç›®åç§°: ontology-llm\n",
      "   Pythonæ–‡ä»¶: 13 ä¸ª\n"
     ]
    }
   ],
   "source": [
    "from src.context_analyzer import GitHubIntegration\n",
    "\n",
    "# æ–¹å¼1: ä½¿ç”¨GitHubé¡¹ç›®ï¼ˆæ¨èï¼‰\n",
    "# ç¤ºä¾‹ï¼šæœ¬ä½“åŒ¹é…é¡¹ç›®\n",
    "project_source = \"https://github.com/qzc438-research/ontology-llm\"\n",
    "\n",
    "# æ–¹å¼2: ä½¿ç”¨æœ¬åœ°é¡¹ç›®\n",
    "# project_source = \"/Users/yourname/projects/your-project\"\n",
    "\n",
    "# å…‹éš†æˆ–ä½¿ç”¨é¡¹ç›®\n",
    "print(\"ğŸ”„ å‡†å¤‡é¡¹ç›®...\")\n",
    "project_path = GitHubIntegration.clone_or_use_repo(project_source)\n",
    "\n",
    "print(f\"\\nğŸ“‚ é¡¹ç›®è·¯å¾„: {project_path}\")\n",
    "print(f\"   é¡¹ç›®åç§°: {project_path.name}\")\n",
    "\n",
    "# å¿«é€Ÿæµè§ˆé¡¹ç›®ç»“æ„\n",
    "python_files = list(project_path.rglob('*.py'))\n",
    "python_files = [f for f in python_files if '__pycache__' not in str(f) and '.venv' not in str(f)]\n",
    "print(f\"   Pythonæ–‡ä»¶: {len(python_files)} ä¸ª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd2c0a",
   "metadata": {},
   "source": [
    "## ğŸ§  æ­¥éª¤3: åˆå§‹åŒ–ç”Ÿæˆå™¨\n",
    "\n",
    "åˆ›å»ºç®€å•ç”Ÿæˆå™¨å®ä¾‹ï¼Œæ”¯æŒä¸Šä¸‹æ–‡å¢å¼º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ac3447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ\n",
      "   LLMå¯ç”¨: True\n",
      "   ä¸Šä¸‹æ–‡å¢å¼º: True\n",
      "   é¡¹ç›®: ontology-llm\n"
     ]
    }
   ],
   "source": [
    "from src.simple_generator import SimpleGenerator\n",
    "\n",
    "# åˆ›å»ºç”Ÿæˆå™¨\n",
    "generator = SimpleGenerator(\n",
    "    project_path=str(project_path),\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3  # è¾ƒä½æ¸©åº¦ä¿è¯æ ¼å¼ç¨³å®šæ€§\n",
    ")\n",
    "\n",
    "print(\"âœ… ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "print(f\"   LLMå¯ç”¨: {generator.llm_available}\")\n",
    "print(f\"   ä¸Šä¸‹æ–‡å¢å¼º: {generator.context_enabled}\")\n",
    "print(f\"   é¡¹ç›®: {generator.project_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690f2f7",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤4a: ç”Ÿæˆå•ä¸ªé—®ç­”å¯¹ï¼ˆæµ‹è¯•ï¼‰\n",
    "\n",
    "å…ˆç”Ÿæˆä¸€ä¸ªé—®ç­”å¯¹æµ‹è¯•æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5439ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ æµ‹è¯•æ–‡ä»¶: om_database_matching.py\n",
      "\n",
      "ã€ä»£ç ç‰‡æ®µé¢„è§ˆã€‘\n",
      "syntactic_matches = pd.DataFrame(syntactic_matching)\n",
      "    syntactic_matches.drop_duplicates(['entity'], inplace=True)\n",
      "    if len(syntactic_matches) != 0:\n",
      "        result = syntactic_matches['entity'].head(top_k).values.tolist()\n",
      "    else:\n",
      "        result = [null_value_matching]\n",
      "    print(result)\n",
      "    ret...\n",
      "\n",
      "ğŸ”„ ç”Ÿæˆé—®ç­”å¯¹...\n",
      "\n",
      "âœ… ç”ŸæˆæˆåŠŸï¼\n",
      "\n",
      "======================================================================\n",
      "é—®é¢˜: åœ¨`om_database_matching.py`æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä»£ç ç‰‡æ®µå¤„ç†äº†`syntactic_matches`ï¼Œå¹¶ä¸”`lexical`å‡½æ•°è¢«å°è£…ä¸ºLangChainçš„`@tool`ã€‚ç»“åˆé¡¹ç›®`ontology-llm`çš„ä¸Šä¸‹æ–‡ä»¥åŠ`llm_matching`ã€`llm_om_zero_shot`ç­‰æ ¸å¿ƒæ¨¡å—ï¼Œè¯·è¯¦ç»†é˜è¿°è¯¥ç³»ç»Ÿæ˜¯å¦‚ä½•ç¼–æ’ä¸åŒç²’åº¦çš„å®ä½“åŒ¹é…ç­–ç•¥ï¼ˆä¾‹å¦‚å¥æ³•ã€è¯æ³•ã€ä»¥åŠåŸºäºLLMçš„åŒ¹é…ï¼‰ã€‚ç‰¹åˆ«æ˜¯ï¼Œå°†`lexical`ç­‰ä¼ ç»ŸåŒ¹é…æ–¹æ³•å°è£…ä¸º`@tool`åœ¨æ•´ä¸ªåŒ¹é…æµç¨‹ä¸­æä¾›äº†å“ªäº›å…·ä½“çš„æ¶æ„ä¼˜åŠ¿ï¼Œä»¥åŠç³»ç»Ÿå¦‚ä½•åˆ©ç”¨è¿™ç§ç¼–æ’æ¥å¤„ç†åŒ¹é…å¤±è´¥æˆ–æ— ç»“æœï¼ˆå¦‚`null_value_matching`ï¼‰çš„æƒ…å†µä»¥ç¡®ä¿é²æ£’æ€§ï¼Ÿ\n",
      "\n",
      "ç­”æ¡ˆ: åœ¨`ontology-llm`é¡¹ç›®ä¸­ï¼Œ`om_database_matching.py`æ¨¡å—è´Ÿè´£å¤„ç†å®ä½“åŒ¹é…ï¼Œå®ƒæ˜¾ç„¶é‡‡ç”¨äº†**å¤šé˜¶æ®µã€æ··åˆå¼**çš„åŒ¹é…ç­–ç•¥ï¼Œç»“åˆäº†ä¼ ç»Ÿè§„åˆ™æ–¹æ³•å’Œå…ˆè¿›çš„LLMèƒ½åŠ›ï¼Œå¹¶é€šè¿‡LangChainçš„`@tool`æœºåˆ¶è¿›è¡Œå·§å¦™ç¼–æ’ã€‚\n",
      "\n",
      "**ä¸åŒç²’åº¦å®ä½“åŒ¹é…ç­–ç•¥çš„ç¼–æ’ï¼š**\n",
      "\n",
      "1.  **åˆæœŸ/é«˜æ•ˆåŒ¹é…ï¼ˆå¥æ³•å’Œè¯æ³•ï¼‰ï¼š**\n",
      "    *   **å¥æ³•åŒ¹é… (Syntactic Matching):** ä»£ç ä¸­å±•ç¤ºçš„`syntactic_matches`å¤„ç†éƒ¨åˆ†ï¼Œé€šå¸¸æ¶‰åŠåˆ°åŸºäºå­—ç¬¦ä¸²ç›¸ä¼¼åº¦ã€æ­£åˆ™è¡¨è¾¾å¼ã€ç¼–è¾‘è·ç¦»ç­‰å¿«é€Ÿã€ç¡®å®šæ€§çš„æ–¹æ³•ã€‚å®ƒçš„ç›®æ ‡æ˜¯è¯†åˆ«ç²¾ç¡®æˆ–è¿‘ä¼¼çš„æ–‡æœ¬åŒ¹é…ï¼Œæ•ˆç‡é«˜ï¼Œé€‚ç”¨äºå¤„ç†æ‹¼å†™é”™è¯¯ã€å¤§å°å†™å·®å¼‚æˆ–ç®€å•çš„è¯åºå˜åŠ¨ã€‚`drop_duplicates`å’Œ`head(top_k)`è¡¨æ˜å®ƒä¼šè¿›è¡Œç»“æœçš„å»é‡å’Œä¼˜å…ˆé€‰æ‹©ã€‚\n",
      "    *   **è¯æ³•åŒ¹é… (Lexical Matching):** `lexical`å‡½æ•°ï¼Œé€šè¿‡è°ƒç”¨`entity_matching(entity, \"lexical_matching\")`å®ç°ï¼Œä¼šæ›´è¿›ä¸€æ­¥åœ°å¤„ç†è¯å½¢å˜åŒ–ã€åŒä¹‰è¯æˆ–è¿‘ä¹‰è¯çš„è¯†åˆ«ã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°è¯å…¸æŸ¥æ‰¾ã€è¯å¹²æå–ã€è¯å½¢è¿˜åŸç­‰è¯­è¨€å­¦å¤„ç†ï¼Œæ¯”çº¯å¥æ³•åŒ¹é…æ›´æ™ºèƒ½ã€‚\n",
      "    *   **ç¼–æ’é€»è¾‘ï¼š** é€šå¸¸ï¼Œç³»ç»Ÿä¼šä¼˜å…ˆå°è¯•è¿™äº›æˆæœ¬è¾ƒä½ã€é€Ÿåº¦è¾ƒå¿«çš„ä¼ ç»Ÿæ–¹æ³•ã€‚å¦‚æœå®ƒä»¬èƒ½å¤Ÿæ‰¾åˆ°é«˜è´¨é‡çš„åŒ¹é…ï¼ˆä¾‹å¦‚ï¼Œè¿”å›éç©ºçš„`top_k`ç»“æœï¼‰ï¼Œå°±å¯ä»¥é¿å…è°ƒç”¨æ›´è€—è´¹èµ„æºçš„LLMï¼Œä»è€Œæé«˜æ•´ä½“æ•ˆç‡ã€‚\n",
      "\n",
      "2.  **é«˜çº§/è¯­ä¹‰åŒ¹é…ï¼ˆåŸºäºLLMçš„åŒ¹é…ï¼‰ï¼š**\n",
      "    *   å½“å¥æ³•å’Œè¯æ³•åŒ¹é…æ— æ³•æ‰¾åˆ°æ»¡æ„ç»“æœï¼Œæˆ–è€…éœ€è¦å¤„ç†æ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰å…³è”ã€æ¦‚å¿µæ³›åŒ–ã€å¤æ‚ä¸Šä¸‹æ–‡ç†è§£æ—¶ï¼Œç³»ç»Ÿä¼šå¼•å…¥åŸºäºLLMçš„åŒ¹é…ã€‚\n",
      "    *   **æ ¸å¿ƒæ¨¡å—ï¼š** `llm_matching`å’Œ`llm_om_zero_shot`æ˜ç¡®æŒ‡ç¤ºäº†è¿™ä¸€ç‚¹ã€‚`llm_matching`å¯èƒ½æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œåˆ©ç”¨LLMè¿›è¡Œå„ç§åŒ¹é…ä»»åŠ¡ï¼Œè€Œ`llm_om_zero_shot`åˆ™æš—ç¤ºäº†åˆ©ç”¨LLMçš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œåœ¨æ²¡æœ‰æˆ–æå°‘è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼ŒåŸºäºå…¶é¢„è®­ç»ƒçŸ¥è¯†è¿›è¡Œæœ¬ä½“æˆ–å®ä½“é—´çš„è¯­ä¹‰åŒ¹é…ã€‚\n",
      "    *   **ç¼–æ’é€»è¾‘ï¼š** LLMåŒ¹é…ä½œä¸ºä¸€ç§å›é€€æœºåˆ¶ï¼ˆfallbackï¼‰æˆ–å¢å¼ºæœºåˆ¶ï¼Œåœ¨ä¼ ç»Ÿæ–¹æ³•å¤±æ•ˆæˆ–éœ€è¦æ›´é«˜æ™ºèƒ½çš„åœºæ™¯ä¸‹è¢«è°ƒç”¨ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªLLM Agentå¯ä»¥åˆ¤æ–­ï¼šâ€œå¦‚æœå¥æ³•å’Œè¯æ³•å·¥å…·æœªèƒ½ç»™å‡ºç¡®åˆ‡ç­”æ¡ˆï¼Œé‚£ä¹ˆæˆ‘éœ€è¦è¯·`llm_matching`å·¥å…·æ¥åˆ†æå®ä½“é—´çš„è¯­ä¹‰å…³ç³»ã€‚â€\n",
      "\n",
      "**å°†`lexical`ç­‰ä¼ ç»ŸåŒ¹é…æ–¹æ³•å°è£…ä¸º`@tool`çš„æ¶æ„ä¼˜åŠ¿ï¼š**\n",
      "\n",
      "å°†`lexical`ç­‰ä¼ ç»ŸåŒ¹é…æ–¹æ³•é€šè¿‡`@tool`è£…é¥°å™¨å°è£…èµ·æ¥ï¼Œæ˜¯åˆ©ç”¨LangChainç­‰æ¡†æ¶å®ç°Agentic Orchestrationçš„å…³é”®ï¼Œå¸¦æ¥äº†ä»¥ä¸‹æ˜¾è‘—ä¼˜åŠ¿ï¼š\n",
      "\n",
      "1.  **ç»Ÿä¸€çš„æ¥å£å’Œå¯æ’æ‹”æ€§ï¼š** æ‰€æœ‰çš„åŒ¹é…ç­–ç•¥ï¼ˆæ— è®ºæ˜¯ä¼ ç»Ÿè§„åˆ™è¿˜æ˜¯LLMï¼‰éƒ½é€šè¿‡ç»Ÿä¸€çš„`tool`æ¥å£æš´éœ²ç»™Agentã€‚è¿™ä½¿å¾— Agent èƒ½å¤Ÿä»¥ç›¸åŒçš„æ–¹å¼è°ƒç”¨ä¸åŒç±»å‹çš„åŒ¹é…åŠŸèƒ½ï¼Œæå¤§åœ°æé«˜äº†æ¨¡å—çš„å¯æ’æ‹”æ€§å’Œå¯æ›¿æ¢æ€§ã€‚\n",
      "2.  **æ™ºèƒ½ä»£ç†ç¼–æ’ (Agentic Orchestration)ï¼š**\n",
      "    *   LangChain Agentèƒ½å¤Ÿæ ¹æ®å½“å‰çš„åŒ¹é…ä»»åŠ¡ã€å·²æœ‰çš„åŒ¹é…ç»“æœã€ç”šè‡³LLMè‡ªèº«çš„æ¨ç†èƒ½åŠ›ï¼Œ**åŠ¨æ€åœ°å†³å®š**è°ƒç”¨å“ªä¸ªåŒ¹é…å·¥å…·ä»¥åŠä½•æ—¶è°ƒç”¨ã€‚ä¾‹å¦‚ï¼ŒAgentå¯ä»¥è¢«è®¾è®¡ä¸ºï¼š\n",
      "        *   é¦–å…ˆå°è¯•è°ƒç”¨`syntactic`å·¥å…·ã€‚\n",
      "        *   å¦‚æœ`syntactic`å·¥å…·è¿”å›`null_value_matching`æˆ–åˆ†æ•°è¾ƒä½ï¼Œåˆ™å°è¯•è°ƒç”¨`lexical`å·¥å…·ã€‚\n",
      "        *   å¦‚æœ`lexical`å·¥å…·ä»ç„¶ä¸ç†æƒ³ï¼Œæˆ–è€…åŒ¹é…è¦æ±‚æ›´é«˜è¯­ä¹‰ç²¾åº¦ï¼Œåˆ™è¿›ä¸€æ­¥è°ƒç”¨`llm_matching`æˆ–`llm_om_zero_shot`å·¥å…·ã€‚\n",
      "    *   è¿™ç§åŸºäºAgentçš„å†³ç­–æµï¼Œä½¿å¾—æ•´ä¸ªåŒ¹é…è¿‡ç¨‹æ›´åŠ çµæ´»å’Œæ™ºèƒ½åŒ–ï¼Œèƒ½å¤Ÿé€‚åº”å„ç§å¤æ‚çš„åŒ¹é…åœºæ™¯ã€‚\n",
      "3.  **å¯è§£é‡Šæ€§å’Œè°ƒè¯•æ€§ï¼š** LangChain Agentåœ¨æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨æ—¶ï¼Œé€šå¸¸ä¼šè®°å½•ä¸‹è°ƒç”¨çš„åŸå› ã€è¾“å…¥å’Œè¾“å‡ºã€‚è¿™ä¸ºç†è§£åŒ¹é…å†³ç­–è¿‡ç¨‹æä¾›äº†å¼ºå¤§çš„å¯è§£é‡Šæ€§ï¼Œå¹¶æœ‰åŠ©äºè°ƒè¯•å’Œä¼˜åŒ–åŒ¹é…ç­–ç•¥ã€‚\n",
      "4.  **æ¨¡å—åŒ–ä¸é‡ç”¨ï¼š** æ¯ä¸ª`@tool`éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€åŠŸèƒ½æ˜ç¡®çš„å•å…ƒï¼Œå¯ä»¥è¢«é‡å¤åˆ©ç”¨äºä¸åŒçš„åŒ¹é…æµç¨‹æˆ–Agentä¸­ï¼Œæé«˜äº†ä»£ç çš„å¤ç”¨æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚\n",
      "5.  **æ¡¥æ¥ä¼ ç»Ÿé€»è¾‘ä¸LLMï¼š** `tool`æœºåˆ¶æ˜¯è¿æ¥ä¼ ç»Ÿç¼–ç¨‹é€»è¾‘ä¸LLMâ€œæ€è€ƒâ€å’Œâ€œè¡ŒåŠ¨â€çš„å…³é”®æ¡¥æ¢ã€‚LLMå¯ä»¥ç†è§£å·¥å…·çš„æè¿°ï¼Œç„¶åç”Ÿæˆè°ƒç”¨å·¥å…·çš„å‚æ•°ï¼Œä»è€Œå°†å¤æ‚çš„ã€éç»“æ„åŒ–çš„åŒ¹é…è¯·æ±‚è½¬åŒ–ä¸ºå¯¹ç»“æ„åŒ–å·¥å…·çš„è°ƒç”¨ã€‚\n",
      "\n",
      "**å¤„ç†åŒ¹é…å¤±è´¥æˆ–æ— ç»“æœ (`null_value_matching`) çš„é²æ£’æ€§ï¼š**\n",
      "\n",
      "ç³»ç»Ÿé€šè¿‡ä»¥ä¸‹æ–¹å¼ç»“åˆå·¥å…·ç¼–æ’å’Œ`null_value_matching`æœºåˆ¶ç¡®ä¿é²æ£’æ€§ï¼š\n",
      "\n",
      "1.  **æ˜¾å¼å¤±è´¥æ ‡è®°ï¼š** `null_value_matching`ä½œä¸ºä¸€ä¸ªæ˜ç¡®çš„ä¿¡å·ï¼Œè¡¨ç¤ºæŸä¸ªç‰¹å®šçš„åŒ¹é…å·¥å…·ï¼ˆå¦‚`syntactic`ï¼‰æœªèƒ½æ‰¾åˆ°ä»»ä½•åŒ¹é…ç»“æœã€‚è¿™æ¯”è¿”å›ç©ºåˆ—è¡¨æ›´å…·è¯­ä¹‰ï¼Œèƒ½å¤ŸæŒ‡å¯¼åç»­çš„å†³ç­–ã€‚\n",
      "2.  **åˆ†çº§å›é€€ç­–ç•¥ï¼š** å½“ä¸€ä¸ªå·¥å…·è¿”å›`[null_value_matching]`æ—¶ï¼ŒLangChain Agentå¯ä»¥æ ¹æ®é¢„è®¾çš„é€»è¾‘æˆ–LLMçš„æ¨ç†ï¼Œè‡ªåŠ¨è§¦å‘ä¸‹ä¸€ä¸ªæ›´é«˜çº§æˆ–ä¸åŒçš„åŒ¹é…å·¥å…·ã€‚ä¾‹å¦‚ï¼š\n",
      "    *   `Syntactic` -> `[null_value_matching]` -> **Agentå†³å®šè°ƒç”¨** `Lexical`\n",
      "    *   `Lexical` -> `[null_value_matching]` -> **Agentå†³å®šè°ƒç”¨** `LLM_Matching`\n",
      "    *   è¿™ç§é€’è¿›å¼çš„åŒ¹é…å°è¯•ï¼Œç¡®ä¿äº†ç³»ç»Ÿåœ¨ç©·å°½å„ç§å¯èƒ½çš„æ–¹æ³•ä¹‹å‰ï¼Œä¸ä¼šè½»æ˜“æ”¾å¼ƒåŒ¹é…ä»»åŠ¡ã€‚\n",
      "3.  **æœ€ç»ˆå†³ç­–ä¸æŠ¥å‘Šï¼š** å¦‚æœæ‰€æœ‰åŒ¹é…å·¥å…·éƒ½è¿”å›`[null_value_matching]`ï¼ŒAgentå¯ä»¥æœ€ç»ˆå†³å®šæŠ¥å‘ŠåŒ¹é…å¤±è´¥ï¼Œæˆ–è€…è§¦å‘äººå·¥å®¡æ ¸æµç¨‹ï¼Œä»è€Œé¿å…äº†ç³»ç»Ÿåœ¨æ²¡æœ‰åŒ¹é…ç»“æœæ—¶é™·å…¥åƒµå±€ã€‚\n",
      "\n",
      "ç»¼ä¸Šæ‰€è¿°ï¼Œ`ontology-llm`é¡¹ç›®é€šè¿‡å°†ä¸åŒç²’åº¦çš„åŒ¹é…ç­–ç•¥å°è£…ä¸ºLangChainå·¥å…·ï¼Œæ„å»ºäº†ä¸€ä¸ªæ™ºèƒ½ã€çµæ´»ä¸”é²æ£’çš„å®ä½“åŒ¹é…æµç¨‹ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†ä»ç®€å•åˆ°å¤æ‚çš„å„ç§åŒ¹é…åœºæ™¯ï¼Œå¹¶æœ‰æ•ˆåœ°åº”å¯¹æ— åŒ¹é…ç»“æœçš„æƒ…å†µã€‚\n",
      "\n",
      "---\n",
      "\n",
      "æ¨ç†æ­¥éª¤:\n",
      "  1. **åˆæœŸ/é«˜æ•ˆåŒ¹é…ï¼ˆå¥æ³•å’Œè¯æ³•ï¼‰ï¼š**\n",
      "    *   **å¥æ³•åŒ¹é… (Syntactic Matching):** ä»£ç ä¸­å±•ç¤ºçš„`syntactic_matches`å¤„ç†éƒ¨åˆ†ï¼Œé€šå¸¸æ¶‰åŠåˆ°åŸºäºå­—ç¬¦ä¸²ç›¸ä¼¼åº¦ã€æ­£åˆ™è¡¨è¾¾å¼ã€ç¼–è¾‘è·ç¦»ç­‰å¿«é€Ÿã€ç¡®å®šæ€§çš„æ–¹æ³•ã€‚å®ƒçš„ç›®æ ‡æ˜¯è¯†åˆ«ç²¾ç¡®æˆ–è¿‘ä¼¼çš„æ–‡æœ¬åŒ¹é…ï¼Œæ•ˆç‡é«˜ï¼Œé€‚ç”¨äºå¤„ç†æ‹¼å†™é”™è¯¯ã€å¤§å°å†™å·®å¼‚æˆ–ç®€å•çš„è¯åºå˜åŠ¨ã€‚`drop_duplicates`å’Œ`head(top_k)`è¡¨æ˜å®ƒä¼šè¿›è¡Œç»“æœçš„å»é‡å’Œä¼˜å…ˆé€‰æ‹©ã€‚\n",
      "    *   **è¯æ³•åŒ¹é… (Lexical Matching):** `lexical`å‡½æ•°ï¼Œé€šè¿‡è°ƒç”¨`entity_matching(entity, \"lexical_matching\")`å®ç°ï¼Œä¼šæ›´è¿›ä¸€æ­¥åœ°å¤„ç†è¯å½¢å˜åŒ–ã€åŒä¹‰è¯æˆ–è¿‘ä¹‰è¯çš„è¯†åˆ«ã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°è¯å…¸æŸ¥æ‰¾ã€è¯å¹²æå–ã€è¯å½¢è¿˜åŸç­‰è¯­è¨€å­¦å¤„ç†ï¼Œæ¯”çº¯å¥æ³•åŒ¹é…æ›´æ™ºèƒ½ã€‚\n",
      "    *   **ç¼–æ’é€»è¾‘ï¼š** é€šå¸¸ï¼Œç³»ç»Ÿä¼šä¼˜å…ˆå°è¯•è¿™äº›æˆæœ¬è¾ƒä½ã€é€Ÿåº¦è¾ƒå¿«çš„ä¼ ç»Ÿæ–¹æ³•ã€‚å¦‚æœå®ƒä»¬èƒ½å¤Ÿæ‰¾åˆ°é«˜è´¨é‡çš„åŒ¹é…ï¼ˆä¾‹å¦‚ï¼Œè¿”å›éç©ºçš„`top_k`ç»“æœï¼‰ï¼Œå°±å¯ä»¥é¿å…è°ƒç”¨æ›´è€—è´¹èµ„æºçš„LLMï¼Œä»è€Œæé«˜æ•´ä½“æ•ˆç‡ã€‚\n",
      "  2. **é«˜çº§/è¯­ä¹‰åŒ¹é…ï¼ˆåŸºäºLLMçš„åŒ¹é…ï¼‰ï¼š**\n",
      "    *   å½“å¥æ³•å’Œè¯æ³•åŒ¹é…æ— æ³•æ‰¾åˆ°æ»¡æ„ç»“æœï¼Œæˆ–è€…éœ€è¦å¤„ç†æ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰å…³è”ã€æ¦‚å¿µæ³›åŒ–ã€å¤æ‚ä¸Šä¸‹æ–‡ç†è§£æ—¶ï¼Œç³»ç»Ÿä¼šå¼•å…¥åŸºäºLLMçš„åŒ¹é…ã€‚\n",
      "    *   **æ ¸å¿ƒæ¨¡å—ï¼š** `llm_matching`å’Œ`llm_om_zero_shot`æ˜ç¡®æŒ‡ç¤ºäº†è¿™ä¸€ç‚¹ã€‚`llm_matching`å¯èƒ½æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œåˆ©ç”¨LLMè¿›è¡Œå„ç§åŒ¹é…ä»»åŠ¡ï¼Œè€Œ`llm_om_zero_shot`åˆ™æš—ç¤ºäº†åˆ©ç”¨LLMçš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œåœ¨æ²¡æœ‰æˆ–æå°‘è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼ŒåŸºäºå…¶é¢„è®­ç»ƒçŸ¥è¯†è¿›è¡Œæœ¬ä½“æˆ–å®ä½“é—´çš„è¯­ä¹‰åŒ¹é…ã€‚\n",
      "    *   **ç¼–æ’é€»è¾‘ï¼š** LLMåŒ¹é…ä½œä¸ºä¸€ç§å›é€€æœºåˆ¶ï¼ˆfallbackï¼‰æˆ–å¢å¼ºæœºåˆ¶ï¼Œåœ¨ä¼ ç»Ÿæ–¹æ³•å¤±æ•ˆæˆ–éœ€è¦æ›´é«˜æ™ºèƒ½çš„åœºæ™¯ä¸‹è¢«è°ƒç”¨ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªLLM Agentå¯ä»¥åˆ¤æ–­ï¼šâ€œå¦‚æœå¥æ³•å’Œè¯æ³•å·¥å…·æœªèƒ½ç»™å‡ºç¡®åˆ‡ç­”æ¡ˆï¼Œé‚£ä¹ˆæˆ‘éœ€è¦è¯·`llm_matching`å·¥å…·æ¥åˆ†æå®ä½“é—´çš„è¯­ä¹‰å…³ç³»ã€‚â€\n",
      "  3. **ç»Ÿä¸€çš„æ¥å£å’Œå¯æ’æ‹”æ€§ï¼š** æ‰€æœ‰çš„åŒ¹é…ç­–ç•¥ï¼ˆæ— è®ºæ˜¯ä¼ ç»Ÿè§„åˆ™è¿˜æ˜¯LLMï¼‰éƒ½é€šè¿‡ç»Ÿä¸€çš„`tool`æ¥å£æš´éœ²ç»™Agentã€‚è¿™ä½¿å¾— Agent èƒ½å¤Ÿä»¥ç›¸åŒçš„æ–¹å¼è°ƒç”¨ä¸åŒç±»å‹çš„åŒ¹é…åŠŸèƒ½ï¼Œæå¤§åœ°æé«˜äº†æ¨¡å—çš„å¯æ’æ‹”æ€§å’Œå¯æ›¿æ¢æ€§ã€‚\n",
      "  4. **æ™ºèƒ½ä»£ç†ç¼–æ’ (Agentic Orchestration)ï¼š**\n",
      "    *   LangChain Agentèƒ½å¤Ÿæ ¹æ®å½“å‰çš„åŒ¹é…ä»»åŠ¡ã€å·²æœ‰çš„åŒ¹é…ç»“æœã€ç”šè‡³LLMè‡ªèº«çš„æ¨ç†èƒ½åŠ›ï¼Œ**åŠ¨æ€åœ°å†³å®š**è°ƒç”¨å“ªä¸ªåŒ¹é…å·¥å…·ä»¥åŠä½•æ—¶è°ƒç”¨ã€‚ä¾‹å¦‚ï¼ŒAgentå¯ä»¥è¢«è®¾è®¡ä¸ºï¼š\n",
      "        *   é¦–å…ˆå°è¯•è°ƒç”¨`syntactic`å·¥å…·ã€‚\n",
      "        *   å¦‚æœ`syntactic`å·¥å…·è¿”å›`null_value_matching`æˆ–åˆ†æ•°è¾ƒä½ï¼Œåˆ™å°è¯•è°ƒç”¨`lexical`å·¥å…·ã€‚\n",
      "        *   å¦‚æœ`lexical`å·¥å…·ä»ç„¶ä¸ç†æƒ³ï¼Œæˆ–è€…åŒ¹é…è¦æ±‚æ›´é«˜è¯­ä¹‰ç²¾åº¦ï¼Œåˆ™è¿›ä¸€æ­¥è°ƒç”¨`llm_matching`æˆ–`llm_om_zero_shot`å·¥å…·ã€‚\n",
      "    *   è¿™ç§åŸºäºAgentçš„å†³ç­–æµï¼Œä½¿å¾—æ•´ä¸ªåŒ¹é…è¿‡ç¨‹æ›´åŠ çµæ´»å’Œæ™ºèƒ½åŒ–ï¼Œèƒ½å¤Ÿé€‚åº”å„ç§å¤æ‚çš„åŒ¹é…åœºæ™¯ã€‚\n",
      "  5. **å¯è§£é‡Šæ€§å’Œè°ƒè¯•æ€§ï¼š** LangChain Agentåœ¨æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨æ—¶ï¼Œé€šå¸¸ä¼šè®°å½•ä¸‹è°ƒç”¨çš„åŸå› ã€è¾“å…¥å’Œè¾“å‡ºã€‚è¿™ä¸ºç†è§£åŒ¹é…å†³ç­–è¿‡ç¨‹æä¾›äº†å¼ºå¤§çš„å¯è§£é‡Šæ€§ï¼Œå¹¶æœ‰åŠ©äºè°ƒè¯•å’Œä¼˜åŒ–åŒ¹é…ç­–ç•¥ã€‚\n",
      "  6. **æ¨¡å—åŒ–ä¸é‡ç”¨ï¼š** æ¯ä¸ª`@tool`éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€åŠŸèƒ½æ˜ç¡®çš„å•å…ƒï¼Œå¯ä»¥è¢«é‡å¤åˆ©ç”¨äºä¸åŒçš„åŒ¹é…æµç¨‹æˆ–Agentä¸­ï¼Œæé«˜äº†ä»£ç çš„å¤ç”¨æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚\n",
      "  7. **æ¡¥æ¥ä¼ ç»Ÿé€»è¾‘ä¸LLMï¼š** `tool`æœºåˆ¶æ˜¯è¿æ¥ä¼ ç»Ÿç¼–ç¨‹é€»è¾‘ä¸LLMâ€œæ€è€ƒâ€å’Œâ€œè¡ŒåŠ¨â€çš„å…³é”®æ¡¥æ¢ã€‚LLMå¯ä»¥ç†è§£å·¥å…·çš„æè¿°ï¼Œç„¶åç”Ÿæˆè°ƒç”¨å·¥å…·çš„å‚æ•°ï¼Œä»è€Œå°†å¤æ‚çš„ã€éç»“æ„åŒ–çš„åŒ¹é…è¯·æ±‚è½¬åŒ–ä¸ºå¯¹ç»“æ„åŒ–å·¥å…·çš„è°ƒç”¨ã€‚\n",
      "  8. **æ˜¾å¼å¤±è´¥æ ‡è®°ï¼š** `null_value_matching`ä½œä¸ºä¸€ä¸ªæ˜ç¡®çš„ä¿¡å·ï¼Œè¡¨ç¤ºæŸä¸ªç‰¹å®šçš„åŒ¹é…å·¥å…·ï¼ˆå¦‚`syntactic`ï¼‰æœªèƒ½æ‰¾åˆ°ä»»ä½•åŒ¹é…ç»“æœã€‚è¿™æ¯”è¿”å›ç©ºåˆ—è¡¨æ›´å…·è¯­ä¹‰ï¼Œèƒ½å¤ŸæŒ‡å¯¼åç»­çš„å†³ç­–ã€‚\n",
      "  9. **åˆ†çº§å›é€€ç­–ç•¥ï¼š** å½“ä¸€ä¸ªå·¥å…·è¿”å›`[null_value_matching]`æ—¶ï¼ŒLangChain Agentå¯ä»¥æ ¹æ®é¢„è®¾çš„é€»è¾‘æˆ–LLMçš„æ¨ç†ï¼Œè‡ªåŠ¨è§¦å‘ä¸‹ä¸€ä¸ªæ›´é«˜çº§æˆ–ä¸åŒçš„åŒ¹é…å·¥å…·ã€‚ä¾‹å¦‚ï¼š\n",
      "    *   `Syntactic` -> `[null_value_matching]` -> **Agentå†³å®šè°ƒç”¨** `Lexical`\n",
      "    *   `Lexical` -> `[null_value_matching]` -> **Agentå†³å®šè°ƒç”¨** `LLM_Matching`\n",
      "    *   è¿™ç§é€’è¿›å¼çš„åŒ¹é…å°è¯•ï¼Œç¡®ä¿äº†ç³»ç»Ÿåœ¨ç©·å°½å„ç§å¯èƒ½çš„æ–¹æ³•ä¹‹å‰ï¼Œä¸ä¼šè½»æ˜“æ”¾å¼ƒåŒ¹é…ä»»åŠ¡ã€‚\n",
      "  10. **æœ€ç»ˆå†³ç­–ä¸æŠ¥å‘Šï¼š** å¦‚æœæ‰€æœ‰åŒ¹é…å·¥å…·éƒ½è¿”å›`[null_value_matching]`ï¼ŒAgentå¯ä»¥æœ€ç»ˆå†³å®šæŠ¥å‘ŠåŒ¹é…å¤±è´¥ï¼Œæˆ–è€…è§¦å‘äººå·¥å®¡æ ¸æµç¨‹ï¼Œä»è€Œé¿å…äº†ç³»ç»Ÿåœ¨æ²¡æœ‰åŒ¹é…ç»“æœæ—¶é™·å…¥åƒµå±€ã€‚\n",
      "  11. **è¯†åˆ«æ ¸å¿ƒç»„ä»¶ä¸åŠŸèƒ½ï¼š**\n",
      "    *   ä»£ç ç‰‡æ®µæ˜¾ç¤ºäº†`syntactic_matches`çš„å¤„ç†é€»è¾‘ï¼ˆPandas DataFrameæ“ä½œï¼Œ`drop_duplicates`, `head(top_k)`, `null_value_matching`ï¼‰ï¼Œä»¥åŠ`lexical`å‡½æ•°è¢«`@tool`è£…é¥°å™¨ä¿®é¥°ï¼Œå¹¶è°ƒç”¨äº†`entity_matching`ã€‚\n",
      "    *   æ ¹æ®é¡¹ç›®æè¿°ï¼Œ`ontology-llm`æ˜¯ä¸€ä¸ªæ¶‰åŠæœ¬ä½“å’ŒLLMçš„é¡¹ç›®ï¼Œ`om_database_matching.py`æ˜¯åŒ¹é…ä¸šåŠ¡æ¨¡å—ã€‚\n",
      "    *   ä¾èµ–å’Œæ ¸å¿ƒæ¨¡å—æåˆ°äº†`langchain_core`ã€`langchain_community`ã€`llm_om_zero_shot`ã€`llm_matching`ã€`entity_matching`ã€‚\n",
      "    *   `@tool`è£…é¥°å™¨æ˜ç¡®æŒ‡å‘LangChainçš„Agent/ToolåŠŸèƒ½ã€‚\n",
      "  12. **æ¨æ–­åŒ¹é…ç­–ç•¥ç±»å‹åŠå…³ç³»ï¼š**\n",
      "    *   `syntactic_matches`å’Œ`lexical`å‡½æ•°ä»£è¡¨ä¼ ç»Ÿçš„ã€åŸºäºè§„åˆ™æˆ–å­—ç¬¦ä¸²ç›¸ä¼¼åº¦çš„åŒ¹é…æ–¹æ³•ï¼ˆå¥æ³•ã€è¯æ³•ï¼‰ã€‚å®ƒä»¬é€šå¸¸é€Ÿåº¦å¿«ã€æˆæœ¬ä½ã€‚\n",
      "    *   `llm_om_zero_shot`å’Œ`llm_matching`åˆ™æ˜ç¡®æŒ‡å‡ºå­˜åœ¨åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŒ¹é…ç­–ç•¥ï¼Œè¿™é€šå¸¸ç”¨äºå¤„ç†æ›´å¤æ‚çš„è¯­ä¹‰ç†è§£å’Œé›¶æ ·æœ¬åŒ¹é…ï¼Œæˆæœ¬ç›¸å¯¹è¾ƒé«˜ã€‚\n",
      "    *   å› æ­¤ï¼Œç³»ç»Ÿé‡‡ç”¨çš„æ˜¯ä¸€ä¸ª**æ··åˆåŒ¹é…**ç­–ç•¥ï¼Œç»“åˆäº†ä¼ ç»Ÿæ–¹æ³•å’ŒLLMæ–¹æ³•ã€‚\n",
      "  13. **åˆ†æ`@tool`è£…é¥°å™¨çš„ä½œç”¨åŠç¼–æ’ä¼˜åŠ¿ï¼š**\n",
      "    *   `@tool`å°†å‡½æ•°å°è£…ä¸ºLangChain Agentå¯è°ƒç”¨çš„å·¥å…·ã€‚è¿™æ„å‘³ç€Agentï¼ˆå¯èƒ½æ˜¯ä¸€ä¸ªLLMé©±åŠ¨çš„Agentï¼‰å¯ä»¥æ™ºèƒ½åœ°é€‰æ‹©å¹¶æ‰§è¡Œè¿™äº›åŒ¹é…å‡½æ•°ã€‚\n",
      "    *   **æ¶æ„ä¼˜åŠ¿**åœ¨äºï¼šæ¨¡å—åŒ–ã€ç»Ÿä¸€æ¥å£ï¼ˆAgentå¯ä»¥ç»Ÿä¸€è°ƒç”¨ä¸åŒç±»å‹çš„åŒ¹é…ï¼‰ã€Agentic Orchestrationï¼ˆAgentå¯ä»¥åŠ¨æ€å†³ç­–è°ƒç”¨é¡ºåºï¼‰ã€å¯è§£é‡Šæ€§ï¼ˆAgentè°ƒç”¨æ—¥å¿—ï¼‰ã€ä»¥åŠæ¡¥æ¥LLMä¸ä¼ ç»Ÿé€»è¾‘ã€‚LLMå¯ä»¥æ ¹æ®ä»»åŠ¡æè¿°å’Œå·¥å…·åŠŸèƒ½å®šä¹‰ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚\n",
      "  14. **è§£é‡Šé²æ£’æ€§ä¸`null_value_matching`å¤„ç†ï¼š**\n",
      "    *   `null_value_matching`æ˜¯å½“æŸä¸ªåŒ¹é…æ–¹æ³•æœªæ‰¾åˆ°ç»“æœæ—¶è¿”å›çš„æ˜¾å¼æ ‡è®°ã€‚è¿™æ¯”ç®€å•çš„ç©ºåˆ—è¡¨æ›´å…·è¯­ä¹‰ï¼Œå› ä¸ºå®ƒæ˜ç¡®è¡¨ç¤ºâ€œæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å·²çŸ¥å€¼â€ï¼Œè€Œéâ€œè¿”å›ä¸€ä¸ªç©ºé›†â€ã€‚\n",
      "    *   ç»“åˆ`@tool`å’ŒAgentic Orchestrationï¼Œå½“ä¸€ä¸ªå·¥å…·ï¼ˆå¦‚`syntactic`ï¼‰è¿”å›`null_value_matching`æ—¶ï¼ŒAgentå¯ä»¥è¢«ç¼–ç¨‹ä¸ºï¼ˆæˆ–ç”±LLMæ¨ç†å†³å®šï¼‰å°è¯•è°ƒç”¨ä¸‹ä¸€ä¸ªæ›´å¤æ‚çš„å·¥å…·ï¼ˆå¦‚`lexical`ï¼Œç„¶åæ˜¯`llm_matching`ï¼‰ã€‚\n",
      "    *   è¿™ç§**åˆ†çº§å›é€€ç­–ç•¥**ç¡®ä¿äº†ç³»ç»Ÿåœ¨ç©·å°½å„ç§å¯èƒ½æ€§ä¹‹å‰ä¸ä¼šè½»æ˜“æ”¾å¼ƒï¼Œä»è€Œå¢å¼ºäº†æ•´ä½“çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿå¤„ç†ä»ç²¾ç¡®åŒ¹é…åˆ°å¤æ‚è¯­ä¹‰åŒ¹é…çš„å„ç§åœºæ™¯ã€‚\n",
      "  15. **ç»¼åˆå½’çº³å¹¶å½¢æˆQ&Aï¼š**\n",
      "    *   å°†ä¸Šè¿°åˆ†ææ•´åˆï¼Œå½¢æˆä¸€ä¸ªæ·±å…¥ä¸”å…·ä½“çš„é—®ç­”å¯¹ã€‚é—®é¢˜åº”æ¶µç›–ä¸åŒåŒ¹é…ç­–ç•¥çš„ç¼–æ’ã€`@tool`çš„æ¶æ„ä¼˜åŠ¿ä»¥åŠå¤±è´¥å¤„ç†æœºåˆ¶ã€‚ç­”æ¡ˆåˆ™è¯¦ç»†é˜è¿°æ¯ä¸ªæ–¹é¢ã€‚\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# éšæœºé€‰æ‹©ä¸€ä¸ªæ–‡ä»¶\n",
    "files = generator.discover_python_files()\n",
    "test_file = random.choice(files)\n",
    "rel_path = test_file.relative_to(project_path)\n",
    "\n",
    "print(f\"ğŸ“„ æµ‹è¯•æ–‡ä»¶: {rel_path}\\n\")\n",
    "\n",
    "# æå–ä»£ç ç‰‡æ®µ\n",
    "code_snippet = generator.extract_code_snippet(test_file, length=600)\n",
    "print(\"ã€ä»£ç ç‰‡æ®µé¢„è§ˆã€‘\")\n",
    "print(code_snippet[:300] + \"...\\n\")\n",
    "\n",
    "# ç”Ÿæˆé—®ç­”å¯¹\n",
    "print(\"ğŸ”„ ç”Ÿæˆé—®ç­”å¯¹...\")\n",
    "qa = generator.generate_qa_pair(\n",
    "    code_snippet=code_snippet,\n",
    "    file_path=str(rel_path),\n",
    "    use_context=True  # å¯ç”¨ä¸Šä¸‹æ–‡å¢å¼º\n",
    ")\n",
    "\n",
    "if qa:\n",
    "    print(\"\\nâœ… ç”ŸæˆæˆåŠŸï¼\\n\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"é—®é¢˜: {qa['question']}\\n\")\n",
    "    print(f\"ç­”æ¡ˆ: {qa['answer']}\\n\")\n",
    "    print(\"æ¨ç†æ­¥éª¤:\")\n",
    "    for i, step in enumerate(qa['reasoning_steps'], 1):\n",
    "        print(f\"  {i}. {step}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"âŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b8f85",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ æ­¥éª¤4b: ç”Ÿæˆå•ä¸ªè®¾è®¡æ–¹æ¡ˆï¼ˆæµ‹è¯•ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8572551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ æµ‹è¯•éœ€æ±‚: ä¸ºé¡¹ç›®æ·»åŠ æ‰¹é‡å¤„ç†åŠŸèƒ½ï¼Œæ”¯æŒå¹¶å‘å¤„ç†å¤§é‡æ•°æ®\n",
      "\n",
      "ğŸ”„ ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ...\n",
      "\n",
      "âœ… ç”ŸæˆæˆåŠŸï¼\n",
      "\n",
      "======================================================================\n",
      "éœ€æ±‚: ä¸ºé¡¹ç›®æ·»åŠ æ‰¹é‡å¤„ç†åŠŸèƒ½ï¼Œæ”¯æŒå¹¶å‘å¤„ç†å¤§é‡æ•°æ®\n",
      "\n",
      "è§£å†³æ–¹æ¡ˆ: ä¸ºäº†ä¸º `ontology-llm` é¡¹ç›®æ·»åŠ æ‰¹é‡å¤„ç†å’Œå¹¶å‘åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨åŸºäº `concurrent.futures` æ¨¡å—çš„ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ã€‚`run_series_conference` æ¨¡å—å°†ä½œä¸ºåè°ƒå™¨ï¼Œè´Ÿè´£åŠ è½½æ‰€æœ‰å¾…å¤„ç†çš„æ•°æ®é¡¹ï¼ˆå³â€œä»»åŠ¡â€ï¼‰ï¼Œå°†å…¶åˆ‡åˆ†ä¸ºå¯ç®¡ç†çš„æ‰¹æ¬¡ï¼ˆbatchï¼‰ï¼Œç„¶åå°†è¿™äº›æ‰¹æ¬¡æäº¤ç»™ä¸€ä¸ªçº¿ç¨‹æ± æˆ–è¿›ç¨‹æ± ï¼ˆ`ThreadPoolExecutor` æˆ– `ProcessPoolExecutor`ï¼‰è¿›è¡Œå¹¶å‘å¤„ç†ã€‚æ ¸å¿ƒçš„LLMè°ƒç”¨é€»è¾‘ï¼ˆå¦‚ `llm_om_zero_shot` æˆ– `llm_matching`ï¼‰å°†è¢«å°è£…æˆä¸€ä¸ªå¯è¢«å¹¶å‘æ‰§è¡Œçš„å‡½æ•°ã€‚`util` æ¨¡å—å°†æä¾›æ‰¹å¤„ç†å’Œå¹¶å‘ç›¸å…³çš„è¾…åŠ©å‡½æ•°ã€‚\n",
      "\n",
      "è¿™ç§æ–¹æ³•å…è®¸æˆ‘ä»¬ï¼š\n",
      "1. **æ§åˆ¶å¹¶å‘åº¦**: é€šè¿‡é…ç½®çº¿ç¨‹/è¿›ç¨‹æ± çš„å¤§å°ã€‚\n",
      "2. **ä¼˜åŒ–èµ„æºåˆ©ç”¨**: åœ¨ç­‰å¾…LLM APIå“åº”æ—¶ï¼Œå…¶ä»–ä»»åŠ¡å¯ä»¥åŒæ—¶å¤„ç†ã€‚\n",
      "3. **æé«˜ååé‡**: æ˜¾è‘—å‡å°‘å¤„ç†å¤§é‡æ•°æ®æ‰€éœ€çš„æ—¶é—´ã€‚\n",
      "4. **å¼¹æ€§æ‰©å±•**: æ˜“äºæ ¹æ®ç¡¬ä»¶èµ„æºæˆ–APIé™åˆ¶è°ƒæ•´å‚æ•°ã€‚\n",
      "\n",
      "å®æ–½æ­¥éª¤:\n",
      "  1. **æ§åˆ¶å¹¶å‘åº¦**: é€šè¿‡é…ç½®çº¿ç¨‹/è¿›ç¨‹æ± çš„å¤§å°ã€‚\n",
      "  2. **ä¼˜åŒ–èµ„æºåˆ©ç”¨**: åœ¨ç­‰å¾…LLM APIå“åº”æ—¶ï¼Œå…¶ä»–ä»»åŠ¡å¯ä»¥åŒæ—¶å¤„ç†ã€‚\n",
      "  3. **æé«˜ååé‡**: æ˜¾è‘—å‡å°‘å¤„ç†å¤§é‡æ•°æ®æ‰€éœ€çš„æ—¶é—´ã€‚\n",
      "  4. **å¼¹æ€§æ‰©å±•**: æ˜“äºæ ¹æ®ç¡¬ä»¶èµ„æºæˆ–APIé™åˆ¶è°ƒæ•´å‚æ•°ã€‚\n",
      "  5. **å®šä¹‰â€œä»»åŠ¡â€ç»“æ„**:\n",
      "    *   é¦–å…ˆï¼Œæ˜ç¡®ä¸€ä¸ªå•ä¸€çš„LLMæœ¬ä½“åŒ¹é…æ“ä½œï¼ˆä¾‹å¦‚ï¼Œè°ƒç”¨ `llm_om_zero_shot` è¿›è¡Œä¸€æ¬¡åŒ¹é…ï¼‰æ‰€éœ€çš„å…¨éƒ¨è¾“å…¥æ•°æ®ã€‚è¿™å¯èƒ½æ˜¯ä¸€ä¸ªå­—å…¸ã€ä¸€ä¸ªå¯¹è±¡æˆ–ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«æºæœ¬ä½“ä¿¡æ¯ã€ç›®æ ‡æœ¬ä½“ä¿¡æ¯ã€LLMæç¤ºæ¨¡æ¿ã€å…¶ä»–é…ç½®å‚æ•°ç­‰ã€‚æˆ‘ä»¬å°†æŠŠæ¯ä¸ªè¿™æ ·çš„è¾“å…¥å•å…ƒç§°ä¸ºä¸€ä¸ªâ€œä»»åŠ¡â€ã€‚\n",
      "    *   *ä¿®æ”¹æ–‡ä»¶*: æ£€æŸ¥ `llm_om_zero_shot.py` å’Œ `llm_matching.py` ä¸­æ ¸å¿ƒå‡½æ•°çš„ç­¾åï¼Œç¡®ä¿å®ƒä»¬èƒ½å¤Ÿæ¥æ”¶ä¸€ä¸ªå°è£…äº†æ‰€æœ‰å¿…è¦ä¿¡æ¯çš„å•ä¸€â€œä»»åŠ¡â€å¯¹è±¡ä½œä¸ºè¾“å…¥ã€‚\n",
      "  6. **åˆ›å»ºæ•°æ®åŠ è½½å’Œä»»åŠ¡ç”Ÿæˆæ¨¡å—**:\n",
      "    *   åœ¨ `generate_conference_benchmark.py` æˆ– `run_series_conference.py` ä¸­ï¼Œå®ç°ä¸€ä¸ªå‡½æ•°æ¥åŠ è½½æ‰€æœ‰çš„åŸå§‹æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨çš„â€œä»»åŠ¡â€å¯¹è±¡ã€‚è¿™ä¸ªåˆ—è¡¨å°†æ˜¯å¾…å¤„ç†çš„å…¨éƒ¨æ•°æ®ã€‚\n",
      "    *   *ä¿®æ”¹æ–‡ä»¶*: `generate_conference_benchmark.py` æˆ– `run_series_conference.py`ã€‚\n",
      "  7. **åœ¨ `util.py` ä¸­æ·»åŠ æ‰¹å¤„ç†ï¼ˆChunkingï¼‰è¾…åŠ©å‡½æ•°**:\n",
      "    *   å®ç°ä¸€ä¸ªé€šç”¨å‡½æ•° `chunk_data(data_list, batch_size)`ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªæ•°æ®é¡¹åˆ—è¡¨å’Œä¸€ä¸ªæ‰¹æ¬¡å¤§å°ï¼Œå¹¶è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæ¯æ¬¡ yielding ä¸€ä¸ªåŒ…å« `batch_size` ä¸ªæ•°æ®é¡¹çš„å­åˆ—è¡¨ï¼ˆå³ä¸€ä¸ªæ‰¹æ¬¡ï¼‰ã€‚\n",
      "    *   è¿™ä¸ªå‡½æ•°å°†åœ¨ `run_series_conference.py` ä¸­è¢«è°ƒç”¨ï¼Œç”¨äºå°†å¤§é‡ä»»åŠ¡åˆ†è§£æˆå°æ‰¹æ¬¡ã€‚\n",
      "    *   *ä¿®æ”¹æ–‡ä»¶*: `util.py`ã€‚\n",
      "  8. **ä¿®æ”¹æ ¸å¿ƒLLMå¤„ç†å‡½æ•°ä»¥æ”¯æŒå•ä»»åŠ¡å¤„ç†**:\n",
      "    *   ç¡®ä¿ `llm_om_zero_shot.py` (æˆ– `llm_matching.py`) ä¸­çš„æ ¸å¿ƒå¤„ç†å‡½æ•°æ˜¯â€œåŸå­æ€§â€çš„ï¼Œå³å®ƒæ¥æ”¶ä¸€ä¸ªâ€œä»»åŠ¡â€å¹¶è¿”å›è¯¥ä»»åŠ¡çš„å¤„ç†ç»“æœã€‚å®ƒåº”è¯¥ç‹¬ç«‹äºå…¶ä»–ä»»åŠ¡ï¼Œä¸ä¾èµ–å…¨å±€çŠ¶æ€ã€‚\n",
      "    *   è€ƒè™‘æ·»åŠ é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•æœºåˆ¶ï¼Œä»¥ä¾¿åœ¨å•ä¸ªä»»åŠ¡å¤±è´¥æ—¶ä¸ä¼šä¸­æ–­æ•´ä¸ªæ‰¹å¤„ç†æµç¨‹ã€‚\n",
      "    *   *ä¿®æ”¹æ–‡ä»¶*: `llm_om_zero_shot.py`, `llm_matching.py`ã€‚\n",
      "  9. **åœ¨ `run_series_conference.py` ä¸­å®ç°å¹¶å‘æ‰¹å¤„ç†é€»è¾‘**:\n",
      "    *   **åŠ è½½ä»»åŠ¡**: è°ƒç”¨æ­¥éª¤2ä¸­å®ç°çš„ä»»åŠ¡ç”Ÿæˆå‡½æ•°ï¼Œè·å–æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡åˆ—è¡¨ã€‚\n",
      "    *   **é…ç½®å‚æ•°**: å¼•å…¥é…ç½®é€‰é¡¹ï¼Œä¾‹å¦‚ `batch_size`ï¼ˆæ¯ä¸ªæ‰¹æ¬¡çš„ä»»åŠ¡æ•°é‡ï¼‰å’Œ `max_workers`ï¼ˆå¹¶å‘æ‰§è¡Œçš„çº¿ç¨‹/è¿›ç¨‹æ•°é‡ï¼‰ã€‚è¿™å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ã€é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡æ¥è®¾ç½®ã€‚\n",
      "    *   **ä½¿ç”¨ `concurrent.futures`**:\n",
      "        *   åˆå§‹åŒ– `ThreadPoolExecutor` (é€‚åˆI/Oå¯†é›†å‹ä»»åŠ¡ï¼Œå¦‚ç­‰å¾…LLM APIå“åº”) æˆ– `ProcessPoolExecutor` (é€‚åˆCPUå¯†é›†å‹ä»»åŠ¡)ã€‚ç”±äºLLMè°ƒç”¨ä¸»è¦æ˜¯I/Oç­‰å¾…ï¼Œ`ThreadPoolExecutor` é€šå¸¸æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚\n",
      "        *   ä½¿ç”¨ `chunk_data` å°†ä»»åŠ¡åˆ—è¡¨åˆ†è§£ä¸ºæ‰¹æ¬¡ã€‚\n",
      "        *   éå†æ¯ä¸ªæ‰¹æ¬¡ï¼Œä½¿ç”¨ `executor.map()` æˆ– `executor.submit()` æ–¹æ³•æäº¤ä»»åŠ¡åˆ°æ‰§è¡Œå™¨ã€‚`map()` æ›´ç®€æ´ï¼Œå¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½è°ƒç”¨åŒä¸€ä¸ªå‡½æ•°å¹¶æœ‰ç›¸ä¼¼çš„è¾“å…¥ã€‚\n",
      "        *   æ”¶é›†å¹¶èšåˆæ‰€æœ‰æ‰¹æ¬¡çš„å¤„ç†ç»“æœã€‚\n",
      "        *   å¤„ç†å¯èƒ½çš„å¼‚å¸¸å’Œå¤±è´¥ä»»åŠ¡ã€‚\n",
      "    *   **è¿›åº¦æ˜¾ç¤º**: å¯é€‰åœ°ï¼Œé›†æˆä¸€ä¸ªè¿›åº¦æ¡ï¼ˆå¦‚ `tqdm` åº“ï¼‰æ¥æ˜¾ç¤ºæ‰¹å¤„ç†çš„è¿›åº¦ã€‚\n",
      "    *   *ä¿®æ”¹æ–‡ä»¶*: `run_series_conference.py`ã€‚\n",
      "  10. **ç»“æœå­˜å‚¨ä¸æŠ¥å‘Š**:\n",
      "    *   å¤„ç†å®Œæ‰€æœ‰æ‰¹æ¬¡åï¼Œå°†èšåˆçš„ç»“æœè¿›è¡Œå­˜å‚¨ï¼ˆä¾‹å¦‚ï¼Œå†™å…¥æ–‡ä»¶ã€æ•°æ®åº“ï¼‰ã€‚\n",
      "    *   ç”Ÿæˆå¤„ç†æŠ¥å‘Šï¼ŒåŒ…æ‹¬æˆåŠŸä»»åŠ¡æ•°ã€å¤±è´¥ä»»åŠ¡æ•°ã€æ€»è€—æ—¶ç­‰ã€‚\n",
      "    *   *ä¿®æ”¹æ–‡ä»¶*: `run_series_conference.py`ã€‚\n",
      "\n",
      "éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:\n",
      "  - llm` é¡¹ç›®æ·»åŠ æ‰¹é‡å¤„ç†å’Œå¹¶å‘åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨åŸºäº `concurrent.futures` æ¨¡å—çš„ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹ã€‚`run_series_conference` æ¨¡å—å°†ä½œä¸ºåè°ƒå™¨ï¼Œè´Ÿè´£åŠ è½½æ‰€æœ‰å¾…å¤„ç†çš„æ•°æ®é¡¹ï¼ˆå³â€œä»»åŠ¡â€ï¼‰ï¼Œå°†å…¶åˆ‡åˆ†ä¸ºå¯ç®¡ç†çš„æ‰¹æ¬¡ï¼ˆbatchï¼‰ï¼Œç„¶åå°†è¿™äº›æ‰¹æ¬¡æäº¤ç»™ä¸€ä¸ªçº¿ç¨‹æ± æˆ–è¿›ç¨‹æ± ï¼ˆ`ThreadPoolExecutor` æˆ– `ProcessPoolExecutor`ï¼‰è¿›è¡Œå¹¶å‘å¤„ç†ã€‚æ ¸å¿ƒçš„LLMè°ƒç”¨é€»è¾‘ï¼ˆå¦‚ `llm_om_zero_shot` æˆ– `llm_matching`ï¼‰å°†è¢«å°è£…æˆä¸€ä¸ªå¯è¢«å¹¶å‘æ‰§è¡Œçš„å‡½æ•°ã€‚`util` æ¨¡å—å°†æä¾›æ‰¹å¤„ç†å’Œå¹¶å‘ç›¸å…³çš„è¾…åŠ©å‡½æ•°ã€‚\n",
      "\n",
      "è¿™ç§æ–¹æ³•å…è®¸æˆ‘ä»¬ï¼š\n",
      "1. **æ§åˆ¶å¹¶å‘åº¦**: é€šè¿‡é…ç½®çº¿ç¨‹/è¿›ç¨‹æ± çš„å¤§å°ã€‚\n",
      "2. **ä¼˜åŒ–èµ„æºåˆ©ç”¨**: åœ¨ç­‰å¾…LLM APIå“åº”æ—¶ï¼Œå…¶ä»–ä»»åŠ¡å¯ä»¥åŒæ—¶å¤„ç†ã€‚\n",
      "3. **æé«˜ååé‡**: æ˜¾è‘—å‡å°‘å¤„ç†å¤§é‡æ•°æ®æ‰€éœ€çš„æ—¶é—´ã€‚\n",
      "4. **å¼¹æ€§æ‰©å±•**: æ˜“äºæ ¹æ®ç¡¬ä»¶èµ„æºæˆ–APIé™åˆ¶è°ƒæ•´å‚æ•°ã€‚\n",
      "  - `run_series_conference.py`: *   **ä¿®æ”¹åŸå› **: è¿™æ˜¯é¡¹ç›®çš„æ‰§è¡Œå…¥å£å’Œåè°ƒå™¨ã€‚å®ƒå°†è´Ÿè´£åŠ è½½æ‰€æœ‰ä»»åŠ¡ã€è¿›è¡Œæ‰¹å¤„ç†åˆ‡åˆ†ã€å¯åŠ¨å¹¶å‘æ‰§è¡Œå™¨ï¼ˆ`ThreadPoolExecutor`ï¼‰ï¼Œå¹¶å°†æ¯ä¸ªæ‰¹æ¬¡æäº¤ç»™LLMå¤„ç†å‡½æ•°ã€‚åŒæ—¶ï¼Œå®ƒè¿˜éœ€è¦æ”¶é›†å’Œèšåˆæ‰€æœ‰å¹¶å‘ä»»åŠ¡çš„ç»“æœã€‚\n",
      "  - `llm_om_zero_shot.py` (and/or `llm_matching.py`): *   **ä¿®æ”¹åŸå› **: æ¨¡å—ä¸­çš„æ ¸å¿ƒLLMè°ƒç”¨å‡½æ•°éœ€è¦è¢«å°è£…æˆä¸€ä¸ªå¯ç‹¬ç«‹æ‰§è¡Œçš„å•å…ƒï¼Œæ¥æ”¶ä¸€ä¸ªâ€œä»»åŠ¡â€ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›å…¶ç»“æœã€‚è¿™ç¡®ä¿äº†å®ƒå¯ä»¥åœ¨å¹¶å‘ç¯å¢ƒä¸­å®‰å…¨åœ°è¿è¡Œï¼Œä¸ä¾èµ–å…±äº«çŠ¶æ€ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ¸…æ™°åœ°è¿”å›æ¯ä¸ªä»»åŠ¡çš„ç»“æœæˆ–é”™è¯¯ã€‚\n",
      "  - `util.py`: *   **ä¿®æ”¹åŸå› **: æ·»åŠ é€šç”¨çš„ `chunk_data` å‡½æ•°ï¼Œç”¨äºå°†å¤§çš„ä»»åŠ¡åˆ—è¡¨åˆ†å‰²æˆå°æ‰¹æ¬¡ã€‚æœªæ¥è¿˜å¯ä»¥æ·»åŠ å…¶ä»–ä¸å¹¶å‘å¤„ç†ç›¸å…³çš„è¾…åŠ©å‡½æ•°ï¼Œå¦‚é”™è¯¯é‡è¯•æœºåˆ¶æˆ–ç»“æœåˆå¹¶å·¥å…·ã€‚\n",
      "  - `generate_conference_benchmark.py`: (Optional)\n",
      "    *   **ä¿®æ”¹åŸå› **: å¦‚æœæ­¤æ¨¡å—æ˜¯ç”ŸæˆåŸå§‹æ•°æ®æˆ–ä»»åŠ¡çš„æ¥æºï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å…¶è¾“å‡ºæ ¼å¼ï¼Œä½¿å…¶æ›´å®¹æ˜“è¢« `run_series_conference.py` è¯†åˆ«å’ŒåŠ è½½ä¸ºâ€œä»»åŠ¡â€åˆ—è¡¨ã€‚æˆ–è€…ï¼Œå¦‚æœå…¶å†…éƒ¨ä¹Ÿæœ‰éœ€è¦æ‰¹å¤„ç†çš„é€»è¾‘ï¼Œä¹Ÿå¯ä»¥åœ¨æ­¤æ¨¡å—å†…éƒ¨åº”ç”¨ç±»ä¼¼çš„å¹¶å‘æ¨¡å¼ã€‚\n",
      "  - `config.py` (or new config file): *   **ä¿®æ”¹åŸå› **: å¼•å…¥ `batch_size` å’Œ `max_workers` ç­‰é…ç½®å‚æ•°ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥è½»æ¾è°ƒæ•´å¹¶å‘è¡Œä¸ºã€‚\n",
      "  - except` å—ã€‚ä½¿ç”¨ `concurrent.futures` æ”¶é›†ç»“æœæ—¶ï¼Œè¦æ£€æŸ¥æ¯ä¸ª `Future` å¯¹è±¡çš„å¼‚å¸¸ã€‚è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼Œå¹¶è€ƒè™‘è·³è¿‡å¤±è´¥ä»»åŠ¡æˆ–å°†å…¶æ ‡è®°ä¸ºå¾…é‡è¯•ã€‚\n",
      "3.  **èµ„æºæ¶ˆè€— (å†…å­˜/CPU/GPU)**: *   **æŒ‘æˆ˜**: å¹¶å‘å¤„ç†å¤§é‡æ•°æ®å¯èƒ½å¯¼è‡´å†…å­˜æ¶ˆè€—è¿‡é«˜ï¼Œå°¤å…¶æ˜¯åœ¨ `ProcessPoolExecutor` ä¸­å¦‚æœä»»åŠ¡æ•°æ®è¢«å¤åˆ¶åˆ°æ¯ä¸ªè¿›ç¨‹ã€‚å¦‚æœLLMæ˜¯æœ¬åœ°è¿è¡Œçš„ï¼ŒCPU/GPUèµ„æºä¹Ÿå¯èƒ½æˆä¸ºç“¶é¢ˆã€‚\n",
      "    *   **åº”å¯¹**: ä¼˜åŒ–ä»»åŠ¡æ•°æ®ç»“æ„ï¼Œç¡®ä¿åªä¼ é€’å¿…è¦çš„ä¿¡æ¯ã€‚åˆç†è®¾ç½® `batch_size` å’Œ `max_workers`ã€‚å¯¹äºæœ¬åœ°LLMï¼Œå¯èƒ½éœ€è¦ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µï¼Œå¹¶è°ƒæ•´å¹¶è¡Œåº¦ã€‚\n",
      "4.  **ç»“æœèšåˆä¸é¡ºåº**:\n",
      "    *   **æŒ‘æˆ˜**: å¹¶å‘æ‰§è¡Œçš„ä»»åŠ¡å®Œæˆé¡ºåºæ˜¯ä¸ç¡®å®šçš„ã€‚å¦‚æœæœ€ç»ˆç»“æœéœ€è¦ä¿æŒä¸è¾“å…¥æ•°æ®ç›¸åŒçš„é¡ºåºï¼Œæˆ–è€…éœ€è¦æŒ‰ç‰¹å®šé¡ºåºèšåˆï¼Œåˆ™éœ€è¦é¢å¤–çš„å¤„ç†ã€‚\n",
      "    *   **åº”å¯¹**: `executor.map()` ä¼šä¿ç•™è¾“å…¥é¡ºåºï¼Œä½†å¦‚æœä½¿ç”¨ `executor.submit()` å’Œ `as_completed()`ï¼Œåˆ™éœ€è¦æ‰‹åŠ¨å°†ç»“æœä¸åŸå§‹ä»»åŠ¡IDå…³è”èµ·æ¥è¿›è¡Œæ’åºã€‚åœ¨ç»“æœä¸­åŒ…å«ä»»åŠ¡æ ‡è¯†ç¬¦æ˜¯å…³é”®ã€‚\n",
      "5.  **è°ƒè¯•å¤æ‚æ€§**:\n",
      "    *   **æŒ‘æˆ˜**: å¹¶å‘ç¨‹åºçš„è°ƒè¯•æ¯”é¡ºåºç¨‹åºæ›´å›°éš¾ï¼Œå› ä¸ºé—®é¢˜å¯èƒ½ä¾èµ–äºæ—¶é—´ã€çº¿ç¨‹è°ƒåº¦å’Œèµ„æºç«äº‰ã€‚\n",
      "    *   **åº”å¯¹**: å……åˆ†çš„æ—¥å¿—è®°å½•æ˜¯å…³é”®ï¼ŒåŒ…æ‹¬æ¯ä¸ªä»»åŠ¡çš„å¼€å§‹/ç»“æŸæ—¶é—´ã€è¾“å…¥ã€è¾“å‡ºå’Œé”™è¯¯ã€‚ä½¿ç”¨Pythonçš„ `logging` æ¨¡å—ï¼Œå¹¶ç¡®ä¿æ—¥å¿—åœ¨å¹¶å‘ç¯å¢ƒä¸­å®‰å…¨ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨ `logging.handlers.QueueHandler` æˆ–ç¡®ä¿æ—¥å¿—å†™æ˜¯åŸå­çš„ï¼‰ã€‚\n",
      "6.  **é…ç½®ä¸è°ƒä¼˜**:\n",
      "    *   **æŒ‘æˆ˜**: `batch_size` å’Œ `max_workers` çš„æœ€ä½³å€¼å–å†³äºå…·ä½“çš„LLMæœåŠ¡ã€ç½‘ç»œå»¶è¿Ÿã€ä»»åŠ¡å¤æ‚åº¦ä»¥åŠå¯ç”¨çš„ç³»ç»Ÿèµ„æºã€‚æ‰¾åˆ°æœ€ä¼˜é…ç½®å¯èƒ½éœ€è¦åå¤è¯•éªŒã€‚\n",
      "    *   **åº”å¯¹**: æä¾›æ¸…æ™°çš„é…ç½®é€‰é¡¹ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®æ–‡ä»¶è½»æ¾è°ƒæ•´è¿™äº›å€¼ã€‚æä¾›åŸºå‡†æµ‹è¯•å’Œæ€§èƒ½æŒ‡æ ‡ï¼Œå¸®åŠ©ç”¨æˆ·è¿›è¡Œè°ƒä¼˜ã€‚\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰éœ€æ±‚\n",
    "test_requirement = \"ä¸ºé¡¹ç›®æ·»åŠ æ‰¹é‡å¤„ç†åŠŸèƒ½ï¼Œæ”¯æŒå¹¶å‘å¤„ç†å¤§é‡æ•°æ®\"\n",
    "\n",
    "print(f\"ğŸ“‹ æµ‹è¯•éœ€æ±‚: {test_requirement}\\n\")\n",
    "\n",
    "# ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ\n",
    "print(\"ğŸ”„ ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ...\")\n",
    "design = generator.generate_design_solution(\n",
    "    requirement=test_requirement,\n",
    "    use_context=True\n",
    ")\n",
    "\n",
    "if design:\n",
    "    print(\"\\nâœ… ç”ŸæˆæˆåŠŸï¼\\n\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"éœ€æ±‚: {design['requirement']}\\n\")\n",
    "    print(f\"è§£å†³æ–¹æ¡ˆ: {design['solution']}\\n\")\n",
    "    print(\"å®æ–½æ­¥éª¤:\")\n",
    "    for i, step in enumerate(design['steps'], 1):\n",
    "        print(f\"  {i}. {step}\")\n",
    "    print(\"\\néœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:\")\n",
    "    for item in design['files_to_modify']:\n",
    "        print(f\"  - {item['file']}: {item['reason']}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"âŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75667fa9",
   "metadata": {},
   "source": [
    "## ğŸš€ æ­¥éª¤5: æ‰¹é‡ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
    "\n",
    "ä¸€é”®ç”Ÿæˆå®Œæ•´è®­ç»ƒæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba640d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ¯ æ‰¹é‡ç”Ÿæˆé…ç½®\n",
      "======================================================================\n",
      "   é—®ç­”å¯¹æ•°é‡: 10\n",
      "   è®¾è®¡æ–¹æ¡ˆæ•°é‡: 5\n",
      "   ä¸Šä¸‹æ–‡å¢å¼º: True\n",
      "   é¢„è®¡è€—æ—¶: 3.8 åˆ†é’Ÿ\n",
      "\n",
      "======================================================================\n",
      "ğŸš€ å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ å‘ç°Pythonæ–‡ä»¶...\n",
      "   æ‰¾åˆ° 13 ä¸ªæ–‡ä»¶\n",
      "\n",
      "ğŸ“ ç”Ÿæˆ 10 ä¸ªé—®ç­”å¯¹...\n",
      "   [1/10] å¤„ç†æ–‡ä»¶: generate_anatomy_mse_benchmark.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [2/10] å¤„ç†æ–‡ä»¶: generate_anatomy_mse_benchmark.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [3/10] å¤„ç†æ–‡ä»¶: run_series_similarity.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [4/10] å¤„ç†æ–‡ä»¶: run_config.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [5/10] å¤„ç†æ–‡ä»¶: generate_conference_benchmark.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [6/10] å¤„ç†æ–‡ä»¶: run_series_conference.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [7/10] å¤„ç†æ–‡ä»¶: run_series_conference.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [8/10] å¤„ç†æ–‡ä»¶: run_series_similarity.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [9/10] å¤„ç†æ–‡ä»¶: llm_om_zero_shot.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [10/10] å¤„ç†æ–‡ä»¶: om_csv_to_database.py\n",
      "       âœ… æˆåŠŸ\n",
      "\n",
      "ğŸ—ï¸  ç”Ÿæˆ 5 ä¸ªè®¾è®¡æ–¹æ¡ˆ...\n",
      "   [1/5] éœ€æ±‚: æ‰©å±•run_series_conferenceä»¥æ”¯æŒå¼±ç½‘ç¯å¢ƒåœºæ™¯...\n",
      "       âœ… æˆåŠŸ\n",
      "   [2/5] éœ€æ±‚: æ‰©å±•utilä»¥æ”¯æŒå¾®æœåŠ¡åœºæ™¯...\n",
      "       âœ… æˆåŠŸ\n",
      "   [3/5] éœ€æ±‚: ä¼˜åŒ–generate_conference_benchmarkçš„å¯ç»´æŠ¤æ€§æ€§èƒ½...\n",
      "       âœ… æˆåŠŸ\n",
      "   [4/5] éœ€æ±‚: æ”¹è¿›llm_om_zero_shotçš„å¼€å‘è€…ä½“éªŒ...\n",
      "       âœ… æˆåŠŸ\n",
      "   [5/5] éœ€æ±‚: é‡æ„utilä»¥æ”¯æŒçƒ­æ›´æ–°...\n",
      "       âœ… æˆåŠŸ\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š ç”Ÿæˆå®Œæˆ\n",
      "======================================================================\n",
      "   é—®ç­”å¯¹: 10/10\n",
      "   è®¾è®¡æ–¹æ¡ˆ: 5/5\n",
      "   æˆåŠŸç‡: 100.0%\n",
      "\n",
      "ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# é…ç½®ç”Ÿæˆå‚æ•°\n",
    "NUM_QA_PAIRS = 10      # é—®ç­”å¯¹æ•°é‡\n",
    "NUM_DESIGN = 5         # è®¾è®¡æ–¹æ¡ˆæ•°é‡\n",
    "USE_CONTEXT = True     # æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¢å¼º\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ æ‰¹é‡ç”Ÿæˆé…ç½®\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   é—®ç­”å¯¹æ•°é‡: {NUM_QA_PAIRS}\")\n",
    "print(f\"   è®¾è®¡æ–¹æ¡ˆæ•°é‡: {NUM_DESIGN}\")\n",
    "print(f\"   ä¸Šä¸‹æ–‡å¢å¼º: {USE_CONTEXT}\")\n",
    "print(f\"   é¢„è®¡è€—æ—¶: {(NUM_QA_PAIRS + NUM_DESIGN) * 15 / 60:.1f} åˆ†é’Ÿ\\n\")\n",
    "\n",
    "# æ‰§è¡Œæ‰¹é‡ç”Ÿæˆ\n",
    "dataset = generator.generate_batch(\n",
    "    num_qa=NUM_QA_PAIRS,\n",
    "    num_design=NUM_DESIGN,\n",
    "    use_context=USE_CONTEXT\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36ebda",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ­¥éª¤6: æ•°æ®è´¨é‡åˆ†æ\n",
    "\n",
    "åˆ†æç”Ÿæˆæ•°æ®çš„è´¨é‡æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "570ed3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š é—®ç­”å¯¹è´¨é‡åˆ†æ\n",
      "======================================================================\n",
      "   æ€»æ•°é‡: 10\n",
      "   å¹³å‡é—®é¢˜é•¿åº¦: 575 å­—ç¬¦\n",
      "   å¹³å‡ç­”æ¡ˆé•¿åº¦: 4396 å­—ç¬¦\n",
      "   å¹³å‡æ¨ç†æ­¥éª¤: 11.4 æ­¥\n",
      "\n",
      "   æ–‡ä»¶è¦†ç›–æ•°: 7\n",
      "   æ–‡ä»¶åˆ†å¸ƒ: {'generate_anatomy_mse_benchmark.py': 2, 'run_series_similarity.py': 2, 'run_series_conference.py': 2}\n",
      "\n",
      "   ã€ç¤ºä¾‹é—®ç­”å¯¹ã€‘\n",
      "   Q: The provided code snippet demonstrates a series of benchmarking steps for ontolo...\n",
      "   A: This code snippet reveals a robust and iterative evaluation strategy for the `on...\n",
      "\n",
      "======================================================================\n",
      "ğŸ—ï¸  è®¾è®¡æ–¹æ¡ˆè´¨é‡åˆ†æ\n",
      "======================================================================\n",
      "   æ€»æ•°é‡: 5\n",
      "   å¹³å‡å®æ–½æ­¥éª¤: 6.8 æ­¥\n",
      "   å¹³å‡ä¿®æ”¹æ–‡ä»¶: 8.4 ä¸ª\n",
      "\n",
      "   ã€ç¤ºä¾‹è®¾è®¡æ–¹æ¡ˆã€‘\n",
      "   éœ€æ±‚: æ‰©å±•run_series_conferenceä»¥æ”¯æŒå¼±ç½‘ç¯å¢ƒåœºæ™¯...\n",
      "   æ–¹æ¡ˆ: ä¸º `run_series_conference` å¼•å…¥å¼¹æ€§æœºåˆ¶ï¼Œä»¥åº”å¯¹å¼±ç½‘ç¯å¢ƒä¸‹çš„ç½‘ç»œå»¶è¿Ÿã€è¿æ¥ä¸­æ–­å’Œè¯·æ±‚è¶…æ—¶ç­‰é—®é¢˜ã€‚...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# ç»Ÿè®¡é—®ç­”å¯¹\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š é—®ç­”å¯¹è´¨é‡åˆ†æ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if dataset['qa_pairs']:\n",
    "    # åŸºç¡€ç»Ÿè®¡\n",
    "    total_qa = len(dataset['qa_pairs'])\n",
    "    avg_question_len = sum(len(qa['question']) for qa in dataset['qa_pairs']) / total_qa\n",
    "    avg_answer_len = sum(len(qa['answer']) for qa in dataset['qa_pairs']) / total_qa\n",
    "    avg_reasoning_steps = sum(len(qa['reasoning_steps']) for qa in dataset['qa_pairs']) / total_qa\n",
    "    \n",
    "    print(f\"   æ€»æ•°é‡: {total_qa}\")\n",
    "    print(f\"   å¹³å‡é—®é¢˜é•¿åº¦: {avg_question_len:.0f} å­—ç¬¦\")\n",
    "    print(f\"   å¹³å‡ç­”æ¡ˆé•¿åº¦: {avg_answer_len:.0f} å­—ç¬¦\")\n",
    "    print(f\"   å¹³å‡æ¨ç†æ­¥éª¤: {avg_reasoning_steps:.1f} æ­¥\")\n",
    "    \n",
    "    # æ–‡ä»¶åˆ†å¸ƒ\n",
    "    source_files = [qa.get('source_file', 'unknown') for qa in dataset['qa_pairs']]\n",
    "    file_dist = Counter(source_files)\n",
    "    print(f\"\\n   æ–‡ä»¶è¦†ç›–æ•°: {len(file_dist)}\")\n",
    "    print(f\"   æ–‡ä»¶åˆ†å¸ƒ: {dict(list(file_dist.most_common(3)))}\")\n",
    "    \n",
    "    # ç¤ºä¾‹å±•ç¤º\n",
    "    print(\"\\n   ã€ç¤ºä¾‹é—®ç­”å¯¹ã€‘\")\n",
    "    sample = dataset['qa_pairs'][0]\n",
    "    print(f\"   Q: {sample['question'][:80]}...\")\n",
    "    print(f\"   A: {sample['answer'][:80]}...\")\n",
    "else:\n",
    "    print(\"   âš ï¸  æœªç”Ÿæˆé—®ç­”å¯¹\")\n",
    "\n",
    "# ç»Ÿè®¡è®¾è®¡æ–¹æ¡ˆ\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ—ï¸  è®¾è®¡æ–¹æ¡ˆè´¨é‡åˆ†æ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if dataset['design_solutions']:\n",
    "    total_design = len(dataset['design_solutions'])\n",
    "    avg_steps = sum(len(d['steps']) for d in dataset['design_solutions']) / total_design\n",
    "    avg_files = sum(len(d['files_to_modify']) for d in dataset['design_solutions']) / total_design\n",
    "    \n",
    "    print(f\"   æ€»æ•°é‡: {total_design}\")\n",
    "    print(f\"   å¹³å‡å®æ–½æ­¥éª¤: {avg_steps:.1f} æ­¥\")\n",
    "    print(f\"   å¹³å‡ä¿®æ”¹æ–‡ä»¶: {avg_files:.1f} ä¸ª\")\n",
    "    \n",
    "    # ç¤ºä¾‹å±•ç¤º\n",
    "    print(\"\\n   ã€ç¤ºä¾‹è®¾è®¡æ–¹æ¡ˆã€‘\")\n",
    "    sample = dataset['design_solutions'][0]\n",
    "    print(f\"   éœ€æ±‚: {sample['requirement'][:60]}...\")\n",
    "    print(f\"   æ–¹æ¡ˆ: {sample['solution'][:60]}...\")\n",
    "else:\n",
    "    print(\"   âš ï¸  æœªç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d744f",
   "metadata": {},
   "source": [
    "## ğŸ’¾ æ­¥éª¤7: ä¿å­˜è®­ç»ƒæ•°æ®\n",
    "\n",
    "å°†æ•°æ®ä¿å­˜ä¸ºJSONæ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e76bc51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ æ•°æ®å·²ä¿å­˜: outputs/ontology-llm/training_data_20251219_162158.json\n",
      "   æ–‡ä»¶å¤§å°: 174.8 KB\n",
      "\n",
      "âœ… æ–‡ä»¶å·²ä¿å­˜\n",
      "   è·¯å¾„: outputs/ontology-llm/training_data_20251219_162158.json\n",
      "   å¤§å°: 174.8 KB\n",
      "   é—®ç­”å¯¹: 10\n",
      "   è®¾è®¡æ–¹æ¡ˆ: 5\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "project_name = project_path.name\n",
    "output_file = f\"outputs/{project_name}/training_data_{timestamp}.json\"\n",
    "\n",
    "# ä¿å­˜æ•°æ®\n",
    "generator.save_dataset(dataset, output_file)\n",
    "\n",
    "# éªŒè¯æ–‡ä»¶\n",
    "output_path = Path(output_file)\n",
    "if output_path.exists():\n",
    "    file_size = output_path.stat().st_size\n",
    "    print(f\"\\nâœ… æ–‡ä»¶å·²ä¿å­˜\")\n",
    "    print(f\"   è·¯å¾„: {output_path}\")\n",
    "    print(f\"   å¤§å°: {file_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # è¯»å–éªŒè¯\n",
    "    with open(output_path, 'r', encoding='utf-8') as f:\n",
    "        loaded = json.load(f)\n",
    "    print(f\"   é—®ç­”å¯¹: {len(loaded['qa_pairs'])}\")\n",
    "    print(f\"   è®¾è®¡æ–¹æ¡ˆ: {len(loaded['design_solutions'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4c32a",
   "metadata": {},
   "source": [
    "## ğŸ“ æ­¥éª¤8: æ•°æ®é¢„è§ˆ\n",
    "\n",
    "æŸ¥çœ‹å®Œæ•´çš„è®­ç»ƒæ•°æ®æ ·æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a89489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“ å®Œæ•´é—®ç­”å¯¹ç¤ºä¾‹\n",
      "======================================================================\n",
      "{\n",
      "  \"question\": \"The provided code snippet demonstrates a series of benchmarking steps for ontology alignment across different years (2022 and 2023) using distinct file paths and functions like `find_alignment` and `util.calculate_benchmark_metrics`. Given the broader context of an `ontology-llm` project, what does this specific structure of benchmarking reveal about the evaluation strategy for LLM-based ontology alignment? Furthermore, how do the varying file paths and the sequential nature of these calls (e.g., 2022 vs. 2023 data) contribute to assessing the maturity or iterative improvement of the `llm_matching` or `llm_om_zero_shot` components over time, especially considering potential changes in benchmark datasets or alignment algorithms?\",\n",
      "  \"answer\": \"This code snippet reveals a robust and iterative evaluation strategy for the `ontology-llm` project, designed to systematically benchmark the performance and track the evolution of LLM-based ontology alignment techniques.\\n\\n**Evaluation Strategy for LLM-based Ontology Alignment:**\\n\\n1.  **Metric-Driven Assessment:** The core of the strategy is the calculation of standard information retrieval metrics (Precision, Recall, F1) via `util.calculate_benchmark_metrics`. This requires:\\n    *   **Ground Truth (`true.csv`):** Files like `\\\"benchmark_2022/mse/secondTestCase/true.csv\\\"` store the human-validated correct alignments. The `find_alignment` function is used to prepare these ground truths, potentially parsing reference alignments from XML (`reference.xml`) or existing tool outputs (`LogMap.rdf`) into a standardized CSV format for consistent evaluation.\\n    *   **System Predictions (`predict.csv`):** The `predict.csv` (e.g., `\\\"alignment/mse/MaterialInformation-MatOnto/component/predict.csv\\\"`) holds the alignment candidates generated by the LLM-based matching components (`llm_matching` or `llm_om_zero_shot`). Although not explicitly shown generating `predict.csv`, its presence is critical for comparison.\\n    *   **Result Storage (`result.csv`):** `util.create_document` initializes output files (e.g., `\\\"benchmark_2023/mse/secondTestCase/result.csv\\\"`) where the calculated Precision, Recall, and F1 scores are stored, providing a clear record of performance.\\n\\n2.  **Dataset Specificity:** Paths like `\\\"data/mse/MaterialInformation-MatOnto/component/reference.xml\\\"` indicate that benchmarking is performed on specific ontology pairs (e.g., \\\"MaterialInformation\\\" and \\\"MatOnto\\\"). This domain-specific evaluation within an \\\"mse\\\" (likely Materials Science and Engineering) context ensures the LLM's applicability and performance in relevant knowledge domains.\\n\\n3.  **Baseline Comparison:** The inclusion of `\\\"benchmark_2023/mse/secondTestCase/LogMap.rdf\\\"` implies that the LLM-based approach is being benchmarked against established, state-of-the-art traditional ontology matching tools like LogMap. This provides a crucial baseline to contextualize the performance of the LLM system â€“ demonstrating whether it performs comparably, better, or worse than non-LLM methods. The `find_alignment` function likely converts LogMap's native RDF output into the CSV format for uniform metric calculation.\\n\\n**Contribution to Assessing Maturity and Iterative Improvement:**\\n\\nThe sequential nature and varying file paths across 2022 and 2023 are central to tracking the project's progress:\\n\\n1.  **Temporal Performance Tracking:**\\n    *   The distinct `benchmark_2022` and `benchmark_2023` directories allow for direct year-over-year comparison. This is vital for assessing whether the `llm_matching` or `llm_om_zero_shot` components have improved in accuracy, robustness, or efficiency over time.\\n    *   By potentially re-evaluating the current LLM system against older (2022) benchmarks, developers can ensure that new improvements haven't introduced regressions. Conversely, running against newer (2023) benchmarks tests the system's performance on potentially updated or more challenging datasets.\\n\\n2.  **Refinement of Benchmark Datasets:** The differing `true.csv` and `reference.xml` paths for 2022 and 2023 (e.g., the specific `MaterialInformation-MatOnto` for 2023 vs. a more generic `Matcha` for 2022) suggest that the benchmark datasets themselves might be evolving. This could mean:\\n    *   Newer, more complex, or larger ontologies are being used.\\n    *   Ground truth alignments are being refined or expanded.\\n    *   The project is targeting different sets of alignment challenges in different years.\\n\\n3.  **Informing Iterative Development:**\\n    *   **Feedback Loop:** The quantitative results (Precision, Recall, F1) generated from these benchmarks provide concrete feedback to the development team. Poor performance in certain areas can guide efforts to refine LLM prompts, improve fine-tuning datasets, enhance post-processing heuristics, or explore different LLM architectures for the `llm_matching` and `llm_om_zero_shot` modules.\\n    *   **Demonstrating Progress:** Consistently tracking these metrics across benchmark versions and years allows the project to demonstrate tangible improvements, justify design changes, and validate the effectiveness of LLM integration into ontology alignment.\\n    *   **Reproducibility and Comparability:** Maintaining a structured benchmark environment ensures that results are reproducible and comparable across different iterations of the `ontology-llm` system.\\n\\nIn summary, this benchmarking setup facilitates a rigorous, data-driven approach to developing and validating LLM-powered ontology alignment solutions, allowing for continuous improvement and objective assessment against both internal progression and external baselines.\",\n",
      "  \"reasoning_steps\": [\n",
      "    \"**Metric-Driven Assessment:** The core of the strategy is the calculation of standard information retrieval metrics (Precision, Recall, F1) via `util.calculate_benchmark_metrics`. This requires:\\n    *   **Ground Truth (`true.csv`):** Files like `\\\"benchmark_2022/mse/secondTestCase/true.csv\\\"` store the human-validated correct alignments. The `find_alignment` function is used to prepare these ground truths, potentially parsing reference alignments from XML (`reference.xml`) or existing tool outputs (`LogMap.rdf`) into a standardized CSV format for consistent evaluation.\\n    *   **System Predictions (`predict.csv`):** The `predict.csv` (e.g., `\\\"alignment/mse/MaterialInformation-MatOnto/component/predict.csv\\\"`) holds the alignment candidates generated by the LLM-based matching components (`llm_matching` or `llm_om_zero_shot`). Although not explicitly shown generating `predict.csv`, its presence is critical for comparison.\\n    *   **Result Storage (`result.csv`):** `util.create_document` initializes output files (e.g., `\\\"benchmark_2023/mse/secondTestCase/result.csv\\\"`) where the calculated Precision, Recall, and F1 scores are stored, providing a clear record of performance.\",\n",
      "    \"**Dataset Specificity:** Paths like `\\\"data/mse/MaterialInformation-MatOnto/component/reference.xml\\\"` indicate that benchmarking is performed on specific ontology pairs (e.g., \\\"MaterialInformation\\\" and \\\"MatOnto\\\"). This domain-specific evaluation within an \\\"mse\\\" (likely Materials Science and Engineering) context ensures the LLM's applicability and performance in relevant knowledge domains.\",\n",
      "    \"**Baseline Comparison:** The inclusion of `\\\"benchmark_2023/mse/secondTestCase/LogMap.rdf\\\"` implies that the LLM-based approach is being benchmarked against established, state-of-the-art traditional ontology matching tools like LogMap. This provides a crucial baseline to contextualize the performance of the LLM system â€“ demonstrating whether it performs comparably, better, or worse than non-LLM methods. The `find_alignment` function likely converts LogMap's native RDF output into the CSV format for uniform metric calculation.\",\n",
      "    \"**Temporal Performance Tracking:**\\n    *   The distinct `benchmark_2022` and `benchmark_2023` directories allow for direct year-over-year comparison. This is vital for assessing whether the `llm_matching` or `llm_om_zero_shot` components have improved in accuracy, robustness, or efficiency over time.\\n    *   By potentially re-evaluating the current LLM system against older (2022) benchmarks, developers can ensure that new improvements haven't introduced regressions. Conversely, running against newer (2023) benchmarks tests the system's performance on potentially updated or more challenging datasets.\",\n",
      "    \"**Refinement of Benchmark Datasets:** The differing `true.csv` and `reference.xml` paths for 2022 and 2023 (e.g., the specific `MaterialInformation-MatOnto` for 2023 vs. a more generic `Matcha` for 2022) suggest that the benchmark datasets themselves might be evolving. This could mean:\\n    *   Newer, more complex, or larger ontologies are being used.\\n    *   Ground truth alignments are being refined or expanded.\\n    *   The project is targeting different sets of alignment challenges in different years.\",\n",
      "    \"**Informing Iterative Development:**\\n    *   **Feedback Loop:** The quantitative results (Precision, Recall, F1) generated from these benchmarks provide concrete feedback to the development team. Poor performance in certain areas can guide efforts to refine LLM prompts, improve fine-tuning datasets, enhance post-processing heuristics, or explore different LLM architectures for the `llm_matching` and `llm_om_zero_shot` modules.\\n    *   **Demonstrating Progress:** Consistently tracking these metrics across benchmark versions and years allows the project to demonstrate tangible improvements, justify design changes, and validate the effectiveness of LLM integration into ontology alignment.\\n    *   **Reproducibility and Comparability:** Maintaining a structured benchmark environment ensures that results are reproducible and comparable across different iterations of the `ontology-llm` system.\",\n",
      "    \"**Analyze Function Calls and File Paths:**\\n    *   `util.calculate_benchmark_metrics(true.csv, predict.csv, result.csv, \\\"Agent-OM\\\")`: This clearly indicates performance measurement using ground truth (`true.csv`) and system output (`predict.csv`), storing results in `result.csv`. The \\\"Agent-OM\\\" suggests a specific system or configuration being evaluated.\\n    *   `util.create_document(\\\"benchmark_2023/mse/secondTestCase/result.csv\\\", header=...)`: This prepares a file to store metrics for 2023.\\n    *   `find_alignment(\\\"data/mse/MaterialInformation-MatOnto/component/reference.xml\\\", \\\"benchmark_2023/mse/secondTestCase/true.csv\\\")`: This suggests extracting or processing ground truth from an XML reference for a specific ontology pair (\\\"MaterialInformation-MatOnto\\\") for the 2023 benchmark.\\n    *   `find_alignment(\\\"benchmark_2023/mse/secondTestCase/LogMap.rdf\\\", \\\"benchmark_202...\\\")`: This indicates processing the output of a known ontology matching tool (LogMap) for 2023, likely to create a baseline for comparison.\\n    *   The presence of `benchmark_2022` and `benchmark_2023` directories points to temporal evaluation.\",\n",
      "    \"**Integrate Project Context (`ontology-llm`, core modules/functions):**\\n    *   The project name `ontology-llm` implies that Large Language Models are used for ontology matching.\\n    *   The listed core modules like `llm_om_zero_shot` and `llm_matching` are the components whose performance is being evaluated by these benchmarks.\\n    *   `find_alignment` is a core function, thus it plays a significant role in preparing or processing alignment data.\",\n",
      "    \"**Deduce Evaluation Strategy:**\\n    *   The pattern of `true.csv` vs `predict.csv` for metric calculation is standard for supervised evaluation tasks.\\n    *   The use of XML (`reference.xml`) and RDF (`LogMap.rdf`) for input, and CSV for internal processing, highlights the need for data format consistency for metric calculation.\\n    *   The inclusion of LogMap as a source indicates a strategy of comparing against established baselines to assess the relative performance of the LLM-based approach.\",\n",
      "    \"**Infer Contribution to Iterative Improvement:**\\n    *   **Temporal Distinction:** The clear separation of 2022 and 2023 benchmarks suggests a strategy for tracking progress year-over-year. This allows for assessing improvements to the LLM models or matching algorithms (`llm_matching`, `llm_om_zero_shot`) between different development cycles.\\n    *   **Benchmark Evolution:** Different file paths for `true.csv` or source references in 2022 versus 2023 imply that either the specific ontology alignment tasks are changing, or the ground truth sets are being updated/expanded, which are common practices in iterative benchmark development.\\n    *   **Feedback Loop:** The quantified metrics (Precision, Recall, F1) provide direct feedback to developers, guiding subsequent modifications to the LLM prompts, fine-tuning data, or post-processing logic to enhance performance on identified weaknesses.\\n    *   **Demonstration of Maturity:** Consistent and improving results across these benchmarks would demonstrate the increasing maturity and effectiveness of the `ontology-llm` system.\"\n",
      "  ],\n",
      "  \"code_context\": \"   \\\"benchmark_2022/mse/secondTestCase/Matcha.csv\\\",\\n                                     \\\"benchmark_2022/mse/secondTestCase/result.csv\\\", \\\"Matcha\\\")\\n    util.calculate_benchmark_metrics(\\\"benchmark_2022/mse/secondTestCase/true.csv\\\",\\n                                     \\\"alignment/mse/MaterialInformation-MatOnto/component/predict.csv\\\",\\n                                     \\\"benchmark_2022/mse/secondTestCase/result.csv\\\", \\\"Agent-OM\\\")\\n\\n    # 2023 results\\n    util.create_document(\\\"benchmark_2023/mse/secondTestCase/result.csv\\\", header=['Name', 'Precision', 'Recall', 'F1'])\\n\\n    find_alignment(\\\"data/mse/MaterialInformation-MatOnto/component/reference.xml\\\",\\n                   \\\"benchmark_2023/mse/secondTestCase/true.csv\\\")\\n\\n    find_alignment(\\\"benchmark_2023/mse/secondTestCase/LogMap.rdf\\\", \\\"benchmark_202\",\n",
      "  \"source_file\": \"generate_anatomy_mse_benchmark.py\",\n",
      "  \"metadata\": {\n",
      "    \"model\": \"gemini-2.5-flash\",\n",
      "    \"temperature\": 0.3,\n",
      "    \"timestamp\": \"2025-12-19T16:16:09.135542\",\n",
      "    \"context_enabled\": true\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ—ï¸  å®Œæ•´è®¾è®¡æ–¹æ¡ˆç¤ºä¾‹\n",
      "======================================================================\n",
      "{\n",
      "  \"requirement\": \"æ‰©å±•run_series_conferenceä»¥æ”¯æŒå¼±ç½‘ç¯å¢ƒåœºæ™¯\",\n",
      "  \"solution\": \"ä¸º `run_series_conference` å¼•å…¥å¼¹æ€§æœºåˆ¶ï¼Œä»¥åº”å¯¹å¼±ç½‘ç¯å¢ƒä¸‹çš„ç½‘ç»œå»¶è¿Ÿã€è¿æ¥ä¸­æ–­å’Œè¯·æ±‚è¶…æ—¶ç­‰é—®é¢˜ã€‚æ ¸å¿ƒç­–ç•¥åŒ…æ‹¬ï¼š\\n1.  **è¯·æ±‚é‡è¯• (Retry Mechanism)**: å¯¹ LLM API è°ƒç”¨å¢åŠ è‡ªåŠ¨é‡è¯•é€»è¾‘ï¼Œæ”¯æŒæŒ‡æ•°é€€é¿ (Exponential Backoff)ï¼Œä»¥åº”å¯¹ç¬æ—¶ç½‘ç»œæ•…éšœæˆ–æœåŠ¡ä¸ç¨³å®šã€‚\\n2.  **å¯é…ç½®è¶…æ—¶ (Configurable Timeouts)**: å…è®¸ç”¨æˆ·ä¸º LLM API è¯·æ±‚è®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œé˜²æ­¢å› ç½‘ç»œé˜»å¡å¯¼è‡´é•¿æ—¶é—´æŒ‚èµ·ã€‚\\n3.  **è¿›åº¦ä¿å­˜ä¸æ¢å¤ (Checkpointing)**: å¯¹äºé•¿æ—¶é—´è¿è¡Œçš„ `run_series_conference` ä»»åŠ¡ï¼Œå®ç°ä¸­é—´ç»“æœçš„å®šæœŸä¿å­˜ï¼Œå¹¶åœ¨ä»»åŠ¡ä¸­æ–­åèƒ½å¤Ÿä»ä¸Šæ¬¡ä¿å­˜ç‚¹æ¢å¤ï¼Œé¿å…é‡å¤è®¡ç®—å’Œæµªè´¹èµ„æºã€‚\\n4.  **è¯¦ç»†æ—¥å¿— (Detailed Logging)**: å¢å¼ºæ—¥å¿—è¾“å‡ºï¼Œè®°å½•é‡è¯•å°è¯•ã€è¶…æ—¶äº‹ä»¶å’Œæ¢å¤è¿›åº¦ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥å’Œè¿è¡ŒçŠ¶æ€ç›‘æ§ã€‚\\n\\né€šè¿‡å°†é‡è¯•å’Œè¶…æ—¶é€»è¾‘å°è£…åœ¨ `util` æ¨¡å—ä¸­ï¼Œå¹¶åº”ç”¨äº `llm_om_zero_shot` å’Œ `llm_matching` ç­‰æ ¸å¿ƒ LLM è°ƒç”¨æ¨¡å—ï¼Œæˆ‘ä»¬å¯ä»¥ä¿æŒ `run_series_conference` çš„é«˜å±‚åè°ƒèŒè´£ï¼ŒåŒæ—¶ä½¿å…¶åº•å±‚æ“ä½œæ›´å…·éŸ§æ€§ã€‚\",\n",
      "  \"steps\": [\n",
      "    \"**è¯·æ±‚é‡è¯• (Retry Mechanism)**: å¯¹ LLM API è°ƒç”¨å¢åŠ è‡ªåŠ¨é‡è¯•é€»è¾‘ï¼Œæ”¯æŒæŒ‡æ•°é€€é¿ (Exponential Backoff)ï¼Œä»¥åº”å¯¹ç¬æ—¶ç½‘ç»œæ•…éšœæˆ–æœåŠ¡ä¸ç¨³å®šã€‚\",\n",
      "    \"**å¯é…ç½®è¶…æ—¶ (Configurable Timeouts)**: å…è®¸ç”¨æˆ·ä¸º LLM API è¯·æ±‚è®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œé˜²æ­¢å› ç½‘ç»œé˜»å¡å¯¼è‡´é•¿æ—¶é—´æŒ‚èµ·ã€‚\",\n",
      "    \"**è¿›åº¦ä¿å­˜ä¸æ¢å¤ (Checkpointing)**: å¯¹äºé•¿æ—¶é—´è¿è¡Œçš„ `run_series_conference` ä»»åŠ¡ï¼Œå®ç°ä¸­é—´ç»“æœçš„å®šæœŸä¿å­˜ï¼Œå¹¶åœ¨ä»»åŠ¡ä¸­æ–­åèƒ½å¤Ÿä»ä¸Šæ¬¡ä¿å­˜ç‚¹æ¢å¤ï¼Œé¿å…é‡å¤è®¡ç®—å’Œæµªè´¹èµ„æºã€‚\",\n",
      "    \"**è¯¦ç»†æ—¥å¿— (Detailed Logging)**: å¢å¼ºæ—¥å¿—è¾“å‡ºï¼Œè®°å½•é‡è¯•å°è¯•ã€è¶…æ—¶äº‹ä»¶å’Œæ¢å¤è¿›åº¦ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥å’Œè¿è¡ŒçŠ¶æ€ç›‘æ§ã€‚\",\n",
      "    \"**åœ¨ `util.py` ä¸­å®ç°é€šç”¨çš„é‡è¯•è£…é¥°å™¨/å‡½æ•°:**\\n    *   **ç›®æ ‡:** åˆ›å»ºä¸€ä¸ª `retry_with_backoff` è£…é¥°å™¨æˆ–å‡½æ•°ï¼Œå®ƒå¯ä»¥åŒ…è£¹ä»»ä½•å¯èƒ½å¤±è´¥çš„å‡½æ•°è°ƒç”¨ã€‚\\n    *   **åŠŸèƒ½:**\\n        *   æ¥æ”¶å‚æ•°ï¼š`max_retries` (æœ€å¤§é‡è¯•æ¬¡æ•°), `initial_delay` (åˆå§‹ç­‰å¾…æ—¶é—´), `backoff_factor` (é€€é¿å› å­), `exceptions_to_retry` (éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹ï¼Œä¾‹å¦‚ç½‘ç»œç›¸å…³çš„å¼‚å¸¸å¦‚ `requests.exceptions.ConnectionError`, `requests.exceptions.Timeout` ç­‰)ã€‚\\n        *   å®ç°æŒ‡æ•°é€€é¿é€»è¾‘ï¼šæ¯æ¬¡é‡è¯•å¤±è´¥åï¼Œç­‰å¾…æ—¶é—´æŒ‰ `delay = initial_delay * (backoff_factor ** (attempt - 1))` å¢é•¿ã€‚\\n        *   è®°å½•æ¯æ¬¡é‡è¯•çš„çŠ¶æ€å’Œé‡åˆ°çš„å¼‚å¸¸ã€‚\\n        *   åœ¨è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°åï¼Œå¦‚æœä»ç„¶å¤±è´¥ï¼Œåˆ™æŠ›å‡ºæœ€åçš„å¼‚å¸¸ã€‚\\n    *   **ç¤ºä¾‹ä¼ªä»£ç :**\\n        ```python\\n        # util.py\\n        import time\\n        import functools\\n        import logging\\n        import requests # Assuming LLM calls use requests or similar lib\",\n",
      "    \"**åœ¨ `llm_om_zero_shot.py` å’Œ `llm_matching.py` ä¸­åº”ç”¨é‡è¯•å’Œè¶…æ—¶:**\\n    *   **ç›®æ ‡:** è¯†åˆ«è¿™äº›æ¨¡å—ä¸­ç›´æ¥ä¸å¤–éƒ¨ LLM æœåŠ¡è¿›è¡Œ API äº¤äº’çš„å‡½æ•°ã€‚\\n    *   **ä¿®æ”¹:**\\n        *   å¯¼å…¥ `util.py` ä¸­å®ç°çš„ `retry_with_backoff` è£…é¥°å™¨ã€‚\\n        *   å°†è¯¥è£…é¥°å™¨åº”ç”¨äºæ‰§è¡Œ LLM API è°ƒç”¨çš„å‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œ`call_llm_api`, `perform_matching_query` ç­‰ï¼‰ã€‚\\n        *   ç¡®ä¿åº•å±‚çš„ HTTP å®¢æˆ·ç«¯ï¼ˆå¦‚ `requests`ï¼‰è°ƒç”¨åŒ…å«äº† `timeout` å‚æ•°ï¼Œå¹¶ä¸”è¿™ä¸ªè¶…æ—¶å€¼å¯ä»¥ä»ä¸Šå±‚é…ç½®ä¼ å…¥ã€‚\\n    *   **ç¤ºä¾‹ä¼ªä»£ç  (é’ˆå¯¹ `llm_om_zero_shot.py`):**\\n        ```python\\n        # llm_om_zero_shot.py\\n        from .util import retry_with_backoff # å‡è®¾utilåœ¨åŒçº§æˆ–å¯å¯¼å…¥è·¯å¾„\\n        import requests\\n        import logging\",\n",
      "    \"**åœ¨ `run_series_conference.py` ä¸­é›†æˆé…ç½®å’Œå®ç°è¿›åº¦ä¿å­˜/æ¢å¤:**\\n    *   **ç›®æ ‡:** `run_series_conference` æ˜¯æ ¸å¿ƒåè°ƒå™¨ï¼Œå®ƒéœ€è¦èƒ½å¤Ÿæ¥æ”¶å’Œä¼ é€’é‡è¯•ã€è¶…æ—¶é…ç½®ï¼Œå¹¶ç®¡ç†æ•´ä¸ªç³»åˆ—ä»»åŠ¡çš„æ‰§è¡Œè¿›åº¦ã€‚\\n    *   **ä¿®æ”¹:**\\n        *   **é…ç½®å‚æ•°:** å¼•å…¥æ–°çš„å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®é¡¹ï¼Œä¾‹å¦‚ `--max-llm-retries`, `--llm-timeout`, `--checkpoint-file`, `--enable-checkpointing` ç­‰ã€‚\\n        *   **ä¼ é€’é…ç½®:** å°†è¿™äº›é…ç½®å‚æ•°ä¼ é€’ç»™è°ƒç”¨çš„ `llm_om_zero_shot` å’Œ `llm_matching` æ¨¡å—ä¸­çš„å‡½æ•°ã€‚\\n        *   **è¿›åº¦ä¿å­˜:**\\n            *   åœ¨ `run_series_conference` çš„å¾ªç¯ä¸­ï¼Œå®šä¹‰ä¸€ä¸ª checkpoint æ–‡ä»¶è·¯å¾„ã€‚\\n            *   å®šæœŸï¼ˆä¾‹å¦‚ï¼Œæ¯å¤„ç† N ä¸ª conference æˆ–æ¯éš”ä¸€æ®µæ—¶é—´ï¼‰å°†å½“å‰çš„æ‰§è¡Œè¿›åº¦ã€å·²å®Œæˆçš„ conference åˆ—è¡¨ã€å·²è·å¾—çš„ä¸­é—´ç»“æœä¿å­˜åˆ° checkpoint æ–‡ä»¶ï¼ˆä¾‹å¦‚ JSON æˆ– pickle æ ¼å¼ï¼‰ã€‚\\n            *   ç¡®ä¿ä¿å­˜æ“ä½œæ˜¯åŸå­æ€§çš„ï¼ˆä¾‹å¦‚ï¼Œå…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½åï¼‰ã€‚\\n        *   **è¿›åº¦æ¢å¤:**\\n            *   åœ¨ `run_series_conference` å¯åŠ¨æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨ checkpoint æ–‡ä»¶ã€‚\\n            *   å¦‚æœå­˜åœ¨ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦ä» checkpoint æ¢å¤ï¼Œå¹¶åŠ è½½ä¸Šæ¬¡ä¿å­˜çš„çŠ¶æ€ã€‚\\n            *   æ ¹æ®åŠ è½½çš„çŠ¶æ€ï¼Œè·³è¿‡å·²å®Œæˆçš„ conferenceï¼Œä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œã€‚\\n        *   **é”™è¯¯å¤„ç†:** å³ä½¿é‡è¯•æœºåˆ¶å·²ç»å¤„ç†äº†åº•å±‚ç½‘ç»œé”™è¯¯ï¼Œ`run_series_conference` ä¹Ÿåº”è¯¥æ•è·å¹¶è®°å½•æ›´é«˜çº§åˆ«çš„é€»è¾‘é”™è¯¯ï¼Œç¡®ä¿å³ä½¿æœ€ç»ˆå¤±è´¥ï¼Œä¹Ÿèƒ½ä¿å­˜å½“å‰è¿›åº¦å¹¶æ¸…æ™°æŠ¥å‘Šé—®é¢˜ã€‚\\n    *   **ç¤ºä¾‹ä¼ªä»£ç  (é’ˆå¯¹ `run_series_conference.py`):**\\n        ```python\\n        # run_series_conference.py\\n        import argparse\\n        import json\\n        import os\\n        import logging\\n        from .llm_om_zero_shot import query_llm_for_ontology_matching # å‡è®¾å·²å¯¼å…¥\",\n",
      "    \"**æ›´æ–° `generate_conference_benchmark.py` (æˆ–ä¸»å…¥å£ç‚¹):**\\n    *   **ç›®æ ‡:** å¦‚æœ `generate_conference_benchmark.py` æ˜¯æ•´ä¸ªä»»åŠ¡çš„å¯åŠ¨è„šæœ¬ï¼Œå®ƒéœ€è¦æš´éœ²å¹¶æ¥æ”¶ä¸Šè¿°æ–°çš„é…ç½®å‚æ•°ã€‚\\n    *   **ä¿®æ”¹:** åœ¨ `ArgumentParser` ä¸­æ·»åŠ  `--llm-timeout`, `--max-llm-retries`, `--checkpoint-file`, `--enable-checkpointing`, `--checkpoint-interval` ç­‰å‚æ•°ï¼Œå¹¶å°†å®ƒä»¬ä¼ é€’ç»™ `run_series_conference` å‡½æ•°ã€‚\",\n",
      "    \"**åŒºåˆ†å¯é‡è¯•é”™è¯¯ä¸éå¯é‡è¯•é”™è¯¯:**\\n    *   **æŒ‘æˆ˜:** å¹¶éæ‰€æœ‰é”™è¯¯éƒ½åº”è¯¥é‡è¯•ã€‚ä¾‹å¦‚ï¼Œ400 Bad Request (å®¢æˆ·ç«¯è¯·æ±‚é”™è¯¯) æ˜¯é€»è¾‘é”™è¯¯ï¼Œé‡è¯•æ— æ„ä¹‰ï¼›è€Œ 503 Service Unavailable (æœåŠ¡æš‚æ—¶ä¸å¯ç”¨) æˆ–ç½‘ç»œè¿æ¥ä¸­æ–­åˆ™æ˜¯å¯é‡è¯•çš„ã€‚æ­£ç¡®è¯†åˆ«å’Œé…ç½® `exceptions_to_retry` è‡³å…³é‡è¦ã€‚\\n    *   **è§£å†³æ–¹æ¡ˆ:** ä»”ç»†ç ”ç©¶ LLM API å®¢æˆ·ç«¯å¯èƒ½æŠ›å‡ºçš„å¼‚å¸¸ç±»å‹ï¼Œå¹¶ä»…å°†ç½‘ç»œç›¸å…³ã€æœåŠ¡æš‚æ—¶æ€§é”™è¯¯åŠ å…¥é‡è¯•åˆ—è¡¨ã€‚å¯¹äº 4xx ç­‰å®¢æˆ·ç«¯é”™è¯¯ï¼Œåº”ç«‹å³æŠ¥å‘Šå¹¶åœæ­¢ã€‚\",\n",
      "    \"**æ£€æŸ¥ç‚¹ (Checkpointing) çš„æ•°æ®ä¸€è‡´æ€§ä¸åŸå­æ€§:**\\n    *   **æŒ‘æˆ˜:** åœ¨ä¿å­˜ä¸­é—´ç»“æœæ—¶ï¼Œå¦‚æœå†™å…¥æ“ä½œæœ¬èº«å¤±è´¥ï¼ˆä¾‹å¦‚ç£ç›˜ç©ºé—´ä¸è¶³ã€I/O é”™è¯¯ï¼‰ï¼Œå¯èƒ½å¯¼è‡´æ£€æŸ¥ç‚¹æ–‡ä»¶æŸåï¼Œç”šè‡³ä¸¢å¤±ä¹‹å‰å·²å®Œæˆçš„è¿›åº¦ã€‚\\n    *   **è§£å†³æ–¹æ¡ˆ:** é‡‡ç”¨åŸå­æ€§å†™å…¥ç­–ç•¥ï¼Œä¾‹å¦‚å…ˆå°†æ•°æ®å†™å…¥ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ï¼ŒæˆåŠŸåå†å°†ä¸´æ—¶æ–‡ä»¶é‡å‘½åä¸ºå®é™…çš„æ£€æŸ¥ç‚¹æ–‡ä»¶ (`os.replace`)ã€‚åŒæ—¶ï¼Œåœ¨åŠ è½½æ£€æŸ¥ç‚¹æ—¶å¢åŠ å¥å£®çš„é”™è¯¯å¤„ç†ï¼Œå³ä½¿æ–‡ä»¶æŸåä¹Ÿèƒ½ä¼˜é›…åœ°å¯åŠ¨ã€‚\"\n",
      "  ],\n",
      "  \"files_to_modify\": [\n",
      "    {\n",
      "      \"file\": \"1))` å¢é•¿ã€‚\\n        *   è®°å½•æ¯æ¬¡é‡è¯•çš„çŠ¶æ€å’Œé‡åˆ°çš„å¼‚å¸¸ã€‚\\n        *   åœ¨è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°åï¼Œå¦‚æœä»ç„¶å¤±è´¥ï¼Œåˆ™æŠ›å‡ºæœ€åçš„å¼‚å¸¸ã€‚\\n    *   **ç¤ºä¾‹ä¼ªä»£ç \",\n",
      "      \"reason\": \"**\\n        ```python\\n        # util.py\\n        import time\\n        import functools\\n        import logging\\n        import requests # Assuming LLM calls use requests or similar lib\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"raise after logging, retry_with_backoff will catch it\\n            except requests.exceptions.RequestException as e\",\n",
      "      \"reason\": \"logger.error(f\\\"LLM query failed: {e}\\\")\\n                raise # Re-raise after logging, retry_with_backoff will catch it\\n        ```\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"-max-llm-retries`, `--llm-timeout`, `--checkpoint-file`, `--enable-checkpointing` ç­‰ã€‚\\n        *   **ä¼ é€’é…ç½®\",\n",
      "      \"reason\": \"** å°†è¿™äº›é…ç½®å‚æ•°ä¼ é€’ç»™è°ƒç”¨çš„ `llm_om_zero_shot` å’Œ `llm_matching` æ¨¡å—ä¸­çš„å‡½æ•°ã€‚\\n        *   **è¿›åº¦ä¿å­˜:**\\n            *   åœ¨ `run_series_conference` çš„å¾ªç¯ä¸­ï¼Œå®šä¹‰ä¸€ä¸ª checkpoint æ–‡ä»¶è·¯å¾„ã€‚\\n            *   å®šæœŸï¼ˆä¾‹å¦‚ï¼Œæ¯å¤„ç† N ä¸ª conference æˆ–æ¯éš”ä¸€æ®µæ—¶é—´ï¼‰å°†å½“å‰çš„æ‰§è¡Œè¿›åº¦ã€å·²å®Œæˆçš„ conference åˆ—è¡¨ã€å·²è·å¾—çš„ä¸­é—´ç»“æœä¿å­˜åˆ° checkpoint æ–‡ä»¶ï¼ˆä¾‹å¦‚ JSON æˆ– pickle æ ¼å¼ï¼‰ã€‚\\n            *   ç¡®ä¿ä¿å­˜æ“ä½œæ˜¯åŸå­æ€§çš„ï¼ˆä¾‹å¦‚ï¼Œå…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½åï¼‰ã€‚\\n        *   **è¿›åº¦æ¢å¤:**\\n            *   åœ¨ `run_series_conference` å¯åŠ¨æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨ checkpoint æ–‡ä»¶ã€‚\\n            *   å¦‚æœå­˜åœ¨ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦ä» checkpoint æ¢å¤ï¼Œå¹¶åŠ è½½ä¸Šæ¬¡ä¿å­˜çš„çŠ¶æ€ã€‚\\n            *   æ ¹æ®åŠ è½½çš„çŠ¶æ€ï¼Œè·³è¿‡å·²å®Œæˆçš„ conferenceï¼Œä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­æ‰§è¡Œã€‚\\n        *   **é”™è¯¯å¤„ç†:** å³ä½¿é‡è¯•æœºåˆ¶å·²ç»å¤„ç†äº†åº•å±‚ç½‘ç»œé”™è¯¯ï¼Œ`run_series_conference` ä¹Ÿåº”è¯¥æ•è·å¹¶è®°å½•æ›´é«˜çº§åˆ«çš„é€»è¾‘é”™è¯¯ï¼Œç¡®ä¿å³ä½¿æœ€ç»ˆå¤±è´¥ï¼Œä¹Ÿèƒ½ä¿å­˜å½“å‰è¿›åº¦å¹¶æ¸…æ™°æŠ¥å‘Šé—®é¢˜ã€‚\\n    *   **ç¤ºä¾‹ä¼ªä»£ç  (é’ˆå¯¹ `run_series_conference.py`):**\\n        ```python\\n        # run_series_conference.py\\n        import argparse\\n        import json\\n        import os\\n        import logging\\n        from .llm_om_zero_shot import query_llm_for_ontology_matching # å‡è®¾å·²å¯¼å…¥\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"8') as f\",\n",
      "      \"reason\": \"checkpoint_data = json.load(f)\\n                        results = checkpoint_data.get('results', {})\\n                        processed_conference_names = set(checkpoint_data.get('processed_conference_names', []))\\n                        logger.info(f\\\"Loaded checkpoint from {checkpoint_file}. Processed {len(processed_conference_names)} conferences.\\\")\\n                except Exception as e:\\n                    logger.warning(f\\\"Failed to load checkpoint from {checkpoint_file}: {e}. Starting from scratch.\\\")\\n                    results = {}\\n                    processed_conference_names = set()\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"8') as f\",\n",
      "      \"reason\": \"json.dump({'results': results, 'processed_conference_names': list(processed_names)}, f, ensure_ascii=False, indent=4)\\n            os.replace(temp_filename, filename) # åŸå­æ€§æ›¿æ¢\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"-llm-timeout', type=int, default=120, help=\\\"Timeout for individual LLM API calls in seconds.\\\")\\n            parser.add_argument('--max-llm-retries', type=int, default=5, help=\\\"Maximum retries for LLM API calls.\\\")\\n            parser.add_argument('--checkpoint-file', type=str, default=\\\"run_series_checkpoint.json\\\", help=\\\"File to save/load progress.\\\")\\n            parser.add_argument('--enable-checkpointing', action='store_true', help=\\\"Enable saving and resuming progress.\\\")\\n            parser.add_argument('--checkpoint-interval', type=int, default=10, help=\\\"Save checkpoint every N conferences processed.\\\")\\n            # ... è§£æå‚æ•°å¹¶è°ƒç”¨ run_series_conference\\n            args = parser.parse_args()\\n            # è¿™é‡Œéœ€è¦ä¿®æ”¹llm_om_zero_shotä¸­çš„retry_with_backoffè£…é¥°å™¨å‚æ•°ï¼Œä½¿å…¶å¯ä»¥ä»å¤–éƒ¨é…ç½®ä¸­è·å–\\n            # æˆ–è€…åœ¨query_llm_for_ontology_matchingå†…éƒ¨æ ¹æ®ä¼ å…¥çš„configæ¥åˆ›å»ºå’Œä½¿ç”¨retry_with_backoff\\n            # ç®€åŒ–èµ·è§ï¼Œå½“å‰ç¤ºä¾‹æ˜¯åœ¨è£…é¥°å™¨ä¸­ç¡¬ç¼–ç ï¼Œå®é™…åº”æ˜¯åŠ¨æ€é…ç½®ã€‚\\n            # æ›´å¥½çš„åšæ³•æ˜¯åœ¨ query_llm_for_ontology_matching å†…éƒ¨æ‰‹åŠ¨è°ƒç”¨ util.retry_with_backoff(func, **config_params)\\n            # è€Œä¸æ˜¯ä½œä¸ºè£…é¥°å™¨ï¼Œå¦‚æœå‚æ•°éœ€è¦åŠ¨æ€è°ƒæ•´ã€‚\\n        ```\\n\\n4.  **æ›´æ–° `generate_conference_benchmark.py` (æˆ–ä¸»å…¥å£ç‚¹)\",\n",
      "      \"reason\": \"**\\n    *   **ç›®æ ‡:** å¦‚æœ `generate_conference_benchmark.py` æ˜¯æ•´ä¸ªä»»åŠ¡çš„å¯åŠ¨è„šæœ¬ï¼Œå®ƒéœ€è¦æš´éœ²å¹¶æ¥æ”¶ä¸Šè¿°æ–°çš„é…ç½®å‚æ•°ã€‚\\n    *   **ä¿®æ”¹:** åœ¨ `ArgumentParser` ä¸­æ·»åŠ  `--llm-timeout`, `--max-llm-retries`, `--checkpoint-file`, `--enable-checkpointing`, `--checkpoint-interval` ç­‰å‚æ•°ï¼Œå¹¶å°†å®ƒä»¬ä¼ é€’ç»™ `run_series_conference` å‡½æ•°ã€‚\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"`util.py`\",\n",
      "      \"reason\": \"*   **ä¿®æ”¹åŸå› :** å®ç°ä¸€ä¸ªé€šç”¨çš„ `retry_with_backoff` è£…é¥°å™¨æˆ–å‡½æ•°ï¼Œç”¨äºå°è£…ç½‘ç»œè¯·æ±‚çš„é‡è¯•é€»è¾‘ã€‚è¿™æ˜¯åº”å¯¹å¼±ç½‘ç¯å¢ƒçš„æ ¸å¿ƒç»„ä»¶ï¼Œé›†ä¸­ç®¡ç†é‡è¯•ç­–ç•¥ã€‚\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"`llm_om_zero_shot.py`\",\n",
      "      \"reason\": \"*   **ä¿®æ”¹åŸå› :** å°† `util.py` ä¸­å®ç°çš„é‡è¯•è£…é¥°å™¨åº”ç”¨äºä¸ LLM æœåŠ¡è¿›è¡Œ API äº¤äº’çš„æ ¸å¿ƒå‡½æ•°ä¸Šã€‚åŒæ—¶ï¼Œç¡®ä¿è¿™äº›å‡½æ•°èƒ½å¤Ÿæ¥æ”¶å¹¶ä¼ é€’ `timeout` å‚æ•°ç»™åº•å±‚çš„ HTTP å®¢æˆ·ç«¯ï¼Œå¢åŠ è¯·æ±‚è¶…æ—¶æ§åˆ¶ã€‚\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"`llm_matching.py`\",\n",
      "      \"reason\": \"*   **ä¿®æ”¹åŸå› :** åŒ `llm_om_zero_shot.py`ï¼Œå¦‚æœæ­¤æ¨¡å—ä¹ŸåŒ…å«ç›´æ¥çš„ LLM API è°ƒç”¨ï¼Œä¹Ÿéœ€åº”ç”¨é‡è¯•å’Œè¶…æ—¶é€»è¾‘ï¼Œä½¿å…¶åœ¨å¼±ç½‘ä¸‹æ›´å¥å£®ã€‚\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"`run_series_conference.py`\",\n",
      "      \"reason\": \"*   **ä¿®æ”¹åŸå› :** ä½œä¸ºé¡¹ç›®çš„æ ¸å¿ƒåè°ƒæ¨¡å—ï¼Œéœ€è¦åœ¨æ­¤å¤„ï¼š\\n        *   æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®é¡¹æ¥æ§åˆ¶é‡è¯•æ¬¡æ•°ã€è¶…æ—¶æ—¶é—´ã€æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„å’Œæ£€æŸ¥ç‚¹é—´éš”ã€‚\\n        *   åœ¨ä¸»å¾ªç¯ä¸­å®ç°è¿›åº¦ä¿å­˜ (checkpointing) å’Œæ¢å¤é€»è¾‘ã€‚\\n        *   å°†é…ç½®å‚æ•°ä¼ é€’ç»™è°ƒç”¨çš„ `llm_om_zero_shot` å’Œ `llm_matching` æ¨¡å—ã€‚\\n        *   å¢å¼ºæ—¥å¿—è¾“å‡ºï¼Œè®°å½•é‡è¯•ã€è¶…æ—¶å’Œæ£€æŸ¥ç‚¹äº‹ä»¶ã€‚\"\n",
      "    },\n",
      "    {\n",
      "      \"file\": \"`generate_conference_benchmark.py` (æˆ–é¡¹ç›®çš„å…¶ä»–ä¸»å…¥å£è„šæœ¬)\",\n",
      "      \"reason\": \"*   **ä¿®æ”¹åŸå› :** å¦‚æœæ­¤æ–‡ä»¶æ˜¯å¯åŠ¨ `run_series_conference` çš„å…¥å£ï¼Œå®ƒéœ€è¦æ›´æ–° `ArgumentParser` æˆ–é…ç½®åŠ è½½é€»è¾‘ï¼Œä»¥æ”¯æŒå¹¶ä¼ é€’æ–°çš„å¼±ç½‘ç›¸å…³é…ç½®å‚æ•°ã€‚\"\n",
      "    }\n",
      "  ],\n",
      "  \"challenges\": [],\n",
      "  \"metadata\": {\n",
      "    \"model\": \"gemini-2.5-flash\",\n",
      "    \"temperature\": 0.3,\n",
      "    \"timestamp\": \"2025-12-19T16:20:00.152510\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ç¾åŒ–è¾“å‡ºç¬¬ä¸€ä¸ªé—®ç­”å¯¹\n",
    "if dataset['qa_pairs']:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ“ å®Œæ•´é—®ç­”å¯¹ç¤ºä¾‹\")\n",
    "    print(\"=\"*70)\n",
    "    sample_qa = dataset['qa_pairs'][0]\n",
    "    print(json.dumps(sample_qa, ensure_ascii=False, indent=2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# ç¾åŒ–è¾“å‡ºç¬¬ä¸€ä¸ªè®¾è®¡æ–¹æ¡ˆ\n",
    "if dataset['design_solutions']:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ—ï¸  å®Œæ•´è®¾è®¡æ–¹æ¡ˆç¤ºä¾‹\")\n",
    "    print(\"=\"*70)\n",
    "    sample_design = dataset['design_solutions'][0]\n",
    "    print(json.dumps(sample_design, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16f3c4",
   "metadata": {},
   "source": [
    "## ğŸš€ å¿«æ·æ–¹å¼: ä¸€é”®ç”Ÿæˆ\n",
    "\n",
    "å¦‚æœä¸éœ€è¦è¯¦ç»†æ­¥éª¤ï¼Œå¯ä»¥ä½¿ç”¨å¿«æ·å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd2891d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš€ å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ å‘ç°Pythonæ–‡ä»¶...\n",
      "   æ‰¾åˆ° 13 ä¸ªæ–‡ä»¶\n",
      "\n",
      "ğŸ“ ç”Ÿæˆ 5 ä¸ªé—®ç­”å¯¹...\n",
      "   [1/5] å¤„ç†æ–‡ä»¶: run_series_conference.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [2/5] å¤„ç†æ–‡ä»¶: generate_conference_benchmark.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [3/5] å¤„ç†æ–‡ä»¶: util.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [4/5] å¤„ç†æ–‡ä»¶: generate_conference_benchmark.py\n",
      "       âœ… æˆåŠŸ\n",
      "   [5/5] å¤„ç†æ–‡ä»¶: llm_om_few_shot.py\n",
      "       âœ… æˆåŠŸ\n",
      "\n",
      "ğŸ—ï¸  ç”Ÿæˆ 3 ä¸ªè®¾è®¡æ–¹æ¡ˆ...\n",
      "   [1/3] éœ€æ±‚: ä¸ºgenerate_anatomy_mse_benchmarkæ·»åŠ å•å…ƒæµ‹è¯•ä¿éšœæœºåˆ¶...\n",
      "       âœ… æˆåŠŸ\n",
      "   [2/3] éœ€æ±‚: ä¼˜åŒ–llm_om_few_shotçš„å¹¶å‘èƒ½åŠ›æ€§èƒ½...\n",
      "       âœ… æˆåŠŸ\n",
      "   [3/3] éœ€æ±‚: æ‰©å±•om_csv_to_databaseä»¥æ”¯æŒå¼±ç½‘ç¯å¢ƒåœºæ™¯...\n",
      "       âœ… æˆåŠŸ\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š ç”Ÿæˆå®Œæˆ\n",
      "======================================================================\n",
      "   é—®ç­”å¯¹: 5/5\n",
      "   è®¾è®¡æ–¹æ¡ˆ: 3/3\n",
      "   æˆåŠŸç‡: 100.0%\n",
      "\n",
      "ğŸ’¾ æ•°æ®å·²ä¿å­˜: outputs/ontology-llm/quick_output.json\n",
      "   æ–‡ä»¶å¤§å°: 94.3 KB\n",
      "\n",
      "ğŸ‰ å¿«æ·ç”Ÿæˆå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "from src.simple_generator import quick_generate\n",
    "\n",
    "# ä¸€é”®ç”Ÿæˆï¼ˆæ‰€æœ‰æ­¥éª¤è‡ªåŠ¨å®Œæˆï¼‰\n",
    "dataset_quick = quick_generate(\n",
    "    project_path=str(project_path),\n",
    "    num_qa=5,\n",
    "    num_design=3,\n",
    "    output_path=f\"outputs/{project_name}/quick_output.json\",\n",
    "    use_context=True\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ å¿«æ·ç”Ÿæˆå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e68a8e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š é™„å½•: è¿›é˜¶é…ç½®\n",
    "\n",
    "\n",
    "### å¸¸è§é—®é¢˜\n",
    "\n",
    "**Q: APIè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**\n",
    "- æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®\n",
    "- éªŒè¯ç½‘ç»œè¿æ¥\n",
    "- æŸ¥çœ‹APIé…é¢é™åˆ¶\n",
    "\n",
    "**Q: å¦‚ä½•æé«˜ç”Ÿæˆè´¨é‡ï¼Ÿ**\n",
    "- å¯ç”¨ä¸Šä¸‹æ–‡å¢å¼º (`use_context=True`)\n",
    "- é€‰æ‹©åˆé€‚çš„ä¸Šä¸‹æ–‡çº§åˆ«\n",
    "- è°ƒæ•´temperatureå‚æ•°ï¼ˆ0.2-0.4æœ€ä½³ï¼‰\n",
    "\n",
    "**Q: å¦‚ä½•åŠ é€Ÿç”Ÿæˆï¼Ÿ**\n",
    "- ä½¿ç”¨`minimal`ä¸Šä¸‹æ–‡çº§åˆ«\n",
    "- å‡å°‘å•æ¬¡ç”Ÿæˆæ•°é‡\n",
    "- ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
