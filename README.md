# æ™ºèƒ½è®­ç»ƒæ•°æ®ç”Ÿæˆä¸å¤„ç†ç³»ç»Ÿ

> ä¸º Qwen 2.5 ç³»åˆ—æ¨¡å‹å¾®è°ƒè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬ç³»ç»Ÿæ—¨åœ¨è‡ªåŠ¨åŒ–ç”Ÿæˆå’Œå¤„ç†è®­ç»ƒæ•°æ®ï¼Œæ”¯æŒåŸºäºæœ¬åœ°ä»£ç ä»“çš„ LLM æ¨¡å‹å¾®è°ƒã€‚ç³»ç»Ÿå¯ä»¥ï¼š

- ğŸ¯ **åœºæ™¯ 1**ï¼šè‡ªåŠ¨ç”Ÿæˆä»£ç é—®ç­”å¯¹ï¼ŒåŒ…å«å®Œæ•´çš„æ¨ç†è½¨è¿¹
- ğŸ—ï¸ **åœºæ™¯ 2**ï¼šæ ¹æ®éœ€æ±‚ç”Ÿæˆæ¶æ„è®¾è®¡æ–¹æ¡ˆï¼Œæä¾›è¯¦ç»†å®ç°æ­¥éª¤
- ğŸ“Š **æ•°æ®éªŒè¯**ï¼šè‡ªåŠ¨è¯„ä¼°æ•°æ®è´¨é‡ï¼Œç¡®ä¿è®­ç»ƒæ•ˆæœ
- ğŸ”„ **å¤šæ ¼å¼å¯¼å‡º**ï¼šæ”¯æŒ JSONLã€JSON ç­‰å¤šç§æ ¼å¼

### æ ¸å¿ƒç‰¹æ€§

- âœ… è‡ªåŠ¨åŒ–ä»£ç åˆ†æï¼ˆPythonã€JavaScriptã€Javaã€TypeScriptï¼‰
- âœ… LLM é©±åŠ¨çš„æ™ºèƒ½é—®ç­”ç”Ÿæˆ
- âœ… æ¨ç†è½¨è¿¹ (Reasoning Trace) ç”Ÿæˆ
- âœ… æ¶æ„æ„ŸçŸ¥çš„è®¾è®¡æ–¹æ¡ˆç”Ÿæˆ
- âœ… å¤šç»´åº¦æ•°æ®è´¨é‡è¯„ä¼°
- âœ… æ”¯æŒ OpenAI å’Œ Anthropic API
- âœ… æ•°æ®é›†è‡ªåŠ¨åˆ’åˆ†ï¼ˆTrain/Val/Testï¼‰
- âœ… å¼€ç®±å³ç”¨çš„å¾®è°ƒæ ¼å¼

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd training_data_generation

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½® API å¯†é’¥

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ API å¯†é’¥
# OPENAI_API_KEY=your_key_here
# æˆ–
# ANTHROPIC_API_KEY=your_key_here
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
# ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ˆä¸è°ƒç”¨ APIï¼‰
python examples/generate_samples.py

# æˆ–ä½¿ç”¨ demo è„šæœ¬
bash examples/demo.sh
```

### 4. ä»çœŸå®ä»£ç ä»“ç”Ÿæˆæ•°æ®

```bash
# ä½¿ç”¨å…¬å¼€çš„ GitHub ä»“åº“
git clone https://github.com/pallets/flask.git repos/flask

# ç”Ÿæˆè®­ç»ƒæ•°æ®
python main.py \
  --repo-path repos/flask \
  --scenario both \
  --num-qa 30 \
  --num-design 10
```

---

## ğŸ“– è¯¦ç»†æ–‡æ¡£

### æ–‡æ¡£å¯¼èˆª

- ğŸ“˜ [è®¾è®¡æ–‡æ¡£](docs/DESIGN.md) - å®Œæ•´çš„ç³»ç»Ÿè®¾è®¡ã€æ•°æ®ç»“æ„ã€æ¶æ„è¯´æ˜
- ğŸ“‹ [äº¤ä»˜æ€»ç»“](docs/SUMMARY.md) - é¡¹ç›®å®Œæˆæƒ…å†µã€è¯„åˆ¤æ ‡å‡†å¯¹ç…§
- âš¡ [å¿«é€Ÿå‚è€ƒ](docs/QUICK_REFERENCE.md) - å‘½ä»¤é€ŸæŸ¥ã€é…ç½®è¯´æ˜ã€å¸¸è§é—®é¢˜

### ç³»ç»Ÿæ¶æ„

ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œåˆ†ä¸ºä»¥ä¸‹æ ¸å¿ƒæ¨¡å—ï¼š

```
ğŸ“¦ training_data_generation
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ analyzer.py          # ä»£ç ä»“åº“åˆ†æ
â”‚   â”œâ”€â”€ llm_service.py       # LLM API æœåŠ¡
â”‚   â”œâ”€â”€ qa_generator.py      # é—®ç­”å¯¹ç”Ÿæˆ
â”‚   â”œâ”€â”€ design_generator.py  # è®¾è®¡æ–¹æ¡ˆç”Ÿæˆ
â”‚   â”œâ”€â”€ data_processor.py    # æ•°æ®å¤„ç†ä¸éªŒè¯
â”‚   â””â”€â”€ schema.py            # æ•°æ®æ¨¡å‹å®šä¹‰
â”œâ”€â”€ ğŸ“ config/               # é…ç½®æ–‡ä»¶
â”œâ”€â”€ ğŸ“ docs/                 # è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ ğŸ“ examples/             # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ ğŸ“ data/                 # æ•°æ®è¾“å‡ºç›®å½•
â””â”€â”€ main.py                  # ä¸»ç¨‹åºå…¥å£
```

è¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼š[docs/DESIGN.md](docs/DESIGN.md)

### æ•°æ®æ ¼å¼

#### åœºæ™¯ 1ï¼šé—®ç­”å¯¹æ ¼å¼

```json
{
  "id": "uuid",
  "question": "è¿™ä¸ªå‡½æ•°çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
  "answer": "è¯¦ç»†çš„ç­”æ¡ˆ...",
  "question_type": "code_explanation",
  "code_contexts": [
    {
      "file_path": "src/module.py",
      "start_line": 10,
      "end_line": 30,
      "code_snippet": "def function_name():\n    ...",
      "language": "python"
    }
  ],
  "reasoning_trace": {
    "steps": [
      {
        "step_number": 1,
        "description": "åˆ†æå‡½æ•°ç­¾å",
        "code_reference": "def function_name(params)",
        "confidence": 0.9
      }
    ],
    "overall_confidence": 0.87,
    "methodology": "è‡ªé¡¶å‘ä¸‹åˆ†ææ³•"
  },
  "difficulty": "medium",
  "tags": ["authentication", "security"]
}
```

#### åœºæ™¯ 2ï¼šè®¾è®¡æ–¹æ¡ˆæ ¼å¼

```json
{
  "id": "uuid",
  "requirement": "æ·»åŠ ç”¨æˆ·è®¤è¯åŠŸèƒ½",
  "requirement_type": "new_feature",
  "solution_overview": "é‡‡ç”¨ JWT è¿›è¡Œæ— çŠ¶æ€è®¤è¯...",
  "detailed_design": "è¯¦ç»†è®¾è®¡è¯´æ˜...",
  "implementation_steps": [
    "1. å®‰è£… PyJWT åº“",
    "2. åˆ›å»º JWT å·¥å…·ç±»",
    "3. å®ç°è®¤è¯ä¸­é—´ä»¶"
  ],
  "architecture_context": {
    "components": [...],
    "design_patterns": ["Repository Pattern"],
    "tech_stack": {"web_framework": "FastAPI"},
    "architecture_type": "RESTful API"
  },
  "reasoning_trace": { ... },
  "complexity": "medium",
  "estimated_effort": "3-5 å¤©"
}
```

---

## ğŸ¯ ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

```bash
# ç”Ÿæˆé—®ç­”å¯¹
python main.py --repo-path /path/to/repo --scenario qa --num-qa 50

# ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ
python main.py --repo-path /path/to/repo --scenario design --num-design 20

# åŒæ—¶ç”Ÿæˆä¸¤ç§æ•°æ®
python main.py --repo-path /path/to/repo --scenario both --num-qa 30 --num-design 10
```

### é«˜çº§é…ç½®

ç¼–è¾‘ `config/config.yaml` è‡ªå®šä¹‰ç”Ÿæˆå‚æ•°ï¼š

```yaml
generation:
  samples_per_scenario: 50
  quality_threshold: 0.7
  llm:
    provider: "openai"  # æˆ– "anthropic"
    model: "gpt-4-turbo-preview"
    temperature: 0.7

scenario1_qa:
  question_types:
    - "code_explanation"
    - "business_logic"
    - "design_pattern"

scenario2_design:
  requirement_types:
    - "new_feature"
    - "refactoring"
    - "integration"
```

### è¾“å‡ºæ–‡ä»¶

ç”Ÿæˆçš„æ•°æ®ä¿å­˜åœ¨ `data/processed/` ç›®å½•ï¼š

```
data/processed/
â”œâ”€â”€ qa_pairs.jsonl              # Q&A å¯¹ï¼ˆJSONLï¼‰
â”œâ”€â”€ qa_pairs.json               # Q&A å¯¹ï¼ˆJSONï¼‰
â”œâ”€â”€ design_solutions.jsonl      # è®¾è®¡æ–¹æ¡ˆï¼ˆJSONLï¼‰
â”œâ”€â”€ design_solutions.json       # è®¾è®¡æ–¹æ¡ˆï¼ˆJSONï¼‰
â”œâ”€â”€ finetuning_data.jsonl       # å¾®è°ƒæ ¼å¼æ•°æ®
â”œâ”€â”€ train.jsonl                 # è®­ç»ƒé›†
â”œâ”€â”€ validation.jsonl            # éªŒè¯é›†
â”œâ”€â”€ test.jsonl                  # æµ‹è¯•é›†
â””â”€â”€ quality_report.json         # è´¨é‡æŠ¥å‘Š
```

---

## ğŸ“Š æ•°æ®è´¨é‡

### è´¨é‡è¯„ä¼°ç»´åº¦

| ç»´åº¦ | è¯„ä¼°æ ‡å‡† | æƒé‡ |
|------|----------|------|
| é—®é¢˜è´¨é‡ | é•¿åº¦ã€æ¸…æ™°åº¦ã€ç›¸å…³æ€§ | 20% |
| ç­”æ¡ˆè´¨é‡ | å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€è¯¦ç»†åº¦ | 30% |
| ä»£ç ä¸Šä¸‹æ–‡ | ç›¸å…³æ€§ã€å®Œæ•´æ€§ | 20% |
| æ¨ç†è´¨é‡ | æ­¥éª¤å®Œæ•´æ€§ã€é€»è¾‘æ€§ã€ç½®ä¿¡åº¦ | 30% |

### è‡ªåŠ¨éªŒè¯

ç³»ç»Ÿè‡ªåŠ¨éªŒè¯æ¯ä¸ªæ ·æœ¬ï¼š

- âœ… é—®é¢˜é•¿åº¦ â‰¥ 5 ä¸ªå•è¯
- âœ… ç­”æ¡ˆé•¿åº¦ â‰¥ 20 ä¸ªå•è¯
- âœ… è‡³å°‘åŒ…å« 1 ä¸ªä»£ç ä¸Šä¸‹æ–‡
- âœ… æ¨ç†æ­¥éª¤ â‰¥ 2 æ­¥
- âœ… æ•´ä½“ç½®ä¿¡åº¦ â‰¥ 0.5

### è´¨é‡æŠ¥å‘Šç¤ºä¾‹

```json
{
  "qa_pairs": {
    "total": 50,
    "valid": 48,
    "avg_quality_score": 0.856,
    "question_types": {
      "code_explanation": 15,
      "business_logic": 12
    }
  },
  "overall": {
    "total_samples": 70,
    "overall_quality": 0.845
  }
}
```

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. ä»£ç åˆ†æ

```python
from src.analyzer import RepositoryAnalyzer

analyzer = RepositoryAnalyzer("/path/to/repo")
analyzer.analyze(languages=['python', 'javascript'])

# è·å–å¤æ‚å‡½æ•°
complex_functions = analyzer.get_functions_by_complexity(min_complexity=3)

# æœç´¢ä»£ç 
results = analyzer.search_code("authenticate")
```

### 2. é—®ç­”ç”Ÿæˆ

```python
from src.qa_generator import QAGenerator

generator = QAGenerator(analyzer, llm_service)
qa_pairs = generator.generate_qa_pairs(
    num_samples=50,
    question_types=['code_explanation', 'business_logic']
)
```

### 3. è®¾è®¡æ–¹æ¡ˆç”Ÿæˆ

```python
from src.design_generator import DesignSolutionGenerator

generator = DesignSolutionGenerator(analyzer, llm_service)
solutions = generator.generate_design_solutions(
    num_samples=20,
    requirement_types=['new_feature', 'refactoring']
)
```

### 4. æ•°æ®å¤„ç†

```python
from src.data_processor import DataProcessor, DataValidator

# éªŒè¯æ•°æ®
validator = DataValidator()
report = validator.generate_report(qa_pairs, design_solutions)

# å¯¼å‡ºæ•°æ®
processor = DataProcessor("data/processed")
processor.export_to_jsonl(qa_pairs, "qa_pairs.jsonl")
processor.export_for_finetuning(qa_pairs, design_solutions)
```

---

## ğŸ“ æ¨¡å‹å¾®è°ƒ

### OpenAI Fine-tuning

```bash
# å‡†å¤‡æ•°æ®
python main.py --repo-path /path/to/repo --scenario both

# ä¸Šä¼ è®­ç»ƒæ–‡ä»¶
openai api fine_tunes.create \
  -t data/processed/finetuning_data.jsonl \
  -m gpt-3.5-turbo

# æŸ¥çœ‹å¾®è°ƒçŠ¶æ€
openai api fine_tunes.follow -i <YOUR_FINE_TUNE_ID>
```

### è‡ªå®šä¹‰å¾®è°ƒï¼ˆå¯é€‰ï¼‰

å¦‚æœä½¿ç”¨å¼€æºæ¨¡å‹ï¼ˆå¦‚ Qwenï¼‰ï¼š

```python
# examples/finetune_qwen.py
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer

# åŠ è½½æ•°æ®
dataset = load_dataset('json', data_files={
    'train': 'data/processed/train.jsonl',
    'validation': 'data/processed/validation.jsonl'
})

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B")

# å¾®è°ƒé…ç½®
training_args = TrainingArguments(
    output_dir="./models/qwen-finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    learning_rate=2e-5
)

# å¼€å§‹è®­ç»ƒ
trainer = Trainer(model=model, args=training_args, train_dataset=dataset['train'])
trainer.train()
```

---

## ğŸ“ˆ æ€§èƒ½ä¸æˆæœ¬

### ç”Ÿæˆé€Ÿåº¦

- å•ä¸ª Q&A å¯¹ï¼šçº¦ 5-10 ç§’ï¼ˆå–å†³äº LLM å“åº”é€Ÿåº¦ï¼‰
- å•ä¸ªè®¾è®¡æ–¹æ¡ˆï¼šçº¦ 10-15 ç§’
- 100 ä¸ªæ ·æœ¬ï¼šçº¦ 10-15 åˆ†é’Ÿ

### API æˆæœ¬ä¼°ç®—ï¼ˆGPT-4ï¼‰

- Q&A å¯¹ï¼šçº¦ $0.02-0.03 per sample
- è®¾è®¡æ–¹æ¡ˆï¼šçº¦ $0.05-0.08 per sample
- 100 æ ·æœ¬æ€»æˆæœ¬ï¼šçº¦ $3-5

ğŸ’¡ **æˆæœ¬ä¼˜åŒ–å»ºè®®**ï¼š
- ä½¿ç”¨ GPT-3.5 Turbo é™ä½æˆæœ¬ï¼ˆè´¨é‡ç•¥é™ï¼‰
- æ‰¹é‡ç”Ÿæˆæ—¶ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤
- å¯¹äºç®€å•é—®é¢˜ä½¿ç”¨æœ¬åœ°æ¨¡å‹

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»ç»´æŠ¤è€…ã€‚

---

## ğŸ¯ é¡¹ç›®ç›®æ ‡

é€šè¿‡æœ¬ç³»ç»Ÿç”Ÿæˆçš„è®­ç»ƒæ•°æ®ï¼ŒæœŸæœ›æ¨¡å‹å…·å¤‡ï¼š

âœ… æ·±å…¥ç†è§£ä»£ç çš„ä¸šåŠ¡é€»è¾‘å’Œå®ç°ç»†èŠ‚  
âœ… æä¾›å¸¦æ¨ç†è¿‡ç¨‹çš„ä»£ç è§£é‡Š  
âœ… åŸºäºç°æœ‰æ¶æ„ç”Ÿæˆåˆç†çš„è®¾è®¡æ–¹æ¡ˆ  
âœ… è€ƒè™‘å®ç°å¤æ‚åº¦å’Œæ½œåœ¨é£é™©  
âœ… æˆä¸ºä¼˜ç§€çš„ä»£ç ç†è§£åŠ©æ‰‹å’Œæ¶æ„è®¾è®¡é¡¾é—®  

---

**Happy Training! ğŸš€**