# =============================================================================
# 训练数据生成系统配置
# =============================================================================

# LLM 配置
llm:
  provider: "gemini"              # 可选: openai, anthropic, gemini
  model: "gemini-2.5-flash"       # 模型名称
  temperature: 0.3                # 温度参数 (0.2-0.4 推荐)
  max_tokens: 2000                # 最大生成token数
  retry_attempts: 3               # 重试次数

# 生成配置
generation:
  samples_per_scenario: 50        # 每场景生成数量
  num_qa_pairs: 10                # 问答对数量
  num_design_solutions: 5         # 设计方案数量
  use_context: true               # 启用上下文增强
  context_level: "standard"       # 上下文级别: minimal/standard/full
  
  code_snippet_length: 800        # 代码片段长度
  max_files: 20                   # 最多分析文件数
  quality_threshold: 0.7          # 质量阈值
  
  max_attempts: 10                # 最大尝试次数
  retry_delay: 2                  # 重试延迟（秒）

# 代码分析配置
code_analysis:
  languages:
    - python
    - javascript
    - java
  
  max_depth: 5
  
  exclude_patterns:
    - "**/node_modules/**"
    - "**/.venv/**"
    - "**/__pycache__/**"
    - "**/test/**"
    - "**/tests/**"
    - "**/.git/**"

# 场景配置
scenario1_qa:
  question_types:
    - "code_explanation"
    - "business_logic"
    - "design_pattern"
    - "error_handling"
    - "performance_optimization"
  include_reasoning: true
  context_window: 50

scenario2_design:
  requirement_types:
    - "new_feature"
    - "refactoring"
    - "integration"
    - "optimization"
  architecture_depth: 3
  include_implementation: true

# 质量控制
quality_control:
  validation:
    check_code_validity: true
    check_reasoning_completeness: true
    check_answer_relevance: true
  
  filters:
    min_question_length: 10
    min_answer_length: 50
    min_code_snippet_lines: 5

# 输出配置
output:
  format: "jsonl"
  split_ratios:
    train: 0.8
    validation: 0.1
    test: 0.1
  save_traces: true
