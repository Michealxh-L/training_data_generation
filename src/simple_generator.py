"""è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""
import os
import json
import random
import re
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime


class SimpleGenerator:
    """ç®€åŒ–ç‰ˆè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(
        self,
        project_path: str,
        api_key: Optional[str] = None,
        model: str = "gemini-2.5-flash",
        temperature: float = 0.3
    ):
        self.project_path = Path(project_path)
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.model = model
        self.temperature = temperature
        
        # å¯¼å…¥ä¾èµ–
        try:
            import google.generativeai as genai
            if self.api_key:
                genai.configure(api_key=self.api_key)
                self.llm = genai.GenerativeModel(model)
                self.llm_available = True
            else:
                self.llm = None
                self.llm_available = False
                print("âš ï¸  æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        except ImportError:
            self.llm = None
            self.llm_available = False
            print("âš ï¸  æœªå®‰è£…google-generativeaiï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        
        # å¯¼å…¥ä¸Šä¸‹æ–‡åˆ†æå™¨
        try:
            from src.context_analyzer import ProjectContextAnalyzer
            self.analyzer = ProjectContextAnalyzer(str(project_path))
            self.context_enabled = True
        except ImportError:
            self.analyzer = None
            self.context_enabled = False
            print("âš ï¸  ä¸Šä¸‹æ–‡åˆ†æå™¨æœªå¯ç”¨")
    
    def discover_python_files(self) -> List[Path]:
        """å‘ç°é¡¹ç›®ä¸­çš„Pythonæ–‡ä»¶"""
        files = []
        for py_file in self.project_path.rglob('*.py'):
            if all(x not in str(py_file) for x in ['__pycache__', '.venv', 'test', '.git']):
                files.append(py_file)
        return files[:20]
    
    def extract_code_snippet(self, file_path: Path, length: int = 800) -> str:
        """æå–ä»£ç ç‰‡æ®µ"""
        try:
            content = file_path.read_text(encoding='utf-8')
            if len(content) <= length:
                return content
            max_start = len(content) - length
            start = random.randint(0, max_start)
            return content[start:start + length]
        except:
            return ""
    
    def _calculate_qa_quality_score(self, qa_data: Dict) -> float:
        """è®¡ç®—é—®ç­”å¯¹çš„è´¨é‡è¯„åˆ†
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - é—®é¢˜è´¨é‡ (0-0.25): é•¿åº¦ã€å…·ä½“æ€§
        - ç­”æ¡ˆè´¨é‡ (0-0.35): è¯¦ç»†ç¨‹åº¦ã€æ·±åº¦
        - æ¨ç†æ­¥éª¤ (0-0.25): æ­¥éª¤æ•°é‡å’Œè´¨é‡
        - ä»£ç ä¸Šä¸‹æ–‡ (0-0.15): æ˜¯å¦åŒ…å«ç›¸å…³ä»£ç 
        """
        score = 0.0
        
        # é—®é¢˜è´¨é‡
        question = qa_data.get('question', '')
        q_words = len(question.split())
        score += min(0.25, (q_words / 20) * 0.25)  # 20è¯ä¸ºæ ‡å‡†
        
        # ç­”æ¡ˆè´¨é‡
        answer = qa_data.get('answer', '')
        a_words = len(answer.split())
        score += min(0.35, (a_words / 100) * 0.35)  # 100è¯ä¸ºæ ‡å‡†
        
        # æ¨ç†æ­¥éª¤
        reasoning = qa_data.get('reasoning_steps', [])
        if reasoning:
            num_steps = len(reasoning)
            score += min(0.25, (num_steps / 5) * 0.25)  # 5æ­¥ä¸ºæ ‡å‡†
        
        # ä»£ç ä¸Šä¸‹æ–‡
        if qa_data.get('code_context'):
            score += 0.15
        
        return min(1.0, round(score, 3))
    
    def _calculate_design_quality_score(self, design_data: Dict) -> float:
        """è®¡ç®—è®¾è®¡æ–¹æ¡ˆçš„è´¨é‡è¯„åˆ†
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - æ–¹æ¡ˆæ¦‚è¿° (0-0.20): æ¸…æ™°åº¦å’Œå®Œæ•´æ€§
        - å®æ–½æ­¥éª¤ (0-0.30): æ­¥éª¤æ•°é‡å’Œè¯¦ç»†åº¦
        - æ–‡ä»¶ä¿®æ”¹ (0-0.25): å…·ä½“æ€§å’Œåˆç†æ€§
        - æŒ‘æˆ˜åˆ†æ (0-0.25): é£é™©è¯†åˆ«å’Œåº”å¯¹
        """
        score = 0.0
        
        # æ–¹æ¡ˆæ¦‚è¿°
        solution = design_data.get('solution', '')
        s_words = len(solution.split())
        score += min(0.20, (s_words / 50) * 0.20)
        
        # å®æ–½æ­¥éª¤
        steps = design_data.get('implementation_steps', [])
        if steps:
            num_steps = len(steps)
            score += min(0.30, (num_steps / 7) * 0.30)
        
        # æ–‡ä»¶ä¿®æ”¹
        files = design_data.get('files_to_modify', [])
        if files:
            score += min(0.25, (len(files) / 5) * 0.25)
        
        # æŒ‘æˆ˜åˆ†æ
        challenges = design_data.get('challenges', [])
        if challenges:
            score += min(0.25, (len(challenges) / 3) * 0.25)
        
        return min(1.0, round(score, 3))
    
    def generate_qa_pair(self, code_snippet: str, file_path: str, use_context: bool = True, context_level: str = 'standard') -> Optional[Dict]:
        """ç”Ÿæˆå•ä¸ªé—®ç­”å¯¹
        
        Args:
            code_snippet: ä»£ç ç‰‡æ®µ
            file_path: æ–‡ä»¶è·¯å¾„
            use_context: æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡
            context_level: ä¸Šä¸‹æ–‡çº§åˆ« ('minimal', 'standard', 'full')
        """
        # å®šä¹‰é—®é¢˜å±‚æ¬¡æ˜ å°„
        question_focus = {
            'minimal': {
                'level': 'ä»£ç å®ç°å±‚',
                'topics': 'ç®—æ³•é€»è¾‘ã€æ•°æ®ç»“æ„ã€APIä½¿ç”¨ã€ä»£ç ç»†èŠ‚',
                'examples': 'å‡½æ•°å®ç°åŸç†ã€å˜é‡å‘½åè§„èŒƒã€å¼‚å¸¸å¤„ç†æ–¹å¼ã€ä»£ç ä¼˜åŒ–å»ºè®®'
            },
            'standard': {
                'level': 'æ¨¡å—è®¾è®¡å±‚',
                'topics': 'è®¾è®¡æ¨¡å¼ã€æ¨¡å—äº¤äº’ã€èŒè´£åˆ’åˆ†ã€ç»„ä»¶åä½œ',
                'examples': 'æ¨¡å—é—´ä¾èµ–å…³ç³»ã€æ¥å£è®¾è®¡åˆç†æ€§ã€è®¾è®¡æ¨¡å¼åº”ç”¨ã€ä»£ç é‡æ„å»ºè®®'
            },
            'full': {
                'level': 'ç³»ç»Ÿæ¶æ„å±‚',
                'topics': 'æŠ€æœ¯é€‰å‹ã€æ‰©å±•æ€§è®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨è€ƒé‡',
                'examples': 'æ•´ä½“æ¶æ„è®¾è®¡ã€æŠ€æœ¯æ ˆé€‰æ‹©ã€å¯æ‰©å±•æ€§åˆ†æã€ç³»ç»Ÿçº§ä¼˜åŒ–ç­–ç•¥'
            }
        }
        
        focus = question_focus.get(context_level, question_focus['standard'])
        
        prompt = ""
        if use_context and self.context_enabled:
            context = self.analyzer.build_context(code_snippet, file_path, context_level=context_level)
            prompt += f"{context}\n"
            prompt += f"ã€ä¸Šä¸‹æ–‡çº§åˆ«ã€‘{context_level.capitalize()}ï¼ˆ{focus['level']}ï¼‰\n\n"
        
        prompt += f"""
è¯·åŸºäºä»¥ä¸‹ä»£ç å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªæŠ€æœ¯é—®ç­”å¯¹ã€‚

ã€ä»£ç ã€‘
```python
{code_snippet}
```

ã€é—®é¢˜å±‚æ¬¡è¦æ±‚ã€‘
æ ¹æ®ä¸Šä¸‹æ–‡çº§åˆ«ç”Ÿæˆå¯¹åº”å±‚æ¬¡çš„é—®é¢˜ï¼š
- Minimalçº§åˆ«ï¼ˆä»£ç å®ç°å±‚ï¼‰ï¼š{question_focus['minimal']['topics']}
  ç¤ºä¾‹ï¼š{question_focus['minimal']['examples']}
  
- Standardçº§åˆ«ï¼ˆæ¨¡å—è®¾è®¡å±‚ï¼‰ï¼š{question_focus['standard']['topics']}
  ç¤ºä¾‹ï¼š{question_focus['standard']['examples']}
  
- Fullçº§åˆ«ï¼ˆç³»ç»Ÿæ¶æ„å±‚ï¼‰ï¼š{question_focus['full']['topics']}
  ç¤ºä¾‹ï¼š{question_focus['full']['examples']}

å½“å‰è¦æ±‚ï¼šç”Ÿæˆã€{focus['level']}ã€‘çš„é—®é¢˜ï¼Œèšç„¦äº{focus['topics']}

ã€å†…å®¹è¦æ±‚ã€‘
1. é—®é¢˜è¦å…·ä½“ä¸”æœ‰æ·±åº¦ï¼Œä¸¥æ ¼åŒ¹é…æŒ‡å®šçš„é—®é¢˜å±‚æ¬¡
2. ç­”æ¡ˆè¦è¯¦ç»†å‡†ç¡®ï¼ŒåŒ…å«ç›¸åº”å±‚æ¬¡çš„æŠ€æœ¯åˆ†æ
3. æ¨ç†æ­¥éª¤è¦æ¸…æ™°ï¼Œå±•ç¤ºä»ä¸Šä¸‹æ–‡åˆ°ç»“è®ºçš„åˆ†æè¿‡ç¨‹

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆè¯·ä¸¥æ ¼éµå¾ªï¼‰
Question: <ä½ çš„é—®é¢˜>

Answer: <è¯¦ç»†ç­”æ¡ˆ>

Reasoning Steps:
1. <æ¨ç†æ­¥éª¤1>
2. <æ¨ç†æ­¥éª¤2>
3. <æ¨ç†æ­¥éª¤3>
"""
        
        # è°ƒç”¨LLM
        if self.llm_available:
            try:
                response = self.llm.generate_content(prompt)
                text = response.text
            except Exception as e:
                print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                return None
        else:
            # æ¨¡æ‹Ÿæ¨¡å¼
            text = self._generate_mock_response(code_snippet, file_path, context_level)
        
        # è§£æå“åº”
        parsed = self._parse_qa_response(text)
        if parsed:
            # æ·»åŠ å…ƒæ•°æ®
            parsed['code_context'] = code_snippet
            parsed['source_file'] = file_path
            parsed['metadata'] = {
                'model': self.model,
                'temperature': self.temperature,
                'timestamp': datetime.now().isoformat(),
                'context_enabled': use_context and self.context_enabled,
                'context_level': context_level,
                'question_layer': {
                    'minimal': 'ä»£ç å®ç°å±‚',
                    'standard': 'æ¨¡å—è®¾è®¡å±‚',
                    'full': 'ç³»ç»Ÿæ¶æ„å±‚'
                }.get(context_level, 'æœªçŸ¥')
            }
            # è®¡ç®—è´¨é‡è¯„åˆ†
            parsed['quality_score'] = self._calculate_qa_quality_score(parsed)
        
        return parsed
    
    def generate_design_solution(self, requirement: str, use_context: bool = True) -> Optional[Dict]:
        """ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ"""
        prompt = ""
        if use_context and self.context_enabled:
            structure = self.analyzer.analyze_project_structure()
            prompt += f"""
## é¡¹ç›®ä¿¡æ¯
- é¡¹ç›®åç§°: {structure['project_name']}
- æ–‡ä»¶æ•°é‡: {structure['total_files']}
- æ ¸å¿ƒæ¨¡å—: {', '.join(structure['core_modules'][:5])}

"""
        
        prompt += f"""
è¯·ä¸ºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„è®¾è®¡æ–¹æ¡ˆã€‚

ã€éœ€æ±‚ã€‘
{requirement}

ã€è¦æ±‚ã€‘
1. è§£å†³æ–¹æ¡ˆè¦ç»“åˆé¡¹ç›®ç°æœ‰æ¶æ„
2. å®æ–½æ­¥éª¤è¦æ¸…æ™°å…·ä½“
3. åˆ—å‡ºéœ€è¦ä¿®æ”¹çš„æ–‡ä»¶å’ŒåŸå› 
4. åˆ†æå¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜

ã€è¾“å‡ºæ ¼å¼ã€‘
Requirement: {requirement}

Solution: <è§£å†³æ–¹æ¡ˆæ¦‚è¿°>

Implementation Steps:
1. <æ­¥éª¤1>
2. <æ­¥éª¤2>
3. <æ­¥éª¤3>

Files to Modify:
- file1.py: <ä¿®æ”¹åŸå› >
- file2.py: <ä¿®æ”¹åŸå› >

Challenges:
- <æŒ‘æˆ˜1>
- <æŒ‘æˆ˜2>
"""
        
        # è°ƒç”¨LLM
        if self.llm_available:
            try:
                response = self.llm.generate_content(prompt)
                text = response.text
            except Exception as e:
                print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                return None
        else:
            # æ¨¡æ‹Ÿæ¨¡å¼
            text = self._generate_mock_design_response(requirement)
        
        # è§£æå“åº”
        parsed = self._parse_design_response(text, requirement)
        if parsed:
            parsed['metadata'] = {
                'model': self.model,
                'temperature': self.temperature,
                'timestamp': datetime.now().isoformat()
            }
            # è®¡ç®—è´¨é‡è¯„åˆ†
            parsed['quality_score'] = self._calculate_design_quality_score(parsed)
        
        return parsed
    
    def generate_batch(self, num_qa: int = 5, num_design: int = 3, use_context: bool = True, context_level: str = 'standard') -> Dict:
        """æ‰¹é‡ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        print("="*70)
        print("ğŸš€ å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®")
        print("="*70)
        
        dataset = {
            'qa_pairs': [],
            'design_solutions': [],
            'metadata': {
                'project': str(self.project_path),
                'generation_time': datetime.now().isoformat(),
                'model': self.model,
                'context_enabled': use_context and self.context_enabled
            }
        }
        
        # å‘ç°æ–‡ä»¶
        print("\nğŸ“ å‘ç°Pythonæ–‡ä»¶...")
        files = self.discover_python_files()
        print(f"   æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
        
        # ç”Ÿæˆé—®ç­”å¯¹
        if num_qa > 0:
            level_name = {
                'minimal': 'ä»£ç å®ç°å±‚',
                'standard': 'æ¨¡å—è®¾è®¡å±‚',
                'full': 'ç³»ç»Ÿæ¶æ„å±‚'
            }.get(context_level, context_level)
            print(f"\nğŸ“ ç”Ÿæˆ {num_qa} ä¸ªé—®ç­”å¯¹ï¼ˆ{level_name}ï¼‰...")
            for i in range(num_qa):
                file = random.choice(files)
                rel_path = file.relative_to(self.project_path)
                code = self.extract_code_snippet(file)
                
                print(f"   [{i+1}/{num_qa}] å¤„ç†æ–‡ä»¶: {rel_path}")
                
                qa = self.generate_qa_pair(code, str(rel_path), use_context, context_level)
                if qa:
                    dataset['qa_pairs'].append(qa)
                    print(f"       âœ… æˆåŠŸï¼ˆ{level_name}ï¼‰")
                else:
                    print(f"       âŒ å¤±è´¥")
        
        # ç”Ÿæˆè®¾è®¡æ–¹æ¡ˆ
        if num_design > 0:
            print(f"\nğŸ—ï¸  ç”Ÿæˆ {num_design} ä¸ªè®¾è®¡æ–¹æ¡ˆ...")
            
            # åŠ¨æ€ç”Ÿæˆå¤šæ ·åŒ–éœ€æ±‚
            requirements = self._generate_diverse_requirements(num_design, files)
            
            for i, req in enumerate(requirements[:num_design]):
                print(f"   [{i+1}/{num_design}] éœ€æ±‚: {req[:50]}...")
                
                design = self.generate_design_solution(req, use_context)
                if design:
                    dataset['design_solutions'].append(design)
                    print(f"       âœ… æˆåŠŸ")
                else:
                    print(f"       âŒ å¤±è´¥")
        
        # ç»Ÿè®¡
        print("\n" + "="*70)
        print("ğŸ“Š ç”Ÿæˆå®Œæˆ")
        print("="*70)
        print(f"   é—®ç­”å¯¹: {len(dataset['qa_pairs'])}/{num_qa}")
        print(f"   è®¾è®¡æ–¹æ¡ˆ: {len(dataset['design_solutions'])}/{num_design}")
        print(f"   æˆåŠŸç‡: {((len(dataset['qa_pairs']) + len(dataset['design_solutions'])) / (num_qa + num_design) * 100):.1f}%")
        
        return dataset
    
    def save_dataset(self, dataset: Dict, output_path: str):
        """
        ä¿å­˜æ•°æ®é›†
        
        Args:
            dataset: æ•°æ®é›†
            output_path: è¾“å‡ºè·¯å¾„
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜: {output_file}")
        print(f"   æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.1f} KB")
    
    def _generate_diverse_requirements(self, num_requirements: int, files: List[Path]) -> List[str]:
        """åŸºäºé¡¹ç›®ä¸Šä¸‹æ–‡åŠ¨æ€ç”Ÿæˆå¤šæ ·åŒ–éœ€æ±‚"""
        templates = [
            "ä¸º{module}æ·»åŠ {feature}åŠŸèƒ½",
            "ä¼˜åŒ–{module}çš„{aspect}æ€§èƒ½",
            "é‡æ„{module}ä»¥æ”¯æŒ{capability}",
            "åœ¨{module}ä¸­å®ç°{pattern}è®¾è®¡æ¨¡å¼",
            "ä¸º{module}æ·»åŠ {quality}ä¿éšœæœºåˆ¶",
            "æ‰©å±•{module}ä»¥æ”¯æŒ{scenario}åœºæ™¯",
            "æ”¹è¿›{module}çš„{attribute}ä½“éªŒ",
            "é›†æˆ{technology}åˆ°{module}ä¸­"
        ]
        
        features = ["æ‰¹é‡å¤„ç†", "å¼‚æ­¥å¤„ç†", "ç¼“å­˜", "æ•°æ®éªŒè¯", "é”™è¯¯å¤„ç†", "ç›‘æ§å‘Šè­¦", "é…ç½®ç®¡ç†", "æ’ä»¶ç³»ç»Ÿ"]
        aspects = ["æŸ¥è¯¢æ•ˆç‡", "å†…å­˜ä½¿ç”¨", "å“åº”æ—¶é—´", "å¹¶å‘èƒ½åŠ›", "æ‰©å±•æ€§", "å¯ç»´æŠ¤æ€§"]
        capabilities = ["å¤šç§Ÿæˆ·", "å›½é™…åŒ–", "ç‰ˆæœ¬æ§åˆ¶", "çƒ­æ›´æ–°", "ç°åº¦å‘å¸ƒ", "é™çº§ç†”æ–­"]
        patterns = ["å·¥å‚æ¨¡å¼", "ç­–ç•¥æ¨¡å¼", "è§‚å¯Ÿè€…æ¨¡å¼", "è´£ä»»é“¾æ¨¡å¼", "è£…é¥°å™¨æ¨¡å¼", "é€‚é…å™¨æ¨¡å¼"]
        qualities = ["å•å…ƒæµ‹è¯•", "é›†æˆæµ‹è¯•", "æ—¥å¿—è®°å½•", "æ€§èƒ½ç›‘æ§", "å®‰å…¨å®¡è®¡", "å®¹é”™æ¢å¤"]
        scenarios = ["é«˜å¹¶å‘", "å¤§æ•°æ®é‡", "å¼±ç½‘ç¯å¢ƒ", "è·¨å¹³å°", "å¾®æœåŠ¡", "è¾¹ç¼˜è®¡ç®—"]
        attributes = ["ç”¨æˆ·", "å¼€å‘è€…", "è¿ç»´", "å®‰å…¨", "æ€§èƒ½"]
        technologies = ["Redis", "Kafka", "Elasticsearch", "GraphQL", "gRPC", "Docker"]
        
        modules = list(set([f.stem for f in files[:10]]))
        if not modules:
            modules = ["æ ¸å¿ƒæ¨¡å—", "æ•°æ®å±‚", "æœåŠ¡å±‚", "APIå±‚"]
        
        requirements = []
        used_combinations = set()
        
        for _ in range(num_requirements * 3):
            template = random.choice(templates)
            module = random.choice(modules)
            
            req = template.format(
                module=module,
                feature=random.choice(features),
                aspect=random.choice(aspects),
                capability=random.choice(capabilities),
                pattern=random.choice(patterns),
                quality=random.choice(qualities),
                scenario=random.choice(scenarios),
                attribute=random.choice(attributes),
                technology=random.choice(technologies)
            )
            
            if req not in used_combinations:
                requirements.append(req)
                used_combinations.add(req)
                if len(requirements) >= num_requirements:
                    break
        
        return requirements if requirements else [
            "ä¼˜åŒ–ç³»ç»Ÿæ¶æ„ï¼Œæå‡æ•´ä½“æ€§èƒ½å’Œå¯æ‰©å±•æ€§",
            "å®ç°å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•æœºåˆ¶",
            "æ·»åŠ è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶ï¼Œæé«˜ä»£ç è´¨é‡"
        ]
    
    def _parse_qa_response(self, text: str) -> Optional[Dict]:
        """è§£æé—®ç­”å“åº”"""
        try:
            question_match = re.search(r'Question:\s*(.+?)(?=\n\nAnswer:|\nAnswer:)', text, re.DOTALL)
            answer_match = re.search(r'Answer:\s*(.+?)(?=\n\nReasoning|$)', text, re.DOTALL)
            reasoning_match = re.findall(r'\d+\.\s*(.+?)(?=\n\d+\.|\n\n|$)', text, re.DOTALL)
            if question_match and answer_match:
                return {
                    'question': question_match.group(1).strip(),
                    'answer': answer_match.group(1).strip(),
                    'reasoning_steps': [r.strip() for r in reasoning_match] if reasoning_match else []
                }
        except:
            pass
        return None
    
    def _parse_design_response(self, text: str, requirement: str) -> Optional[Dict]:
        """è§£æè®¾è®¡æ–¹æ¡ˆå“åº”"""
        try:
            solution_match = re.search(r'Solution:\s*(.+?)(?=\n\nImplementation|\nImplementation)', text, re.DOTALL)
            steps_match = re.findall(r'\d+\.\s*(.+?)(?=\n\d+\.|\n\n|$)', text, re.DOTALL)
            files_match = re.findall(r'-\s*([^:]+):\s*(.+?)(?=\n-|\n\n|$)', text, re.DOTALL)
            challenges_match = re.findall(r'-\s*(.+?)(?=\n-|\n\n|$)', text.split('Challenges:')[-1] if 'Challenges:' in text else '', re.DOTALL)
            if solution_match:
                return {
                    'requirement': requirement,
                    'solution': solution_match.group(1).strip(),
                    'steps': [s.strip() for s in steps_match][:10],
                    'files_to_modify': [{'file': f.strip(), 'reason': r.strip()} for f, r in files_match],
                    'challenges': [c.strip() for c in challenges_match if c.strip()]
                }
        except:
            pass
        return None
    
    def _generate_mock_response(self, code: str, file_path: str, context_level: str = 'standard') -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”ï¼ˆæ ¹æ®ä¸Šä¸‹æ–‡å±‚æ¬¡ç”Ÿæˆä¸åŒå±‚æ¬¡çš„é—®é¢˜ï¼‰"""
        mock_templates = {
            'minimal': f"""
Question: {file_path}ä¸­è¿™æ®µä»£ç ä½¿ç”¨äº†ä»€ä¹ˆæ•°æ®ç»“æ„ï¼Ÿç®—æ³•å¤æ‚åº¦æ˜¯å¤šå°‘ï¼Ÿ

Answer: è¿™æ®µä»£ç ä¸»è¦ä½¿ç”¨äº†å“ˆå¸Œè¡¨(dict)å’Œåˆ—è¡¨(list)æ•°æ®ç»“æ„ã€‚æ ¸å¿ƒç®—æ³•é‡‡ç”¨è¿­ä»£æ–¹å¼å¤„ç†æ•°æ®ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(n)ï¼Œå…¶ä¸­næ˜¯è¾“å…¥æ•°æ®çš„è§„æ¨¡ã€‚ç©ºé—´å¤æ‚åº¦ä¸ºO(n)ï¼Œç”¨äºå­˜å‚¨ä¸­é—´ç»“æœã€‚ä»£ç ä¸­ä½¿ç”¨äº†é›†åˆ(set)æ¥å»é‡ï¼Œæé«˜äº†æŸ¥æ‰¾æ•ˆç‡ã€‚

Reasoning Steps:
1. è¯†åˆ«ä»£ç ä¸­ä½¿ç”¨çš„ä¸»è¦æ•°æ®ç»“æ„(dictã€listã€set)
2. åˆ†ææ ¸å¿ƒå¾ªç¯å’Œè¿­ä»£é€»è¾‘
3. è®¡ç®—æ—¶é—´å¤æ‚åº¦ï¼šå•æ¬¡éå†O(n)
4. è¯„ä¼°ç©ºé—´ä½¿ç”¨ï¼šéœ€è¦é¢å¤–å­˜å‚¨ç©ºé—´O(n)
""",
            'standard': f"""
Question: {file_path}æ¨¡å—åœ¨æ•´ä¸ªç³»ç»Ÿä¸­æ‰¿æ‹…ä»€ä¹ˆèŒè´£ï¼Ÿå®ƒéµå¾ªäº†å“ªäº›è®¾è®¡æ¨¡å¼ï¼Ÿ

Answer: è¯¥æ¨¡å—ä½œä¸ºæ•°æ®å¤„ç†å±‚çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£åè°ƒéªŒè¯å™¨å’Œè½¬æ¢å™¨ï¼Œé‡‡ç”¨äº†ç­–ç•¥æ¨¡å¼å’Œè£…é¥°å™¨æ¨¡å¼ã€‚é€šè¿‡ä¾èµ–æ³¨å…¥å®ç°äº†ä¸å­˜å‚¨å±‚çš„è§£è€¦ï¼Œä½¿ç”¨è§‚å¯Ÿè€…æ¨¡å¼é€šçŸ¥å…¶ä»–æ¨¡å—å¤„ç†ç»“æœã€‚è¿™ç§è®¾è®¡ä¿è¯äº†å•ä¸€èŒè´£åŸåˆ™ï¼Œæé«˜äº†ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§ã€‚

Reasoning Steps:
1. åˆ†ææ¨¡å—çš„ä¸»è¦èŒè´£å’Œåœ¨æ¶æ„ä¸­çš„ä½ç½®
2. è¯†åˆ«ä½¿ç”¨çš„è®¾è®¡æ¨¡å¼ï¼šç­–ç•¥æ¨¡å¼å¤„ç†å¤šç§ç®—æ³•ã€è£…é¥°å™¨å¢å¼ºåŠŸèƒ½
3. è¯„ä¼°æ¨¡å—é—´çš„ä¾èµ–å…³ç³»å’Œè§£è€¦ç¨‹åº¦
4. è¯´æ˜è®¾è®¡å¦‚ä½•æ”¯æŒæ‰©å±•å’Œç»´æŠ¤
""",
            'full': f"""
Question: ä»ç³»ç»Ÿæ¶æ„è§’åº¦åˆ†æï¼Œ{file_path}æ‰€åœ¨å­ç³»ç»Ÿçš„è®¾è®¡å¦‚ä½•æ»¡è¶³æ€§èƒ½å’Œæ‰©å±•æ€§è¦æ±‚ï¼Ÿåœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹æœ‰å“ªäº›ä¼˜åŒ–ç­–ç•¥ï¼Ÿ

Answer: è¯¥å­ç³»ç»Ÿé‡‡ç”¨åˆ†å±‚æ¶æ„å’Œæ’ä»¶åŒ–è®¾è®¡ï¼Œé€šè¿‡æŠ½è±¡å·¥å‚æ¨¡å¼æ”¯æŒå¤šæ•°æ®æºæ‰©å±•ã€‚æ€§èƒ½ä¼˜åŒ–åŒ…æ‹¬ï¼š1) ä½¿ç”¨LRUç¼“å­˜å‡å°‘é‡å¤è®¡ç®—ï¼›2) é‡‡ç”¨å¼‚æ­¥IOå’Œçº¿ç¨‹æ± å¤„ç†å¹¶å‘è¯·æ±‚ï¼›3) é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—å®ç°å‰Šå³°å¡«è°·ã€‚æ‰©å±•æ€§æ–¹é¢ï¼Œé…ç½®ä¸­å¿ƒæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼Œæ°´å¹³æ‰©å±•é€šè¿‡æ— çŠ¶æ€è®¾è®¡å®ç°ã€‚ç›‘æ§æŒ‡æ ‡åŒ…æ‹¬ååé‡ã€å“åº”æ—¶é—´å’Œèµ„æºä½¿ç”¨ç‡ã€‚

Reasoning Steps:
1. åˆ†ææ•´ä½“æ¶æ„ï¼šåˆ†å±‚è®¾è®¡ã€æ’ä»¶åŒ–ã€å¯æ‰©å±•æ€§
2. è¯†åˆ«æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼šç¼“å­˜ã€å¼‚æ­¥ã€å¹¶å‘æ§åˆ¶
3. è¯„ä¼°æ‰©å±•æœºåˆ¶ï¼šé…ç½®åŠ¨æ€åŒ–ã€æ— çŠ¶æ€è®¾è®¡
4. è¯´æ˜ç›‘æ§å’Œè¿ç»´è€ƒé‡
"""
        }
        return mock_templates.get(context_level, mock_templates['standard'])
    
    def _generate_mock_design_response(self, requirement: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿè®¾è®¡å“åº”"""
        return f"""
Requirement: {requirement}

Solution: é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå¼•å…¥ä»»åŠ¡é˜Ÿåˆ—å’Œç¼“å­˜å±‚ã€‚é€šè¿‡å¼‚æ­¥å¤„ç†æå‡æ€§èƒ½ï¼Œä½¿ç”¨Redisä½œä¸ºç¼“å­˜å­˜å‚¨ï¼Œç¡®ä¿ç³»ç»Ÿå¯æ‰©å±•æ€§ã€‚

Implementation Steps:
1. åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—æ¨¡å—ï¼Œä½¿ç”¨Celeryå®ç°å¼‚æ­¥å¤„ç†
2. è®¾è®¡ç¼“å­˜å±‚æ¥å£ï¼Œé›†æˆRedis
3. é‡æ„æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼Œæ·»åŠ ç¼“å­˜æ”¯æŒ
4. å®ç°ç›‘æ§å’Œæ—¥å¿—è®°å½•åŠŸèƒ½
5. ç¼–å†™å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

Files to Modify:
- core/processor.py: æ·»åŠ å¼‚æ­¥å¤„ç†æ”¯æŒ
- utils/cache.py: æ–°å»ºç¼“å­˜ç®¡ç†æ¨¡å—
- config/settings.py: æ·»åŠ ä»»åŠ¡é˜Ÿåˆ—é…ç½®

Challenges:
- å¼‚æ­¥ä»»åŠ¡çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ç¼“å­˜ä¸€è‡´æ€§ä¿è¯
- æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
"""


def quick_generate(project_path: str, num_qa: int = 5, num_design: int = 3, 
                  output_path: str = "output/training_data.json", use_context: bool = True,
                  context_level: str = 'standard') -> Dict:
    """å¿«é€Ÿç”Ÿæˆè®­ç»ƒæ•°æ®
    
    Args:
        project_path: é¡¹ç›®è·¯å¾„
        num_qa: é—®ç­”å¯¹æ•°é‡
        num_design: è®¾è®¡æ–¹æ¡ˆæ•°é‡
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        use_context: æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡
        context_level: ä¸Šä¸‹æ–‡çº§åˆ« ('minimal'/'standard'/'full')
    """
    generator = SimpleGenerator(project_path)
    dataset = generator.generate_batch(num_qa, num_design, use_context, context_level)
    generator.save_dataset(dataset, output_path)
    return dataset
